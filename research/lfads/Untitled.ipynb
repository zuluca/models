{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! export PYTHONPATH=$PYTHONPATH:/path/to/your/directory/lfads/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data\n",
      "Generating chaotic rnn data with no input pulses (g=1.5) with spiking noise\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with no input pulses (g=1.5) with Gaussian noise\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with input pulses (g=1.5)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating chaotic rnn data with input pulses (g=2.5)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  1\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generate the multi-session RNN data (no multi-session synth example in paper)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "1  of  5\n",
      "2  of  5\n",
      "3  of  5\n",
      "4  of  5\n",
      "5  of  5\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data/synthetic_data_utils.py:320: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\n",
      "To use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n",
      "  np.linalg.lstsq(all_data_zm_chxtc.T, all_data_pca_pxtc.T)\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saving variable with name:  input_magnitude\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  input_train_truth\n",
      "Saving variable with name:  alignment_bias_c\n",
      "Saving variable with name:  input_times_train\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  alignment_matrix_cxf\n",
      "Saving variable with name:  input_times_valid\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  input_valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Generating Integration-to-bound RNN data\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "2018-04-18 11:24:53.243626: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Model restored from /Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/synth_data/trained_itb/model-65000\n",
      "Saving variable with name:  train_outputs_u\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_inputs_u\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  max_firing_rate\n",
      "Saving variable with name:  valid_outputs_u\n",
      "Saving variable with name:  u_std\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  train_inputs_u\n",
      "Saving variable with name:  train_data\n",
      "Saved to  /tmp/rnn_synth_data_v1.0/itb_rnn_dataset_N50\n",
      "Generating chaotic rnn data with external input labels (no external input labels example in paper)\n",
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Saving variable with name:  nreplications\n",
      "Saving variable with name:  valid_truth\n",
      "Saving variable with name:  train_ext_input\n",
      "Saving variable with name:  dt\n",
      "Saving variable with name:  valid_data\n",
      "Saving variable with name:  train_truth\n",
      "Saving variable with name:  P_sxn\n",
      "Saving variable with name:  valid_ext_input\n",
      "Saving variable with name:  conversion_factor\n",
      "Saving variable with name:  train_percentage\n",
      "Saving variable with name:  condition_labels_valid\n",
      "Saving variable with name:  condition_labels_train\n",
      "Saving variable with name:  train_data\n",
      "Saved to  /tmp/rnn_synth_data_v1.0/chaotic_rnns_labeled_dataset_N50\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads\n"
     ]
    }
   ],
   "source": [
    "! pwd\n",
    "% cd synth_data\n",
    "! ./run_generate_synth_data.sh\n",
    "% cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md        distributions.py \u001b[31mrun_lfads.py\u001b[m\u001b[m     utils.pyc\r\n",
      "Untitled.ipynb   lfads.py         \u001b[34msynth_data\u001b[m\u001b[m\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m      plot_lfads.py    utils.py\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading data from  /tmp/rnn_synth_data_v1.0/\n",
      "loading data from /tmp/rnn_synth_data_v1.0/ with stem chaotic_rnn_no_inputs\n",
      "1 datasets loaded\n",
      "Found training set with number examples:  3200\n",
      "Found validation set with number examples:  800\n",
      "2018-04-18 11:28:58.919253: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Building graph...\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/lfads.py:322: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  datasets[hps.dataset_names[0]]['train_data'].dtype, int), \\\n",
      "done.\n",
      "Model Variables (to be optimized): \n",
      "     0 LFADS/glm/fac_2_logrates_dataset_N50_S50/W:0 [20, 50]\n",
      "     1 LFADS/glm/fac_2_logrates_dataset_N50_S50/b:0 [1, 50]\n",
      "     2 LFADS/ic_enc_fwd/ic_enc_t0_fwd:0 [1, 128]\n",
      "     3 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     4 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     5 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     6 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     7 LFADS/ic_enc_rev/ic_enc_t0_rev:0 [1, 128]\n",
      "     8 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     9 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     10 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     11 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     12 LFADS/z/prior_g0/mean:0 [1, 64]\n",
      "     13 LFADS/z/ic_enc_2_post_g0/mean/W:0 [256, 64]\n",
      "     14 LFADS/z/ic_enc_2_post_g0/mean/b:0 [1, 64]\n",
      "     15 LFADS/z/ic_enc_2_post_g0/logvar/W:0 [256, 64]\n",
      "     16 LFADS/z/ic_enc_2_post_g0/logvar/b:0 [1, 64]\n",
      "     17 LFADS/gen/g0_2_gen_ic/W:0 [64, 200]\n",
      "     18 LFADS/gen/g0_2_gen_ic/b:0 [1, 200]\n",
      "     19 LFADS/gen/gen_2_fac/W:0 [200, 20]\n",
      "     20 LFADS/gen/GenGRU/Gates/h_2_ru/W:0 [200, 400]\n",
      "     21 LFADS/gen/GenGRU/Gates/h_2_ru/b:0 [1, 400]\n",
      "     22 LFADS/gen/GenGRU/Candidate/rh_2_c/W:0 [200, 200]\n",
      "     23 LFADS/gen/GenGRU/Candidate/rh_2_c/b:0 [1, 200]\n",
      "Total model parameters:  309338\n",
      "Loading latest training checkpoint in:  /tmp/lfads_chaotic_rnn_no_inputs\n",
      "ckpt:  None\n",
      "Created model with fresh parameters.\n",
      "Epoch:0, step:25 (TRAIN, VALID): total: 3095.96, 2249.63      recon: 3094.61, 2246.99,     kl: 217.76, 206.17,     l2: 5.07264,      kl weight: 0.01, l2 weight: 0.01\n",
      "Epoch:1, step:50 (TRAIN, VALID): total: 2238.07, 2233.54      recon: 2234.98, 2230.76,     kl: 167.89, 106.19,     l2: 5.09913,      kl weight: 0.02, l2 weight: 0.02\n",
      "Epoch:2, step:75 (TRAIN, VALID): total: 2231.44, 2229.74      recon: 2229.76, 2229.09,     kl: 52.53, 12.34,     l2: 5.10052,      kl weight: 0.04, l2 weight: 0.04\n",
      "Epoch:3, step:100 (TRAIN, VALID): total: 2229.44, 2229.85      recon: 2228.79, 2229.36,     kl: 10.00, 4.64,     l2: 5.09838,      kl weight: 0.05, l2 weight: 0.05\n",
      "Epoch:4, step:125 (TRAIN, VALID): total: 2229.12, 2228.42      recon: 2228.43, 2227.88,     kl: 7.15, 3.56,     l2: 5.09428,      kl weight: 0.06, l2 weight: 0.06\n",
      "Epoch:5, step:150 (TRAIN, VALID): total: 2228.75, 2228.49      recon: 2227.94, 2227.77,     kl: 6.66, 4.57,     l2: 5.08973,      kl weight: 0.07, l2 weight: 0.07\n",
      "Epoch:6, step:175 (TRAIN, VALID): total: 2227.34, 2229.03      recon: 2226.18, 2227.42,     kl: 9.11, 13.24,     l2: 5.09079,      kl weight: 0.09, l2 weight: 0.09\n",
      "Epoch:7, step:200 (TRAIN, VALID): total: 2209.90, 2190.88      recon: 2207.18, 2187.27,     kl: 23.71, 30.96,     l2: 5.16023,      kl weight: 0.10, l2 weight: 0.10\n",
      "Epoch:8, step:225 (TRAIN, VALID): total: 2148.43, 2113.94      recon: 2143.74, 2107.81,     kl: 38.95, 49.24,     l2: 5.29357,      kl weight: 0.11, l2 weight: 0.11\n",
      "Epoch:9, step:250 (TRAIN, VALID): total: 2138.82, 2120.30      recon: 2132.34, 2112.93,     kl: 49.27, 53.56,     l2: 5.39855,      kl weight: 0.12, l2 weight: 0.12\n",
      "Epoch:10, step:275 (TRAIN, VALID): total: 2114.79, 2111.89      recon: 2108.60, 2106.34,     kl: 41.95, 34.81,     l2: 5.49142,      kl weight: 0.14, l2 weight: 0.14\n",
      "Epoch:11, step:300 (TRAIN, VALID): total: 2103.53, 2107.91      recon: 2098.13, 2102.09,     kl: 32.14, 33.24,     l2: 5.56440,      kl weight: 0.15, l2 weight: 0.15\n",
      "Epoch:12, step:325 (TRAIN, VALID): total: 2091.43, 2079.81      recon: 2085.78, 2074.67,     kl: 30.67, 26.01,     l2: 5.62404,      kl weight: 0.16, l2 weight: 0.16\n",
      "Epoch:13, step:350 (TRAIN, VALID): total: 2091.12, 2095.20      recon: 2085.34, 2088.50,     kl: 28.67, 32.62,     l2: 5.65990,      kl weight: 0.17, l2 weight: 0.17\n",
      "Epoch:14, step:375 (TRAIN, VALID): total: 2086.75, 2084.03      recon: 2080.57, 2078.36,     kl: 28.48, 24.53,     l2: 5.70120,      kl weight: 0.19, l2 weight: 0.19\n",
      "Epoch:15, step:400 (TRAIN, VALID): total: 2081.13, 2075.45      recon: 2075.10, 2069.49,     kl: 25.43, 24.04,     l2: 5.73352,      kl weight: 0.20, l2 weight: 0.20\n",
      "Epoch:16, step:425 (TRAIN, VALID): total: 2077.59, 2073.01      recon: 2071.39, 2066.91,     kl: 24.35, 22.93,     l2: 5.75308,      kl weight: 0.21, l2 weight: 0.21\n",
      "Epoch:17, step:450 (TRAIN, VALID): total: 2075.75, 2070.16      recon: 2069.26, 2063.68,     kl: 23.98, 23.03,     l2: 5.76931,      kl weight: 0.22, l2 weight: 0.22\n",
      "Epoch:18, step:475 (TRAIN, VALID): total: 2073.73, 2068.37      recon: 2067.09, 2061.82,     kl: 22.97, 21.78,     l2: 5.78526,      kl weight: 0.24, l2 weight: 0.24\n",
      "Epoch:19, step:500 (TRAIN, VALID): total: 2081.51, 2084.96      recon: 2074.28, 2077.75,     kl: 23.90, 23.04,     l2: 5.78542,      kl weight: 0.25, l2 weight: 0.25\n",
      "Epoch:20, step:525 (TRAIN, VALID): total: 2078.62, 2071.33      recon: 2070.93, 2064.27,     kl: 24.26, 21.10,     l2: 5.81213,      kl weight: 0.26, l2 weight: 0.26\n",
      "Epoch:21, step:550 (TRAIN, VALID): total: 2072.90, 2073.95      recon: 2065.28, 2066.31,     kl: 22.55, 21.95,     l2: 5.82941,      kl weight: 0.27, l2 weight: 0.27\n",
      "Epoch:22, step:575 (TRAIN, VALID): total: 2077.06, 2082.11      recon: 2069.08, 2073.83,     kl: 22.56, 22.97,     l2: 5.84416,      kl weight: 0.29, l2 weight: 0.29\n",
      "Epoch:23, step:600 (TRAIN, VALID): total: 2072.84, 2066.35      recon: 2064.35, 2058.24,     kl: 23.07, 21.20,     l2: 5.86310,      kl weight: 0.30, l2 weight: 0.30\n",
      "Epoch:24, step:625 (TRAIN, VALID): total: 2074.02, 2069.23      recon: 2065.37, 2060.66,     kl: 22.40, 21.56,     l2: 5.86637,      kl weight: 0.31, l2 weight: 0.31\n",
      "Epoch:25, step:650 (TRAIN, VALID): total: 2069.48, 2067.61      recon: 2060.53, 2058.86,     kl: 22.24, 21.05,     l2: 5.86558,      kl weight: 0.32, l2 weight: 0.32\n",
      "Epoch:26, step:675 (TRAIN, VALID): total: 2066.69, 2068.88      recon: 2057.64, 2059.87,     kl: 21.47, 20.85,     l2: 5.85530,      kl weight: 0.34, l2 weight: 0.34\n",
      "Epoch:27, step:700 (TRAIN, VALID): total: 2068.00, 2067.47      recon: 2058.48, 2058.37,     kl: 21.88, 20.16,     l2: 5.84209,      kl weight: 0.35, l2 weight: 0.35\n",
      "Epoch:28, step:725 (TRAIN, VALID): total: 2067.28, 2072.19      recon: 2057.70, 2062.99,     kl: 21.07, 19.56,     l2: 5.81976,      kl weight: 0.36, l2 weight: 0.36\n",
      "Epoch:29, step:750 (TRAIN, VALID): total: 2074.96, 2072.46      recon: 2064.99, 2062.43,     kl: 21.23, 20.93,     l2: 5.81489,      kl weight: 0.37, l2 weight: 0.37\n",
      "     Decreasing learning rate to 0.009500.\n",
      "Epoch:30, step:775 (TRAIN, VALID): total: 2069.49, 2062.38      recon: 2059.46, 2052.26,     kl: 20.52, 20.32,     l2: 5.81330,      kl weight: 0.39, l2 weight: 0.39\n",
      "Epoch:31, step:800 (TRAIN, VALID): total: 2068.36, 2062.49      recon: 2058.08, 2052.29,     kl: 20.31, 19.72,     l2: 5.80162,      kl weight: 0.40, l2 weight: 0.40\n",
      "Epoch:32, step:825 (TRAIN, VALID): total: 2067.32, 2066.64      recon: 2056.85, 2056.22,     kl: 19.99, 19.46,     l2: 5.78689,      kl weight: 0.41, l2 weight: 0.41\n",
      "Epoch:33, step:850 (TRAIN, VALID): total: 2068.66, 2072.85      recon: 2057.86, 2062.12,     kl: 20.04, 19.51,     l2: 5.75317,      kl weight: 0.42, l2 weight: 0.42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:34, step:875 (TRAIN, VALID): total: 2077.38, 2072.91      recon: 2066.44, 2062.14,     kl: 19.64, 18.88,     l2: 5.75241,      kl weight: 0.44, l2 weight: 0.44\n",
      "Epoch:35, step:900 (TRAIN, VALID): total: 2067.09, 2061.96      recon: 2056.11, 2051.12,     kl: 19.01, 18.34,     l2: 5.75435,      kl weight: 0.45, l2 weight: 0.45\n",
      "Epoch:36, step:925 (TRAIN, VALID): total: 2063.47, 2059.20      recon: 2052.41, 2048.32,     kl: 18.51, 17.78,     l2: 5.72781,      kl weight: 0.46, l2 weight: 0.46\n",
      "Epoch:37, step:950 (TRAIN, VALID): total: 2062.77, 2071.00      recon: 2051.71, 2060.26,     kl: 17.91, 16.92,     l2: 5.68824,      kl weight: 0.47, l2 weight: 0.47\n",
      "Epoch:38, step:975 (TRAIN, VALID): total: 2067.48, 2063.98      recon: 2056.11, 2052.71,     kl: 17.97, 17.45,     l2: 5.65768,      kl weight: 0.49, l2 weight: 0.49\n",
      "Epoch:39, step:1000 (TRAIN, VALID): total: 2064.62, 2060.91      recon: 2053.01, 2049.60,     kl: 17.90, 17.01,     l2: 5.62637,      kl weight: 0.50, l2 weight: 0.50\n",
      "Epoch:40, step:1025 (TRAIN, VALID): total: 2061.60, 2060.96      recon: 2050.06, 2049.57,     kl: 17.21, 16.64,     l2: 5.59589,      kl weight: 0.51, l2 weight: 0.51\n",
      "Epoch:41, step:1050 (TRAIN, VALID): total: 2065.78, 2063.03      recon: 2053.93, 2051.23,     kl: 17.29, 16.92,     l2: 5.55344,      kl weight: 0.52, l2 weight: 0.52\n",
      "Epoch:42, step:1075 (TRAIN, VALID): total: 2064.12, 2059.61      recon: 2051.93, 2047.71,     kl: 17.42, 16.61,     l2: 5.52678,      kl weight: 0.54, l2 weight: 0.54\n",
      "Epoch:43, step:1100 (TRAIN, VALID): total: 2062.65, 2068.17      recon: 2050.39, 2056.26,     kl: 17.04, 16.16,     l2: 5.49397,      kl weight: 0.55, l2 weight: 0.55\n",
      "Epoch:44, step:1125 (TRAIN, VALID): total: 2066.16, 2066.32      recon: 2053.56, 2053.66,     kl: 17.18, 17.04,     l2: 5.46573,      kl weight: 0.56, l2 weight: 0.56\n",
      "Epoch:45, step:1150 (TRAIN, VALID): total: 2063.29, 2059.72      recon: 2050.48, 2047.23,     kl: 17.09, 16.28,     l2: 5.43976,      kl weight: 0.57, l2 weight: 0.57\n",
      "Epoch:46, step:1175 (TRAIN, VALID): total: 2060.36, 2059.03      recon: 2047.49, 2046.51,     kl: 16.73, 15.91,     l2: 5.39751,      kl weight: 0.59, l2 weight: 0.59\n",
      "Epoch:47, step:1200 (TRAIN, VALID): total: 2058.77, 2058.36      recon: 2045.90, 2046.03,     kl: 16.31, 15.21,     l2: 5.34456,      kl weight: 0.60, l2 weight: 0.60\n",
      "Epoch:48, step:1225 (TRAIN, VALID): total: 2059.65, 2055.47      recon: 2046.65, 2042.78,     kl: 16.13, 15.42,     l2: 5.29663,      kl weight: 0.61, l2 weight: 0.61\n",
      "Epoch:49, step:1250 (TRAIN, VALID): total: 2064.48, 2066.10      recon: 2051.34, 2053.22,     kl: 15.97, 15.35,     l2: 5.25171,      kl weight: 0.62, l2 weight: 0.62\n",
      "Epoch:50, step:1275 (TRAIN, VALID): total: 2061.24, 2057.32      recon: 2047.94, 2044.11,     kl: 15.86, 15.52,     l2: 5.20359,      kl weight: 0.64, l2 weight: 0.64\n",
      "Epoch:51, step:1300 (TRAIN, VALID): total: 2062.16, 2058.18      recon: 2048.65, 2044.96,     kl: 15.82, 15.19,     l2: 5.15673,      kl weight: 0.65, l2 weight: 0.65\n",
      "Epoch:52, step:1325 (TRAIN, VALID): total: 2063.52, 2064.78      recon: 2049.85, 2051.36,     kl: 15.70, 15.14,     l2: 5.12194,      kl weight: 0.66, l2 weight: 0.66\n",
      "Epoch:53, step:1350 (TRAIN, VALID): total: 2062.86, 2059.46      recon: 2049.00, 2045.92,     kl: 15.63, 14.98,     l2: 5.08773,      kl weight: 0.67, l2 weight: 0.67\n",
      "Epoch:54, step:1375 (TRAIN, VALID): total: 2063.98, 2068.28      recon: 2049.96, 2054.62,     kl: 15.51, 14.81,     l2: 5.05976,      kl weight: 0.69, l2 weight: 0.69\n",
      "Epoch:55, step:1400 (TRAIN, VALID): total: 2060.58, 2057.55      recon: 2046.62, 2043.82,     kl: 15.09, 14.60,     l2: 5.02010,      kl weight: 0.70, l2 weight: 0.70\n",
      "Epoch:56, step:1425 (TRAIN, VALID): total: 2061.93, 2064.85      recon: 2047.88, 2051.07,     kl: 14.92, 14.37,     l2: 4.96274,      kl weight: 0.71, l2 weight: 0.71\n",
      "Epoch:57, step:1450 (TRAIN, VALID): total: 2063.67, 2057.04      recon: 2049.39, 2043.18,     kl: 14.92, 14.18,     l2: 4.92979,      kl weight: 0.72, l2 weight: 0.72\n",
      "Epoch:58, step:1475 (TRAIN, VALID): total: 2060.21, 2062.41      recon: 2046.03, 2048.47,     kl: 14.49, 14.03,     l2: 4.88291,      kl weight: 0.74, l2 weight: 0.74\n",
      "Epoch:59, step:1500 (TRAIN, VALID): total: 2064.39, 2071.53      recon: 2049.97, 2057.57,     kl: 14.53, 13.77,     l2: 4.84437,      kl weight: 0.75, l2 weight: 0.75\n",
      "     Decreasing learning rate to 0.009025.\n",
      "Epoch:60, step:1525 (TRAIN, VALID): total: 2060.18, 2057.40      recon: 2045.79, 2043.43,     kl: 14.20, 13.51,     l2: 4.81312,      kl weight: 0.76, l2 weight: 0.76\n",
      "Epoch:61, step:1550 (TRAIN, VALID): total: 2057.16, 2058.65      recon: 2042.70, 2044.55,     kl: 14.04, 13.44,     l2: 4.74859,      kl weight: 0.77, l2 weight: 0.77\n",
      "Epoch:62, step:1575 (TRAIN, VALID): total: 2058.11, 2058.97      recon: 2043.52, 2044.55,     kl: 13.97, 13.64,     l2: 4.67810,      kl weight: 0.79, l2 weight: 0.79\n",
      "Epoch:63, step:1600 (TRAIN, VALID): total: 2057.30, 2055.72      recon: 2042.71, 2041.07,     kl: 13.74, 13.71,     l2: 4.61305,      kl weight: 0.80, l2 weight: 0.80\n",
      "Epoch:64, step:1625 (TRAIN, VALID): total: 2059.21, 2060.10      recon: 2044.49, 2046.03,     kl: 13.67, 12.77,     l2: 4.54900,      kl weight: 0.81, l2 weight: 0.81\n",
      "Epoch:65, step:1650 (TRAIN, VALID): total: 2059.04, 2068.27      recon: 2044.36, 2053.85,     kl: 13.41, 12.98,     l2: 4.50111,      kl weight: 0.82, l2 weight: 0.82\n",
      "Epoch:66, step:1675 (TRAIN, VALID): total: 2060.05, 2057.72      recon: 2045.12, 2043.50,     kl: 13.50, 12.53,     l2: 4.45217,      kl weight: 0.84, l2 weight: 0.84\n",
      "Epoch:67, step:1700 (TRAIN, VALID): total: 2059.84, 2060.64      recon: 2044.89, 2045.83,     kl: 13.30, 13.04,     l2: 4.39620,      kl weight: 0.85, l2 weight: 0.85\n",
      "Epoch:68, step:1725 (TRAIN, VALID): total: 2061.57, 2060.95      recon: 2046.33, 2046.26,     kl: 13.43, 12.68,     l2: 4.35239,      kl weight: 0.86, l2 weight: 0.86\n",
      "     Decreasing learning rate to 0.008574.\n",
      "Epoch:69, step:1750 (TRAIN, VALID): total: 2058.66, 2058.38      recon: 2043.50, 2043.49,     kl: 13.12, 12.71,     l2: 4.30953,      kl weight: 0.87, l2 weight: 0.87\n",
      "Epoch:70, step:1775 (TRAIN, VALID): total: 2060.80, 2057.98      recon: 2045.48, 2042.75,     kl: 13.11, 12.92,     l2: 4.24990,      kl weight: 0.89, l2 weight: 0.89\n",
      "Epoch:71, step:1800 (TRAIN, VALID): total: 2059.91, 2057.64      recon: 2044.60, 2042.65,     kl: 12.90, 12.45,     l2: 4.21127,      kl weight: 0.90, l2 weight: 0.90\n",
      "Epoch:72, step:1825 (TRAIN, VALID): total: 2058.68, 2058.32      recon: 2043.23, 2043.30,     kl: 12.86, 12.29,     l2: 4.16684,      kl weight: 0.91, l2 weight: 0.91\n",
      "Epoch:73, step:1850 (TRAIN, VALID): total: 2059.11, 2057.66      recon: 2043.68, 2042.62,     kl: 12.66, 12.14,     l2: 4.11554,      kl weight: 0.92, l2 weight: 0.92\n",
      "Epoch:74, step:1875 (TRAIN, VALID): total: 2059.73, 2063.34      recon: 2044.16, 2048.13,     kl: 12.64, 12.15,     l2: 4.06953,      kl weight: 0.94, l2 weight: 0.94\n",
      "Epoch:75, step:1900 (TRAIN, VALID): total: 2062.26, 2059.07      recon: 2046.62, 2043.63,     kl: 12.52, 12.21,     l2: 4.03312,      kl weight: 0.95, l2 weight: 0.95\n",
      "     Decreasing learning rate to 0.008145.\n",
      "Epoch:76, step:1925 (TRAIN, VALID): total: 2059.97, 2057.96      recon: 2044.34, 2042.60,     kl: 12.34, 11.97,     l2: 3.99563,      kl weight: 0.96, l2 weight: 0.96\n",
      "Epoch:77, step:1950 (TRAIN, VALID): total: 2058.20, 2056.88      recon: 2042.43, 2041.41,     kl: 12.32, 11.92,     l2: 3.94954,      kl weight: 0.97, l2 weight: 0.97\n",
      "Epoch:78, step:1975 (TRAIN, VALID): total: 2057.59, 2058.07      recon: 2041.69, 2042.63,     kl: 12.29, 11.74,     l2: 3.89665,      kl weight: 0.99, l2 weight: 0.99\n",
      "Epoch:79, step:2000 (TRAIN, VALID): total: 2059.52, 2063.14      recon: 2043.54, 2047.55,     kl: 12.22, 11.74,     l2: 3.83992,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:80, step:2025 (TRAIN, VALID): total: 2059.31, 2062.51      recon: 2043.45, 2047.10,     kl: 12.04, 11.61,     l2: 3.80007,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:81, step:2050 (TRAIN, VALID): total: 2060.48, 2059.68      recon: 2044.68, 2044.28,     kl: 12.02, 11.65,     l2: 3.75176,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:82, step:2075 (TRAIN, VALID): total: 2060.42, 2055.23      recon: 2044.71, 2039.92,     kl: 11.97, 11.59,     l2: 3.72675,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:83, step:2100 (TRAIN, VALID): total: 2058.89, 2057.69      recon: 2043.17, 2042.31,     kl: 12.01, 11.69,     l2: 3.68817,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:84, step:2125 (TRAIN, VALID): total: 2058.16, 2055.83      recon: 2042.48, 2040.44,     kl: 12.02, 11.75,     l2: 3.64491,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:85, step:2150 (TRAIN, VALID): total: 2060.17, 2058.63      recon: 2044.57, 2043.56,     kl: 11.97, 11.46,     l2: 3.60792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:86, step:2175 (TRAIN, VALID): total: 2058.83, 2060.48      recon: 2043.33, 2045.26,     kl: 11.91, 11.64,     l2: 3.57758,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:87, step:2200 (TRAIN, VALID): total: 2059.81, 2058.00      recon: 2044.31, 2043.08,     kl: 11.94, 11.37,     l2: 3.54835,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:88, step:2225 (TRAIN, VALID): total: 2058.21, 2055.98      recon: 2042.76, 2041.15,     kl: 11.92, 11.32,     l2: 3.52072,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:89, step:2250 (TRAIN, VALID): total: 2056.12, 2055.74      recon: 2040.78, 2040.72,     kl: 11.83, 11.53,     l2: 3.48342,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:90, step:2275 (TRAIN, VALID): total: 2060.74, 2066.04      recon: 2045.43, 2050.78,     kl: 11.85, 11.82,     l2: 3.44509,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007738.\n",
      "Epoch:91, step:2300 (TRAIN, VALID): total: 2061.01, 2058.76      recon: 2045.59, 2043.59,     kl: 11.99, 11.74,     l2: 3.43025,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:92, step:2325 (TRAIN, VALID): total: 2056.95, 2055.24      recon: 2041.50, 2040.17,     kl: 12.04, 11.67,     l2: 3.40550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:93, step:2350 (TRAIN, VALID): total: 2056.26, 2055.82      recon: 2040.97, 2040.80,     kl: 11.90, 11.64,     l2: 3.37651,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:94, step:2375 (TRAIN, VALID): total: 2056.87, 2056.25      recon: 2041.73, 2041.42,     kl: 11.78, 11.48,     l2: 3.34612,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:95, step:2400 (TRAIN, VALID): total: 2056.36, 2056.27      recon: 2041.24, 2041.34,     kl: 11.79, 11.61,     l2: 3.32086,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:96, step:2425 (TRAIN, VALID): total: 2057.04, 2055.55      recon: 2041.89, 2040.79,     kl: 11.85, 11.47,     l2: 3.29316,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:97, step:2450 (TRAIN, VALID): total: 2057.31, 2056.90      recon: 2042.29, 2042.07,     kl: 11.75, 11.56,     l2: 3.26688,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:98, step:2475 (TRAIN, VALID): total: 2059.43, 2059.55      recon: 2044.22, 2044.40,     kl: 11.95, 11.90,     l2: 3.25370,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007351.\n",
      "Epoch:99, step:2500 (TRAIN, VALID): total: 2056.09, 2055.91      recon: 2041.00, 2041.30,     kl: 11.83, 11.36,     l2: 3.24569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:100, step:2525 (TRAIN, VALID): total: 2055.89, 2056.98      recon: 2040.80, 2042.25,     kl: 11.86, 11.51,     l2: 3.22089,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:101, step:2550 (TRAIN, VALID): total: 2056.45, 2058.00      recon: 2041.49, 2043.38,     kl: 11.75, 11.42,     l2: 3.19695,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:102, step:2575 (TRAIN, VALID): total: 2054.78, 2056.50      recon: 2039.76, 2041.68,     kl: 11.83, 11.65,     l2: 3.17729,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:103, step:2600 (TRAIN, VALID): total: 2054.49, 2054.20      recon: 2039.49, 2039.60,     kl: 11.84, 11.45,     l2: 3.14582,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:104, step:2625 (TRAIN, VALID): total: 2058.95, 2062.86      recon: 2043.82, 2048.13,     kl: 12.00, 11.61,     l2: 3.12341,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:105, step:2650 (TRAIN, VALID): total: 2060.02, 2060.72      recon: 2045.05, 2046.11,     kl: 11.85, 11.49,     l2: 3.11748,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006983.\n",
      "Epoch:106, step:2675 (TRAIN, VALID): total: 2057.60, 2057.78      recon: 2042.79, 2043.45,     kl: 11.69, 11.21,     l2: 3.11778,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:107, step:2700 (TRAIN, VALID): total: 2056.80, 2059.53      recon: 2041.91, 2044.84,     kl: 11.77, 11.58,     l2: 3.10667,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:108, step:2725 (TRAIN, VALID): total: 2056.21, 2054.12      recon: 2041.23, 2039.50,     kl: 11.88, 11.52,     l2: 3.09383,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:109, step:2750 (TRAIN, VALID): total: 2054.33, 2055.83      recon: 2039.39, 2041.37,     kl: 11.86, 11.39,     l2: 3.07543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:110, step:2775 (TRAIN, VALID): total: 2055.43, 2055.58      recon: 2040.55, 2041.30,     kl: 11.82, 11.23,     l2: 3.05564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:111, step:2800 (TRAIN, VALID): total: 2055.01, 2056.47      recon: 2040.14, 2041.86,     kl: 11.82, 11.57,     l2: 3.03769,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:112, step:2825 (TRAIN, VALID): total: 2055.20, 2054.57      recon: 2040.40, 2040.13,     kl: 11.77, 11.42,     l2: 3.02538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:113, step:2850 (TRAIN, VALID): total: 2053.67, 2058.88      recon: 2038.91, 2044.21,     kl: 11.74, 11.66,     l2: 3.01265,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:114, step:2875 (TRAIN, VALID): total: 2055.86, 2054.55      recon: 2041.04, 2040.06,     kl: 11.82, 11.50,     l2: 2.99204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:115, step:2900 (TRAIN, VALID): total: 2054.67, 2054.00      recon: 2039.74, 2039.54,     kl: 11.94, 11.48,     l2: 2.97770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:116, step:2925 (TRAIN, VALID): total: 2053.83, 2058.09      recon: 2039.07, 2043.52,     kl: 11.79, 11.60,     l2: 2.96507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:117, step:2950 (TRAIN, VALID): total: 2058.94, 2056.14      recon: 2044.23, 2041.59,     kl: 11.76, 11.60,     l2: 2.95057,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006634.\n",
      "Epoch:118, step:2975 (TRAIN, VALID): total: 2054.01, 2055.44      recon: 2039.26, 2041.19,     kl: 11.80, 11.30,     l2: 2.95095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:119, step:3000 (TRAIN, VALID): total: 2054.66, 2054.35      recon: 2040.01, 2039.82,     kl: 11.71, 11.60,     l2: 2.94072,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:120, step:3025 (TRAIN, VALID): total: 2056.70, 2057.13      recon: 2041.92, 2041.99,     kl: 11.85, 12.21,     l2: 2.92625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:121, step:3050 (TRAIN, VALID): total: 2055.48, 2053.70      recon: 2040.59, 2039.47,     kl: 11.96, 11.30,     l2: 2.92115,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:122, step:3075 (TRAIN, VALID): total: 2053.69, 2054.55      recon: 2039.07, 2040.07,     kl: 11.71, 11.57,     l2: 2.91500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:123, step:3100 (TRAIN, VALID): total: 2053.55, 2054.72      recon: 2038.80, 2040.33,     kl: 11.84, 11.49,     l2: 2.90037,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:124, step:3125 (TRAIN, VALID): total: 2054.09, 2054.38      recon: 2039.43, 2039.90,     kl: 11.78, 11.60,     l2: 2.88348,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:125, step:3150 (TRAIN, VALID): total: 2054.72, 2056.30      recon: 2039.75, 2041.68,     kl: 12.09, 11.75,     l2: 2.87293,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:126, step:3175 (TRAIN, VALID): total: 2055.52, 2055.53      recon: 2040.50, 2041.07,     kl: 12.15, 11.59,     l2: 2.86021,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:127, step:3200 (TRAIN, VALID): total: 2053.38, 2054.10      recon: 2038.73, 2039.63,     kl: 11.80, 11.62,     l2: 2.85462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:128, step:3225 (TRAIN, VALID): total: 2054.05, 2053.54      recon: 2039.33, 2038.96,     kl: 11.87, 11.74,     l2: 2.83984,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:129, step:3250 (TRAIN, VALID): total: 2053.36, 2054.77      recon: 2038.72, 2040.58,     kl: 11.80, 11.36,     l2: 2.83730,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:130, step:3275 (TRAIN, VALID): total: 2053.93, 2056.03      recon: 2039.44, 2041.37,     kl: 11.67, 11.83,     l2: 2.82472,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:131, step:3300 (TRAIN, VALID): total: 2054.16, 2056.97      recon: 2039.51, 2042.54,     kl: 11.83, 11.61,     l2: 2.81782,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:132, step:3325 (TRAIN, VALID): total: 2054.51, 2054.25      recon: 2039.72, 2039.79,     kl: 11.97, 11.65,     l2: 2.81227,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:133, step:3350 (TRAIN, VALID): total: 2052.74, 2052.40      recon: 2037.96, 2037.60,     kl: 11.98, 11.99,     l2: 2.80640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:134, step:3375 (TRAIN, VALID): total: 2054.59, 2054.34      recon: 2039.94, 2039.81,     kl: 11.85, 11.74,     l2: 2.79479,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006302.\n",
      "Epoch:135, step:3400 (TRAIN, VALID): total: 2052.21, 2052.13      recon: 2037.65, 2037.79,     kl: 11.76, 11.56,     l2: 2.78861,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:136, step:3425 (TRAIN, VALID): total: 2051.63, 2051.34      recon: 2037.07, 2036.81,     kl: 11.77, 11.75,     l2: 2.77933,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:137, step:3450 (TRAIN, VALID): total: 2053.57, 2052.39      recon: 2038.86, 2037.91,     kl: 11.93, 11.71,     l2: 2.76560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:138, step:3475 (TRAIN, VALID): total: 2054.74, 2052.43      recon: 2040.23, 2038.17,     kl: 11.74, 11.50,     l2: 2.76191,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:139, step:3500 (TRAIN, VALID): total: 2052.52, 2055.04      recon: 2037.92, 2040.89,     kl: 11.84, 11.38,     l2: 2.76285,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:140, step:3525 (TRAIN, VALID): total: 2054.92, 2054.65      recon: 2040.31, 2040.18,     kl: 11.84, 11.70,     l2: 2.75827,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:141, step:3550 (TRAIN, VALID): total: 2054.91, 2052.28      recon: 2040.15, 2037.70,     kl: 12.00, 11.83,     l2: 2.75164,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:142, step:3575 (TRAIN, VALID): total: 2052.35, 2053.45      recon: 2037.67, 2038.99,     kl: 11.93, 11.72,     l2: 2.74462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:143, step:3600 (TRAIN, VALID): total: 2052.08, 2052.21      recon: 2037.66, 2038.02,     kl: 11.67, 11.46,     l2: 2.73819,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:144, step:3625 (TRAIN, VALID): total: 2053.37, 2056.20      recon: 2038.85, 2042.19,     kl: 11.78, 11.27,     l2: 2.73196,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:145, step:3650 (TRAIN, VALID): total: 2054.25, 2063.03      recon: 2039.61, 2048.35,     kl: 11.91, 11.95,     l2: 2.72935,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:146, step:3675 (TRAIN, VALID): total: 2058.09, 2057.67      recon: 2043.27, 2043.63,     kl: 12.09, 11.32,     l2: 2.72442,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005987.\n",
      "Epoch:147, step:3700 (TRAIN, VALID): total: 2053.68, 2054.08      recon: 2039.29, 2039.86,     kl: 11.66, 11.48,     l2: 2.73763,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:148, step:3725 (TRAIN, VALID): total: 2052.00, 2052.51      recon: 2037.54, 2038.21,     kl: 11.72, 11.56,     l2: 2.73960,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:149, step:3750 (TRAIN, VALID): total: 2051.04, 2051.04      recon: 2036.44, 2036.53,     kl: 11.87, 11.77,     l2: 2.73348,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:150, step:3775 (TRAIN, VALID): total: 2051.62, 2051.15      recon: 2037.09, 2036.99,     kl: 11.81, 11.43,     l2: 2.72511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:151, step:3800 (TRAIN, VALID): total: 2054.35, 2054.20      recon: 2039.87, 2040.19,     kl: 11.76, 11.29,     l2: 2.71477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:152, step:3825 (TRAIN, VALID): total: 2052.33, 2051.71      recon: 2037.89, 2037.24,     kl: 11.73, 11.75,     l2: 2.72109,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:153, step:3850 (TRAIN, VALID): total: 2051.33, 2052.45      recon: 2036.78, 2038.18,     kl: 11.83, 11.55,     l2: 2.71156,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:154, step:3875 (TRAIN, VALID): total: 2051.95, 2054.16      recon: 2037.53, 2039.81,     kl: 11.71, 11.65,     l2: 2.70672,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:155, step:3900 (TRAIN, VALID): total: 2052.76, 2054.26      recon: 2038.23, 2040.05,     kl: 11.82, 11.51,     l2: 2.69504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:156, step:3925 (TRAIN, VALID): total: 2052.62, 2051.78      recon: 2038.01, 2037.75,     kl: 11.91, 11.34,     l2: 2.69677,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:157, step:3950 (TRAIN, VALID): total: 2051.32, 2053.77      recon: 2036.70, 2039.38,     kl: 11.92, 11.69,     l2: 2.69690,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:158, step:3975 (TRAIN, VALID): total: 2054.03, 2053.30      recon: 2039.58, 2039.13,     kl: 11.76, 11.48,     l2: 2.69002,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005688.\n",
      "Epoch:159, step:4000 (TRAIN, VALID): total: 2052.07, 2051.60      recon: 2037.62, 2037.34,     kl: 11.75, 11.56,     l2: 2.69514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:160, step:4025 (TRAIN, VALID): total: 2052.46, 2051.77      recon: 2037.82, 2037.53,     kl: 11.95, 11.55,     l2: 2.69183,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:161, step:4050 (TRAIN, VALID): total: 2052.49, 2053.59      recon: 2037.95, 2039.18,     kl: 11.85, 11.72,     l2: 2.68795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:162, step:4075 (TRAIN, VALID): total: 2051.76, 2051.80      recon: 2037.31, 2037.64,     kl: 11.76, 11.47,     l2: 2.68910,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:163, step:4100 (TRAIN, VALID): total: 2051.83, 2053.87      recon: 2037.20, 2039.21,     kl: 11.94, 11.97,     l2: 2.68632,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:164, step:4125 (TRAIN, VALID): total: 2052.76, 2052.23      recon: 2037.98, 2037.87,     kl: 12.10, 11.68,     l2: 2.67591,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:165, step:4150 (TRAIN, VALID): total: 2051.15, 2052.67      recon: 2036.63, 2038.45,     kl: 11.84, 11.55,     l2: 2.67402,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:166, step:4175 (TRAIN, VALID): total: 2051.22, 2051.29      recon: 2036.62, 2036.91,     kl: 11.93, 11.71,     l2: 2.66948,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:167, step:4200 (TRAIN, VALID): total: 2050.36, 2050.52      recon: 2035.78, 2036.03,     kl: 11.91, 11.82,     l2: 2.66500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:168, step:4225 (TRAIN, VALID): total: 2050.39, 2052.23      recon: 2035.95, 2037.90,     kl: 11.78, 11.67,     l2: 2.65828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:169, step:4250 (TRAIN, VALID): total: 2050.61, 2052.40      recon: 2036.10, 2038.21,     kl: 11.86, 11.54,     l2: 2.64770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:170, step:4275 (TRAIN, VALID): total: 2050.67, 2050.85      recon: 2036.22, 2036.69,     kl: 11.80, 11.52,     l2: 2.64208,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:171, step:4300 (TRAIN, VALID): total: 2050.60, 2051.53      recon: 2036.14, 2037.38,     kl: 11.82, 11.52,     l2: 2.63238,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:172, step:4325 (TRAIN, VALID): total: 2050.46, 2050.79      recon: 2036.18, 2036.50,     kl: 11.65, 11.66,     l2: 2.63272,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:173, step:4350 (TRAIN, VALID): total: 2050.00, 2050.42      recon: 2035.51, 2036.23,     kl: 11.86, 11.56,     l2: 2.62988,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:174, step:4375 (TRAIN, VALID): total: 2050.39, 2051.29      recon: 2036.01, 2037.18,     kl: 11.75, 11.49,     l2: 2.61635,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:175, step:4400 (TRAIN, VALID): total: 2050.28, 2052.65      recon: 2035.90, 2038.57,     kl: 11.77, 11.46,     l2: 2.61693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:176, step:4425 (TRAIN, VALID): total: 2050.60, 2050.91      recon: 2036.23, 2036.85,     kl: 11.75, 11.45,     l2: 2.61273,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:177, step:4450 (TRAIN, VALID): total: 2050.12, 2050.79      recon: 2035.75, 2036.69,     kl: 11.77, 11.49,     l2: 2.60852,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:178, step:4475 (TRAIN, VALID): total: 2050.15, 2050.31      recon: 2035.61, 2036.20,     kl: 11.94, 11.51,     l2: 2.60152,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:179, step:4500 (TRAIN, VALID): total: 2052.16, 2054.23      recon: 2037.73, 2040.37,     kl: 11.83, 11.27,     l2: 2.59194,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005404.\n",
      "Epoch:180, step:4525 (TRAIN, VALID): total: 2050.49, 2052.55      recon: 2036.13, 2038.10,     kl: 11.77, 11.86,     l2: 2.59580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:181, step:4550 (TRAIN, VALID): total: 2051.20, 2051.27      recon: 2036.71, 2037.12,     kl: 11.89, 11.56,     l2: 2.59095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:182, step:4575 (TRAIN, VALID): total: 2049.24, 2050.58      recon: 2034.82, 2036.49,     kl: 11.84, 11.50,     l2: 2.59037,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:183, step:4600 (TRAIN, VALID): total: 2050.31, 2054.97      recon: 2035.91, 2040.76,     kl: 11.82, 11.63,     l2: 2.58286,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:184, step:4625 (TRAIN, VALID): total: 2051.23, 2053.01      recon: 2036.85, 2038.75,     kl: 11.80, 11.68,     l2: 2.57927,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:185, step:4650 (TRAIN, VALID): total: 2050.41, 2050.91      recon: 2035.98, 2036.63,     kl: 11.85, 11.70,     l2: 2.58204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:186, step:4675 (TRAIN, VALID): total: 2049.84, 2050.02      recon: 2035.38, 2035.80,     kl: 11.88, 11.65,     l2: 2.57878,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:187, step:4700 (TRAIN, VALID): total: 2050.45, 2051.74      recon: 2035.95, 2037.45,     kl: 11.92, 11.71,     l2: 2.57658,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:188, step:4725 (TRAIN, VALID): total: 2050.73, 2052.26      recon: 2036.07, 2037.99,     kl: 12.08, 11.70,     l2: 2.57274,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:189, step:4750 (TRAIN, VALID): total: 2050.40, 2051.58      recon: 2035.98, 2037.41,     kl: 11.85, 11.60,     l2: 2.57008,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:190, step:4775 (TRAIN, VALID): total: 2050.11, 2052.36      recon: 2035.73, 2038.23,     kl: 11.81, 11.56,     l2: 2.56992,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:191, step:4800 (TRAIN, VALID): total: 2049.99, 2051.03      recon: 2035.69, 2036.96,     kl: 11.73, 11.50,     l2: 2.56444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:192, step:4825 (TRAIN, VALID): total: 2050.28, 2051.12      recon: 2035.90, 2036.84,     kl: 11.82, 11.72,     l2: 2.56023,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:193, step:4850 (TRAIN, VALID): total: 2050.51, 2051.57      recon: 2036.06, 2036.85,     kl: 11.88, 12.16,     l2: 2.56074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:194, step:4875 (TRAIN, VALID): total: 2051.23, 2050.98      recon: 2036.52, 2036.57,     kl: 12.15, 11.85,     l2: 2.55901,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005133.\n",
      "Epoch:195, step:4900 (TRAIN, VALID): total: 2050.22, 2053.81      recon: 2035.80, 2039.55,     kl: 11.86, 11.70,     l2: 2.56318,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:196, step:4925 (TRAIN, VALID): total: 2050.57, 2052.27      recon: 2036.11, 2038.03,     kl: 11.89, 11.68,     l2: 2.56492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:197, step:4950 (TRAIN, VALID): total: 2050.78, 2051.08      recon: 2036.43, 2037.05,     kl: 11.79, 11.47,     l2: 2.55921,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:198, step:4975 (TRAIN, VALID): total: 2050.05, 2051.98      recon: 2035.67, 2037.96,     kl: 11.82, 11.45,     l2: 2.56636,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:199, step:5000 (TRAIN, VALID): total: 2049.63, 2049.49      recon: 2035.18, 2035.29,     kl: 11.89, 11.63,     l2: 2.56983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:200, step:5025 (TRAIN, VALID): total: 2049.14, 2049.82      recon: 2034.83, 2035.79,     kl: 11.74, 11.47,     l2: 2.56349,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:201, step:5050 (TRAIN, VALID): total: 2049.75, 2053.86      recon: 2035.31, 2039.58,     kl: 11.88, 11.72,     l2: 2.56313,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:202, step:5075 (TRAIN, VALID): total: 2050.89, 2050.44      recon: 2036.42, 2036.09,     kl: 11.91, 11.79,     l2: 2.55586,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004877.\n",
      "Epoch:203, step:5100 (TRAIN, VALID): total: 2050.22, 2051.06      recon: 2035.76, 2036.95,     kl: 11.90, 11.55,     l2: 2.55668,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:204, step:5125 (TRAIN, VALID): total: 2049.17, 2051.83      recon: 2034.73, 2037.13,     kl: 11.88, 12.14,     l2: 2.55815,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:205, step:5150 (TRAIN, VALID): total: 2049.84, 2050.37      recon: 2035.44, 2036.25,     kl: 11.85, 11.56,     l2: 2.55397,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:206, step:5175 (TRAIN, VALID): total: 2050.31, 2054.44      recon: 2035.98, 2040.59,     kl: 11.78, 11.30,     l2: 2.55542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:207, step:5200 (TRAIN, VALID): total: 2050.50, 2051.05      recon: 2036.17, 2036.88,     kl: 11.77, 11.61,     l2: 2.55657,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:208, step:5225 (TRAIN, VALID): total: 2049.41, 2049.54      recon: 2034.95, 2035.42,     kl: 11.90, 11.57,     l2: 2.55818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:209, step:5250 (TRAIN, VALID): total: 2048.70, 2050.63      recon: 2034.30, 2036.31,     kl: 11.85, 11.77,     l2: 2.55320,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:210, step:5275 (TRAIN, VALID): total: 2051.54, 2051.37      recon: 2036.82, 2037.20,     kl: 12.17, 11.63,     l2: 2.54596,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004633.\n",
      "Epoch:211, step:5300 (TRAIN, VALID): total: 2049.76, 2051.04      recon: 2035.39, 2036.66,     kl: 11.82, 11.83,     l2: 2.54856,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:212, step:5325 (TRAIN, VALID): total: 2049.15, 2049.56      recon: 2034.74, 2035.26,     kl: 11.86, 11.75,     l2: 2.55053,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:213, step:5350 (TRAIN, VALID): total: 2048.65, 2051.05      recon: 2034.27, 2036.70,     kl: 11.83, 11.81,     l2: 2.54751,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:214, step:5375 (TRAIN, VALID): total: 2048.57, 2049.24      recon: 2034.15, 2035.06,     kl: 11.87, 11.63,     l2: 2.54608,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:215, step:5400 (TRAIN, VALID): total: 2049.10, 2050.90      recon: 2034.72, 2036.74,     kl: 11.84, 11.62,     l2: 2.54335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:216, step:5425 (TRAIN, VALID): total: 2049.18, 2050.88      recon: 2034.76, 2036.74,     kl: 11.88, 11.60,     l2: 2.54483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:217, step:5450 (TRAIN, VALID): total: 2048.76, 2049.97      recon: 2034.49, 2036.02,     kl: 11.73, 11.42,     l2: 2.54345,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:218, step:5475 (TRAIN, VALID): total: 2048.82, 2050.25      recon: 2034.44, 2035.97,     kl: 11.84, 11.75,     l2: 2.53977,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:219, step:5500 (TRAIN, VALID): total: 2048.82, 2051.28      recon: 2034.32, 2036.64,     kl: 11.96, 12.10,     l2: 2.53825,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:220, step:5525 (TRAIN, VALID): total: 2049.34, 2051.06      recon: 2034.87, 2036.80,     kl: 11.93, 11.73,     l2: 2.53603,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004401.\n",
      "Epoch:221, step:5550 (TRAIN, VALID): total: 2049.02, 2050.33      recon: 2034.51, 2036.15,     kl: 11.97, 11.65,     l2: 2.53731,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:222, step:5575 (TRAIN, VALID): total: 2049.22, 2054.29      recon: 2034.77, 2039.91,     kl: 11.91, 11.85,     l2: 2.53559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:223, step:5600 (TRAIN, VALID): total: 2048.90, 2049.33      recon: 2034.47, 2035.09,     kl: 11.89, 11.71,     l2: 2.53458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:224, step:5625 (TRAIN, VALID): total: 2048.07, 2049.75      recon: 2033.80, 2035.42,     kl: 11.73, 11.79,     l2: 2.53526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:225, step:5650 (TRAIN, VALID): total: 2049.21, 2049.29      recon: 2034.57, 2035.00,     kl: 12.11, 11.75,     l2: 2.53508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:226, step:5675 (TRAIN, VALID): total: 2048.60, 2051.12      recon: 2034.17, 2036.62,     kl: 11.90, 11.97,     l2: 2.52885,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:227, step:5700 (TRAIN, VALID): total: 2048.22, 2050.29      recon: 2033.75, 2035.82,     kl: 11.94, 11.94,     l2: 2.52764,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:228, step:5725 (TRAIN, VALID): total: 2047.82, 2048.77      recon: 2033.45, 2034.63,     kl: 11.85, 11.62,     l2: 2.52634,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:229, step:5750 (TRAIN, VALID): total: 2048.09, 2051.98      recon: 2033.68, 2037.57,     kl: 11.88, 11.88,     l2: 2.52185,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:230, step:5775 (TRAIN, VALID): total: 2048.99, 2049.22      recon: 2034.52, 2035.03,     kl: 11.95, 11.67,     l2: 2.51953,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:231, step:5800 (TRAIN, VALID): total: 2048.70, 2050.78      recon: 2034.23, 2036.66,     kl: 11.95, 11.61,     l2: 2.51792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:232, step:5825 (TRAIN, VALID): total: 2048.18, 2050.93      recon: 2033.77, 2036.71,     kl: 11.90, 11.70,     l2: 2.51919,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:233, step:5850 (TRAIN, VALID): total: 2048.64, 2049.97      recon: 2034.29, 2036.00,     kl: 11.83, 11.46,     l2: 2.51642,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:234, step:5875 (TRAIN, VALID): total: 2048.81, 2050.35      recon: 2034.52, 2036.35,     kl: 11.77, 11.48,     l2: 2.51438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:235, step:5900 (TRAIN, VALID): total: 2048.12, 2049.58      recon: 2033.84, 2035.52,     kl: 11.77, 11.55,     l2: 2.51240,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:236, step:5925 (TRAIN, VALID): total: 2048.20, 2049.71      recon: 2033.88, 2035.64,     kl: 11.80, 11.56,     l2: 2.51301,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:237, step:5950 (TRAIN, VALID): total: 2048.93, 2052.77      recon: 2034.56, 2038.62,     kl: 11.86, 11.64,     l2: 2.51059,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004181.\n",
      "Epoch:238, step:5975 (TRAIN, VALID): total: 2049.69, 2051.02      recon: 2035.40, 2037.14,     kl: 11.78, 11.36,     l2: 2.51160,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:239, step:6000 (TRAIN, VALID): total: 2048.28, 2050.62      recon: 2033.96, 2036.25,     kl: 11.80, 11.85,     l2: 2.51636,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:240, step:6025 (TRAIN, VALID): total: 2048.35, 2051.13      recon: 2033.96, 2037.13,     kl: 11.88, 11.48,     l2: 2.51483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:241, step:6050 (TRAIN, VALID): total: 2048.04, 2049.46      recon: 2033.62, 2035.36,     kl: 11.90, 11.59,     l2: 2.51770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:242, step:6075 (TRAIN, VALID): total: 2048.52, 2051.28      recon: 2034.26, 2037.29,     kl: 11.75, 11.47,     l2: 2.51455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:243, step:6100 (TRAIN, VALID): total: 2048.60, 2049.00      recon: 2034.18, 2034.98,     kl: 11.90, 11.51,     l2: 2.51532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:244, step:6125 (TRAIN, VALID): total: 2047.95, 2049.94      recon: 2033.55, 2035.66,     kl: 11.88, 11.77,     l2: 2.51430,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:245, step:6150 (TRAIN, VALID): total: 2047.70, 2050.13      recon: 2033.29, 2036.14,     kl: 11.90, 11.48,     l2: 2.51294,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:246, step:6175 (TRAIN, VALID): total: 2047.46, 2049.35      recon: 2033.09, 2035.19,     kl: 11.86, 11.65,     l2: 2.51235,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:247, step:6200 (TRAIN, VALID): total: 2047.80, 2049.61      recon: 2033.45, 2035.54,     kl: 11.84, 11.57,     l2: 2.50576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:248, step:6225 (TRAIN, VALID): total: 2048.08, 2050.42      recon: 2033.80, 2036.35,     kl: 11.77, 11.57,     l2: 2.50647,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:249, step:6250 (TRAIN, VALID): total: 2047.98, 2049.23      recon: 2033.58, 2035.06,     kl: 11.90, 11.66,     l2: 2.50570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:250, step:6275 (TRAIN, VALID): total: 2047.44, 2050.66      recon: 2033.04, 2036.30,     kl: 11.89, 11.85,     l2: 2.50618,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:251, step:6300 (TRAIN, VALID): total: 2047.83, 2049.68      recon: 2033.40, 2035.50,     kl: 11.93, 11.68,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:252, step:6325 (TRAIN, VALID): total: 2047.88, 2050.59      recon: 2033.57, 2036.48,     kl: 11.81, 11.61,     l2: 2.50304,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:253, step:6350 (TRAIN, VALID): total: 2047.92, 2051.01      recon: 2033.50, 2036.85,     kl: 11.91, 11.66,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:254, step:6375 (TRAIN, VALID): total: 2049.30, 2051.79      recon: 2034.75, 2037.22,     kl: 12.05, 12.07,     l2: 2.50061,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003972.\n",
      "Epoch:255, step:6400 (TRAIN, VALID): total: 2049.15, 2051.76      recon: 2034.54, 2037.21,     kl: 12.11, 12.05,     l2: 2.50052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:256, step:6425 (TRAIN, VALID): total: 2049.50, 2055.74      recon: 2034.97, 2041.50,     kl: 12.03, 11.74,     l2: 2.49890,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:257, step:6450 (TRAIN, VALID): total: 2051.54, 2049.95      recon: 2037.14, 2035.61,     kl: 11.90, 11.83,     l2: 2.50043,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:258, step:6475 (TRAIN, VALID): total: 2048.29, 2050.26      recon: 2033.89, 2036.05,     kl: 11.89, 11.71,     l2: 2.50865,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:259, step:6500 (TRAIN, VALID): total: 2048.13, 2050.63      recon: 2033.68, 2036.22,     kl: 11.94, 11.90,     l2: 2.51186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:260, step:6525 (TRAIN, VALID): total: 2047.80, 2050.28      recon: 2033.32, 2035.90,     kl: 11.97, 11.87,     l2: 2.51188,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:261, step:6550 (TRAIN, VALID): total: 2047.38, 2048.39      recon: 2032.95, 2034.28,     kl: 11.92, 11.60,     l2: 2.51125,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:262, step:6575 (TRAIN, VALID): total: 2047.43, 2049.52      recon: 2033.04, 2035.25,     kl: 11.88, 11.76,     l2: 2.51090,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:263, step:6600 (TRAIN, VALID): total: 2047.74, 2050.23      recon: 2033.07, 2036.16,     kl: 12.17, 11.55,     l2: 2.51018,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:264, step:6625 (TRAIN, VALID): total: 2048.07, 2048.76      recon: 2033.67, 2034.55,     kl: 11.90, 11.70,     l2: 2.50776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:265, step:6650 (TRAIN, VALID): total: 2048.24, 2051.42      recon: 2033.71, 2037.16,     kl: 12.02, 11.76,     l2: 2.50451,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003774.\n",
      "Epoch:266, step:6675 (TRAIN, VALID): total: 2047.94, 2050.67      recon: 2033.53, 2036.13,     kl: 11.91, 12.04,     l2: 2.50510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:267, step:6700 (TRAIN, VALID): total: 2049.05, 2049.66      recon: 2034.58, 2035.42,     kl: 11.96, 11.74,     l2: 2.50390,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:268, step:6725 (TRAIN, VALID): total: 2048.73, 2050.87      recon: 2034.05, 2036.51,     kl: 12.17, 11.86,     l2: 2.50944,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:269, step:6750 (TRAIN, VALID): total: 2048.16, 2049.58      recon: 2033.76, 2035.33,     kl: 11.89, 11.74,     l2: 2.50939,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:270, step:6775 (TRAIN, VALID): total: 2049.02, 2050.21      recon: 2034.32, 2035.77,     kl: 12.18, 11.93,     l2: 2.51130,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:271, step:6800 (TRAIN, VALID): total: 2048.63, 2050.82      recon: 2034.19, 2036.54,     kl: 11.93, 11.77,     l2: 2.50963,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:272, step:6825 (TRAIN, VALID): total: 2047.50, 2048.91      recon: 2033.03, 2034.84,     kl: 11.96, 11.56,     l2: 2.51249,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:273, step:6850 (TRAIN, VALID): total: 2047.61, 2049.83      recon: 2033.12, 2035.62,     kl: 11.97, 11.70,     l2: 2.51427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:274, step:6875 (TRAIN, VALID): total: 2047.24, 2048.76      recon: 2032.76, 2034.55,     kl: 11.96, 11.70,     l2: 2.51340,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:275, step:6900 (TRAIN, VALID): total: 2047.72, 2050.43      recon: 2033.22, 2036.16,     kl: 11.99, 11.75,     l2: 2.51394,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:276, step:6925 (TRAIN, VALID): total: 2047.39, 2049.80      recon: 2032.87, 2035.48,     kl: 12.00, 11.82,     l2: 2.50920,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:277, step:6950 (TRAIN, VALID): total: 2047.46, 2050.43      recon: 2033.01, 2036.10,     kl: 11.94, 11.82,     l2: 2.51225,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:278, step:6975 (TRAIN, VALID): total: 2048.17, 2049.82      recon: 2033.67, 2035.52,     kl: 11.99, 11.79,     l2: 2.50795,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003585.\n",
      "Epoch:279, step:7000 (TRAIN, VALID): total: 2047.24, 2047.63      recon: 2032.73, 2033.38,     kl: 12.00, 11.75,     l2: 2.51031,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:280, step:7025 (TRAIN, VALID): total: 2048.18, 2050.62      recon: 2033.65, 2036.30,     kl: 12.02, 11.82,     l2: 2.50647,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:281, step:7050 (TRAIN, VALID): total: 2047.79, 2048.72      recon: 2033.21, 2034.37,     kl: 12.07, 11.84,     l2: 2.50903,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:282, step:7075 (TRAIN, VALID): total: 2047.12, 2050.29      recon: 2032.70, 2035.96,     kl: 11.92, 11.82,     l2: 2.50923,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:283, step:7100 (TRAIN, VALID): total: 2047.03, 2049.93      recon: 2032.62, 2035.61,     kl: 11.90, 11.82,     l2: 2.50669,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:284, step:7125 (TRAIN, VALID): total: 2047.73, 2048.98      recon: 2033.18, 2034.70,     kl: 12.04, 11.77,     l2: 2.50629,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:285, step:7150 (TRAIN, VALID): total: 2046.96, 2049.17      recon: 2032.46, 2034.91,     kl: 11.99, 11.76,     l2: 2.50479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:286, step:7175 (TRAIN, VALID): total: 2047.39, 2050.34      recon: 2032.83, 2036.00,     kl: 12.06, 11.83,     l2: 2.50354,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:287, step:7200 (TRAIN, VALID): total: 2047.13, 2048.67      recon: 2032.64, 2034.54,     kl: 11.99, 11.63,     l2: 2.50359,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:288, step:7225 (TRAIN, VALID): total: 2047.33, 2048.75      recon: 2032.90, 2034.53,     kl: 11.92, 11.71,     l2: 2.50254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:289, step:7250 (TRAIN, VALID): total: 2047.54, 2048.82      recon: 2033.12, 2034.08,     kl: 11.92, 12.24,     l2: 2.50101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:290, step:7275 (TRAIN, VALID): total: 2048.09, 2049.34      recon: 2033.37, 2035.09,     kl: 12.22, 11.76,     l2: 2.49885,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003406.\n",
      "Epoch:291, step:7300 (TRAIN, VALID): total: 2047.15, 2049.11      recon: 2032.80, 2035.05,     kl: 11.86, 11.55,     l2: 2.50147,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:292, step:7325 (TRAIN, VALID): total: 2046.90, 2048.83      recon: 2032.55, 2034.62,     kl: 11.85, 11.71,     l2: 2.50088,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:293, step:7350 (TRAIN, VALID): total: 2047.08, 2047.40      recon: 2032.63, 2033.15,     kl: 11.94, 11.75,     l2: 2.50131,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:294, step:7375 (TRAIN, VALID): total: 2046.75, 2050.83      recon: 2032.33, 2036.65,     kl: 11.91, 11.68,     l2: 2.50138,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:295, step:7400 (TRAIN, VALID): total: 2047.72, 2049.88      recon: 2033.29, 2035.48,     kl: 11.93, 11.90,     l2: 2.49990,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:296, step:7425 (TRAIN, VALID): total: 2047.22, 2048.34      recon: 2032.78, 2034.11,     kl: 11.94, 11.73,     l2: 2.50226,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:297, step:7450 (TRAIN, VALID): total: 2047.32, 2049.12      recon: 2032.90, 2034.87,     kl: 11.92, 11.75,     l2: 2.50253,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:298, step:7475 (TRAIN, VALID): total: 2046.63, 2047.86      recon: 2032.26, 2033.87,     kl: 11.87, 11.48,     l2: 2.50413,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:299, step:7500 (TRAIN, VALID): total: 2047.61, 2049.71      recon: 2033.20, 2035.44,     kl: 11.91, 11.77,     l2: 2.50249,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:300, step:7525 (TRAIN, VALID): total: 2047.00, 2048.30      recon: 2032.56, 2034.07,     kl: 11.94, 11.72,     l2: 2.50494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:301, step:7550 (TRAIN, VALID): total: 2046.67, 2049.90      recon: 2032.30, 2035.70,     kl: 11.86, 11.70,     l2: 2.50241,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:302, step:7575 (TRAIN, VALID): total: 2047.08, 2050.37      recon: 2032.67, 2036.15,     kl: 11.91, 11.72,     l2: 2.50066,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:303, step:7600 (TRAIN, VALID): total: 2047.54, 2057.28      recon: 2033.10, 2042.91,     kl: 11.94, 11.87,     l2: 2.49964,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:304, step:7625 (TRAIN, VALID): total: 2049.10, 2049.27      recon: 2034.75, 2035.16,     kl: 11.85, 11.60,     l2: 2.50088,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003235.\n",
      "Epoch:305, step:7650 (TRAIN, VALID): total: 2046.87, 2049.45      recon: 2032.51, 2035.35,     kl: 11.85, 11.59,     l2: 2.50567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:306, step:7675 (TRAIN, VALID): total: 2046.47, 2047.69      recon: 2032.12, 2033.44,     kl: 11.84, 11.75,     l2: 2.50798,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:307, step:7700 (TRAIN, VALID): total: 2047.25, 2048.69      recon: 2032.80, 2034.60,     kl: 11.95, 11.59,     l2: 2.50694,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:308, step:7725 (TRAIN, VALID): total: 2046.66, 2049.12      recon: 2032.24, 2034.92,     kl: 11.91, 11.69,     l2: 2.50499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:309, step:7750 (TRAIN, VALID): total: 2046.79, 2047.06      recon: 2032.27, 2032.83,     kl: 12.02, 11.73,     l2: 2.50619,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:310, step:7775 (TRAIN, VALID): total: 2047.66, 2048.55      recon: 2033.11, 2034.22,     kl: 12.04, 11.82,     l2: 2.50727,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:311, step:7800 (TRAIN, VALID): total: 2047.26, 2048.58      recon: 2032.82, 2034.37,     kl: 11.93, 11.71,     l2: 2.50610,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:312, step:7825 (TRAIN, VALID): total: 2046.81, 2049.14      recon: 2032.35, 2035.02,     kl: 11.95, 11.61,     l2: 2.50944,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:313, step:7850 (TRAIN, VALID): total: 2046.95, 2050.41      recon: 2032.43, 2035.93,     kl: 12.02, 11.97,     l2: 2.50860,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:314, step:7875 (TRAIN, VALID): total: 2046.90, 2048.48      recon: 2032.40, 2034.25,     kl: 12.00, 11.72,     l2: 2.50808,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:315, step:7900 (TRAIN, VALID): total: 2046.98, 2049.51      recon: 2032.48, 2035.26,     kl: 11.99, 11.74,     l2: 2.50692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:316, step:7925 (TRAIN, VALID): total: 2046.56, 2048.53      recon: 2032.12, 2034.37,     kl: 11.93, 11.65,     l2: 2.50871,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:317, step:7950 (TRAIN, VALID): total: 2046.69, 2048.50      recon: 2032.26, 2034.17,     kl: 11.92, 11.82,     l2: 2.50594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:318, step:7975 (TRAIN, VALID): total: 2046.60, 2049.94      recon: 2032.10, 2035.72,     kl: 11.99, 11.72,     l2: 2.50640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:319, step:8000 (TRAIN, VALID): total: 2046.46, 2047.92      recon: 2032.06, 2033.72,     kl: 11.90, 11.69,     l2: 2.50624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:320, step:8025 (TRAIN, VALID): total: 2046.33, 2048.93      recon: 2031.95, 2034.89,     kl: 11.88, 11.53,     l2: 2.50420,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:321, step:8050 (TRAIN, VALID): total: 2046.33, 2047.04      recon: 2031.89, 2032.82,     kl: 11.94, 11.71,     l2: 2.50702,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:322, step:8075 (TRAIN, VALID): total: 2046.81, 2052.28      recon: 2032.39, 2038.06,     kl: 11.91, 11.72,     l2: 2.50331,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.003074.\n",
      "Epoch:323, step:8100 (TRAIN, VALID): total: 2046.66, 2047.90      recon: 2032.23, 2033.77,     kl: 11.92, 11.63,     l2: 2.50569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:324, step:8125 (TRAIN, VALID): total: 2046.15, 2049.75      recon: 2031.80, 2035.39,     kl: 11.85, 11.85,     l2: 2.50510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:325, step:8150 (TRAIN, VALID): total: 2046.30, 2049.19      recon: 2031.79, 2035.02,     kl: 12.00, 11.67,     l2: 2.50570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:326, step:8175 (TRAIN, VALID): total: 2046.04, 2049.43      recon: 2031.62, 2035.12,     kl: 11.91, 11.81,     l2: 2.50182,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:327, step:8200 (TRAIN, VALID): total: 2046.06, 2048.38      recon: 2031.61, 2034.05,     kl: 11.95, 11.83,     l2: 2.49981,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:328, step:8225 (TRAIN, VALID): total: 2047.11, 2048.95      recon: 2032.53, 2034.62,     kl: 12.09, 11.83,     l2: 2.49983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:329, step:8250 (TRAIN, VALID): total: 2047.13, 2049.28      recon: 2032.75, 2035.13,     kl: 11.88, 11.65,     l2: 2.49968,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002920.\n",
      "Epoch:330, step:8275 (TRAIN, VALID): total: 2046.65, 2048.95      recon: 2032.33, 2034.74,     kl: 11.82, 11.71,     l2: 2.50133,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:331, step:8300 (TRAIN, VALID): total: 2047.28, 2048.88      recon: 2032.73, 2034.60,     kl: 12.05, 11.78,     l2: 2.50321,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:332, step:8325 (TRAIN, VALID): total: 2046.21, 2047.87      recon: 2031.77, 2033.57,     kl: 11.94, 11.80,     l2: 2.50607,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:333, step:8350 (TRAIN, VALID): total: 2046.03, 2047.91      recon: 2031.56, 2033.77,     kl: 11.96, 11.63,     l2: 2.50518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:334, step:8375 (TRAIN, VALID): total: 2046.23, 2048.31      recon: 2031.75, 2034.21,     kl: 11.98, 11.60,     l2: 2.50427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:335, step:8400 (TRAIN, VALID): total: 2046.21, 2048.84      recon: 2031.75, 2034.55,     kl: 11.95, 11.79,     l2: 2.50514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:336, step:8425 (TRAIN, VALID): total: 2046.90, 2048.82      recon: 2032.37, 2034.31,     kl: 12.03, 12.01,     l2: 2.50325,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:337, step:8450 (TRAIN, VALID): total: 2046.27, 2049.89      recon: 2031.81, 2035.39,     kl: 11.96, 12.00,     l2: 2.50283,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:338, step:8475 (TRAIN, VALID): total: 2046.38, 2049.58      recon: 2031.96, 2035.35,     kl: 11.91, 11.73,     l2: 2.50170,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:339, step:8500 (TRAIN, VALID): total: 2046.21, 2048.15      recon: 2031.80, 2033.91,     kl: 11.91, 11.73,     l2: 2.50116,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:340, step:8525 (TRAIN, VALID): total: 2045.94, 2047.28      recon: 2031.45, 2033.14,     kl: 11.98, 11.65,     l2: 2.50174,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:341, step:8550 (TRAIN, VALID): total: 2046.28, 2048.11      recon: 2031.82, 2033.63,     kl: 11.96, 11.97,     l2: 2.50127,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:342, step:8575 (TRAIN, VALID): total: 2046.46, 2048.74      recon: 2031.98, 2034.43,     kl: 11.98, 11.81,     l2: 2.50281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:343, step:8600 (TRAIN, VALID): total: 2046.34, 2048.72      recon: 2031.86, 2034.45,     kl: 11.98, 11.77,     l2: 2.50136,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:344, step:8625 (TRAIN, VALID): total: 2046.20, 2048.67      recon: 2031.78, 2034.50,     kl: 11.91, 11.67,     l2: 2.50270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:345, step:8650 (TRAIN, VALID): total: 2046.61, 2048.28      recon: 2032.17, 2033.97,     kl: 11.94, 11.81,     l2: 2.50240,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002774.\n",
      "Epoch:346, step:8675 (TRAIN, VALID): total: 2046.16, 2049.86      recon: 2031.74, 2035.66,     kl: 11.92, 11.70,     l2: 2.50354,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:347, step:8700 (TRAIN, VALID): total: 2046.61, 2048.61      recon: 2032.17, 2034.36,     kl: 11.94, 11.74,     l2: 2.49998,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:348, step:8725 (TRAIN, VALID): total: 2045.89, 2048.79      recon: 2031.48, 2034.61,     kl: 11.92, 11.68,     l2: 2.50031,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:349, step:8750 (TRAIN, VALID): total: 2045.79, 2047.50      recon: 2031.37, 2033.28,     kl: 11.92, 11.72,     l2: 2.50019,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:350, step:8775 (TRAIN, VALID): total: 2046.34, 2048.46      recon: 2031.85, 2034.04,     kl: 11.99, 11.92,     l2: 2.50057,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:351, step:8800 (TRAIN, VALID): total: 2046.09, 2049.48      recon: 2031.59, 2035.12,     kl: 12.00, 11.86,     l2: 2.49587,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:352, step:8825 (TRAIN, VALID): total: 2047.21, 2049.37      recon: 2032.39, 2034.94,     kl: 12.32, 11.93,     l2: 2.49690,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002635.\n",
      "Epoch:353, step:8850 (TRAIN, VALID): total: 2046.38, 2047.60      recon: 2031.86, 2033.32,     kl: 12.02, 11.78,     l2: 2.49818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:354, step:8875 (TRAIN, VALID): total: 2045.69, 2049.45      recon: 2031.35, 2035.25,     kl: 11.84, 11.70,     l2: 2.49926,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:355, step:8900 (TRAIN, VALID): total: 2046.06, 2048.38      recon: 2031.60, 2034.00,     kl: 11.96, 11.89,     l2: 2.49747,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:356, step:8925 (TRAIN, VALID): total: 2045.82, 2047.75      recon: 2031.39, 2033.69,     kl: 11.93, 11.57,     l2: 2.49711,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:357, step:8950 (TRAIN, VALID): total: 2046.05, 2049.27      recon: 2031.68, 2035.16,     kl: 11.88, 11.61,     l2: 2.49793,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:358, step:8975 (TRAIN, VALID): total: 2045.83, 2048.13      recon: 2031.40, 2033.97,     kl: 11.93, 11.67,     l2: 2.49823,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:359, step:9000 (TRAIN, VALID): total: 2045.95, 2047.85      recon: 2031.45, 2033.62,     kl: 12.00, 11.73,     l2: 2.49872,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:360, step:9025 (TRAIN, VALID): total: 2045.79, 2049.35      recon: 2031.40, 2035.15,     kl: 11.88, 11.71,     l2: 2.49839,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:361, step:9050 (TRAIN, VALID): total: 2046.81, 2048.87      recon: 2032.19, 2034.67,     kl: 12.13, 11.70,     l2: 2.49866,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002503.\n",
      "Epoch:362, step:9075 (TRAIN, VALID): total: 2047.18, 2048.33      recon: 2032.69, 2034.10,     kl: 11.99, 11.74,     l2: 2.49657,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:363, step:9100 (TRAIN, VALID): total: 2045.91, 2049.18      recon: 2031.49, 2034.97,     kl: 11.92, 11.72,     l2: 2.49838,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:364, step:9125 (TRAIN, VALID): total: 2045.96, 2048.28      recon: 2031.58, 2033.96,     kl: 11.87, 11.82,     l2: 2.49986,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:365, step:9150 (TRAIN, VALID): total: 2045.71, 2048.21      recon: 2031.22, 2033.82,     kl: 11.99, 11.90,     l2: 2.50036,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:366, step:9175 (TRAIN, VALID): total: 2045.57, 2047.68      recon: 2031.10, 2033.36,     kl: 11.97, 11.82,     l2: 2.49785,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:367, step:9200 (TRAIN, VALID): total: 2046.20, 2049.54      recon: 2031.53, 2035.16,     kl: 12.17, 11.88,     l2: 2.49728,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:368, step:9225 (TRAIN, VALID): total: 2045.81, 2048.23      recon: 2031.34, 2034.03,     kl: 11.98, 11.70,     l2: 2.49749,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:369, step:9250 (TRAIN, VALID): total: 2045.93, 2049.21      recon: 2031.52, 2035.13,     kl: 11.92, 11.58,     l2: 2.49763,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:370, step:9275 (TRAIN, VALID): total: 2045.47, 2047.32      recon: 2031.10, 2033.08,     kl: 11.87, 11.74,     l2: 2.49828,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:371, step:9300 (TRAIN, VALID): total: 2045.52, 2048.15      recon: 2031.06, 2033.77,     kl: 11.96, 11.89,     l2: 2.49930,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:372, step:9325 (TRAIN, VALID): total: 2045.69, 2048.68      recon: 2031.23, 2034.63,     kl: 11.97, 11.55,     l2: 2.49776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:373, step:9350 (TRAIN, VALID): total: 2046.04, 2048.53      recon: 2031.55, 2034.34,     kl: 12.00, 11.69,     l2: 2.49795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:374, step:9375 (TRAIN, VALID): total: 2045.58, 2048.25      recon: 2031.21, 2033.96,     kl: 11.88, 11.79,     l2: 2.49779,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:375, step:9400 (TRAIN, VALID): total: 2045.93, 2047.96      recon: 2031.39, 2033.72,     kl: 12.04, 11.74,     l2: 2.49698,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:376, step:9425 (TRAIN, VALID): total: 2046.15, 2048.80      recon: 2031.62, 2034.44,     kl: 12.03, 11.87,     l2: 2.49865,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002378.\n",
      "Epoch:377, step:9450 (TRAIN, VALID): total: 2045.55, 2047.01      recon: 2031.07, 2032.64,     kl: 11.98, 11.86,     l2: 2.49762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:378, step:9475 (TRAIN, VALID): total: 2045.26, 2047.32      recon: 2030.75, 2033.09,     kl: 12.01, 11.73,     l2: 2.49770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:379, step:9500 (TRAIN, VALID): total: 2045.16, 2047.77      recon: 2030.71, 2033.60,     kl: 11.95, 11.68,     l2: 2.49713,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:380, step:9525 (TRAIN, VALID): total: 2045.50, 2047.05      recon: 2031.09, 2032.99,     kl: 11.91, 11.57,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:381, step:9550 (TRAIN, VALID): total: 2045.49, 2048.43      recon: 2031.14, 2034.35,     kl: 11.86, 11.58,     l2: 2.49728,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:382, step:9575 (TRAIN, VALID): total: 2046.20, 2049.09      recon: 2031.61, 2034.72,     kl: 12.10, 11.88,     l2: 2.49773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:383, step:9600 (TRAIN, VALID): total: 2045.46, 2047.97      recon: 2030.95, 2033.69,     kl: 12.01, 11.78,     l2: 2.49589,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:384, step:9625 (TRAIN, VALID): total: 2045.25, 2047.44      recon: 2030.82, 2033.18,     kl: 11.93, 11.76,     l2: 2.49624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:385, step:9650 (TRAIN, VALID): total: 2045.45, 2047.70      recon: 2030.99, 2033.45,     kl: 11.96, 11.76,     l2: 2.49377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:386, step:9675 (TRAIN, VALID): total: 2045.22, 2047.81      recon: 2030.82, 2033.70,     kl: 11.90, 11.62,     l2: 2.49450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:387, step:9700 (TRAIN, VALID): total: 2045.42, 2047.05      recon: 2030.92, 2032.72,     kl: 12.00, 11.84,     l2: 2.49536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:388, step:9725 (TRAIN, VALID): total: 2045.80, 2048.22      recon: 2031.31, 2033.75,     kl: 11.99, 11.97,     l2: 2.49416,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:389, step:9750 (TRAIN, VALID): total: 2045.65, 2047.21      recon: 2031.20, 2033.06,     kl: 11.96, 11.65,     l2: 2.49583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:390, step:9775 (TRAIN, VALID): total: 2045.40, 2048.75      recon: 2031.05, 2034.59,     kl: 11.86, 11.66,     l2: 2.49562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:391, step:9800 (TRAIN, VALID): total: 2045.30, 2048.01      recon: 2030.88, 2033.71,     kl: 11.93, 11.81,     l2: 2.49479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:392, step:9825 (TRAIN, VALID): total: 2045.89, 2048.15      recon: 2031.32, 2034.02,     kl: 12.08, 11.64,     l2: 2.49425,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002259.\n",
      "Epoch:393, step:9850 (TRAIN, VALID): total: 2046.18, 2047.79      recon: 2031.72, 2033.45,     kl: 11.96, 11.84,     l2: 2.49426,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:394, step:9875 (TRAIN, VALID): total: 2045.15, 2047.64      recon: 2030.72, 2033.44,     kl: 11.93, 11.70,     l2: 2.49577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:395, step:9900 (TRAIN, VALID): total: 2045.22, 2047.44      recon: 2030.81, 2033.33,     kl: 11.92, 11.61,     l2: 2.49464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:396, step:9925 (TRAIN, VALID): total: 2045.22, 2048.99      recon: 2030.77, 2034.73,     kl: 11.95, 11.76,     l2: 2.49391,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:397, step:9950 (TRAIN, VALID): total: 2045.20, 2048.49      recon: 2030.78, 2034.38,     kl: 11.93, 11.62,     l2: 2.49431,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:398, step:9975 (TRAIN, VALID): total: 2045.20, 2048.57      recon: 2030.78, 2034.40,     kl: 11.92, 11.68,     l2: 2.49542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:399, step:10000 (TRAIN, VALID): total: 2046.01, 2049.03      recon: 2031.49, 2034.77,     kl: 12.02, 11.76,     l2: 2.49450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:400, step:10025 (TRAIN, VALID): total: 2045.68, 2048.01      recon: 2031.19, 2033.72,     kl: 11.99, 11.80,     l2: 2.49311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:401, step:10050 (TRAIN, VALID): total: 2045.05, 2047.62      recon: 2030.69, 2033.59,     kl: 11.86, 11.54,     l2: 2.49611,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:402, step:10075 (TRAIN, VALID): total: 2045.73, 2048.01      recon: 2031.27, 2033.95,     kl: 11.96, 11.56,     l2: 2.49627,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:403, step:10100 (TRAIN, VALID): total: 2045.64, 2048.20      recon: 2030.98, 2033.93,     kl: 12.16, 11.78,     l2: 2.49437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:404, step:10125 (TRAIN, VALID): total: 2045.25, 2048.47      recon: 2030.80, 2034.31,     kl: 11.96, 11.67,     l2: 2.49400,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:405, step:10150 (TRAIN, VALID): total: 2045.37, 2047.98      recon: 2030.94, 2033.77,     kl: 11.93, 11.72,     l2: 2.49464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:406, step:10175 (TRAIN, VALID): total: 2045.24, 2047.55      recon: 2030.82, 2033.36,     kl: 11.92, 11.69,     l2: 2.49575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:407, step:10200 (TRAIN, VALID): total: 2045.13, 2047.53      recon: 2030.73, 2033.42,     kl: 11.91, 11.61,     l2: 2.49648,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:408, step:10225 (TRAIN, VALID): total: 2045.62, 2047.92      recon: 2031.03, 2033.62,     kl: 12.10, 11.80,     l2: 2.49550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:409, step:10250 (TRAIN, VALID): total: 2045.52, 2049.00      recon: 2031.12, 2034.68,     kl: 11.90, 11.83,     l2: 2.49575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:410, step:10275 (TRAIN, VALID): total: 2045.49, 2049.19      recon: 2030.88, 2034.99,     kl: 12.11, 11.70,     l2: 2.49794,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:411, step:10300 (TRAIN, VALID): total: 2045.37, 2048.63      recon: 2030.93, 2034.38,     kl: 11.95, 11.75,     l2: 2.49757,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:412, step:10325 (TRAIN, VALID): total: 2046.71, 2049.04      recon: 2032.22, 2034.80,     kl: 12.00, 11.74,     l2: 2.49580,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002146.\n",
      "Epoch:413, step:10350 (TRAIN, VALID): total: 2045.75, 2047.96      recon: 2031.29, 2033.45,     kl: 11.97, 12.02,     l2: 2.49548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:414, step:10375 (TRAIN, VALID): total: 2045.85, 2047.35      recon: 2031.24, 2033.06,     kl: 12.11, 11.80,     l2: 2.49542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:415, step:10400 (TRAIN, VALID): total: 2045.22, 2047.55      recon: 2030.75, 2033.27,     kl: 11.97, 11.79,     l2: 2.49643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:416, step:10425 (TRAIN, VALID): total: 2045.17, 2046.88      recon: 2030.67, 2032.70,     kl: 12.00, 11.68,     l2: 2.49750,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:417, step:10450 (TRAIN, VALID): total: 2045.13, 2049.42      recon: 2030.70, 2035.16,     kl: 11.93, 11.76,     l2: 2.49866,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:418, step:10475 (TRAIN, VALID): total: 2045.18, 2048.04      recon: 2030.87, 2033.85,     kl: 11.82, 11.70,     l2: 2.49805,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:419, step:10500 (TRAIN, VALID): total: 2045.40, 2048.53      recon: 2030.80, 2034.34,     kl: 12.10, 11.68,     l2: 2.49894,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:420, step:10525 (TRAIN, VALID): total: 2044.89, 2049.01      recon: 2030.43, 2034.71,     kl: 11.96, 11.80,     l2: 2.49811,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:421, step:10550 (TRAIN, VALID): total: 2046.06, 2048.87      recon: 2031.49, 2034.62,     kl: 12.07, 11.75,     l2: 2.49787,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002039.\n",
      "Epoch:422, step:10575 (TRAIN, VALID): total: 2045.53, 2047.97      recon: 2031.01, 2033.71,     kl: 12.02, 11.76,     l2: 2.49847,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:423, step:10600 (TRAIN, VALID): total: 2045.19, 2048.31      recon: 2030.61, 2033.97,     kl: 12.08, 11.84,     l2: 2.49810,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:424, step:10625 (TRAIN, VALID): total: 2044.99, 2047.12      recon: 2030.41, 2032.75,     kl: 12.08, 11.88,     l2: 2.49740,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:425, step:10650 (TRAIN, VALID): total: 2044.79, 2048.48      recon: 2030.39, 2034.34,     kl: 11.91, 11.64,     l2: 2.49842,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:426, step:10675 (TRAIN, VALID): total: 2044.97, 2047.77      recon: 2030.53, 2033.55,     kl: 11.94, 11.73,     l2: 2.49680,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:427, step:10700 (TRAIN, VALID): total: 2045.09, 2048.26      recon: 2030.65, 2034.03,     kl: 11.94, 11.74,     l2: 2.49684,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:428, step:10725 (TRAIN, VALID): total: 2045.29, 2048.53      recon: 2030.81, 2034.32,     kl: 11.98, 11.71,     l2: 2.49774,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:429, step:10750 (TRAIN, VALID): total: 2044.89, 2047.99      recon: 2030.41, 2033.77,     kl: 11.98, 11.72,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:430, step:10775 (TRAIN, VALID): total: 2045.02, 2047.13      recon: 2030.57, 2033.00,     kl: 11.95, 11.63,     l2: 2.49600,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:431, step:10800 (TRAIN, VALID): total: 2044.95, 2047.63      recon: 2030.48, 2033.48,     kl: 11.97, 11.66,     l2: 2.49773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:432, step:10825 (TRAIN, VALID): total: 2045.50, 2048.46      recon: 2030.98, 2034.03,     kl: 12.02, 11.93,     l2: 2.49700,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001937.\n",
      "Epoch:433, step:10850 (TRAIN, VALID): total: 2045.33, 2047.36      recon: 2030.81, 2033.13,     kl: 12.03, 11.73,     l2: 2.49648,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:434, step:10875 (TRAIN, VALID): total: 2045.01, 2047.53      recon: 2030.53, 2033.20,     kl: 11.98, 11.83,     l2: 2.49576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:435, step:10900 (TRAIN, VALID): total: 2044.86, 2048.23      recon: 2030.33, 2033.78,     kl: 12.03, 11.96,     l2: 2.49680,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:436, step:10925 (TRAIN, VALID): total: 2044.95, 2047.87      recon: 2030.39, 2033.62,     kl: 12.06, 11.75,     l2: 2.49692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:437, step:10950 (TRAIN, VALID): total: 2044.95, 2048.48      recon: 2030.55, 2033.84,     kl: 11.90, 12.14,     l2: 2.49742,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:438, step:10975 (TRAIN, VALID): total: 2045.60, 2047.58      recon: 2030.76, 2033.32,     kl: 12.34, 11.76,     l2: 2.49577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:439, step:11000 (TRAIN, VALID): total: 2045.03, 2048.05      recon: 2030.59, 2033.72,     kl: 11.94, 11.83,     l2: 2.49609,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:440, step:11025 (TRAIN, VALID): total: 2044.97, 2046.27      recon: 2030.44, 2031.99,     kl: 12.04, 11.79,     l2: 2.49539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:441, step:11050 (TRAIN, VALID): total: 2045.11, 2046.98      recon: 2030.47, 2032.71,     kl: 12.14, 11.77,     l2: 2.49656,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:442, step:11075 (TRAIN, VALID): total: 2045.00, 2048.26      recon: 2030.49, 2033.99,     kl: 12.02, 11.77,     l2: 2.49669,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:443, step:11100 (TRAIN, VALID): total: 2044.88, 2047.80      recon: 2030.40, 2033.47,     kl: 11.98, 11.84,     l2: 2.49717,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:444, step:11125 (TRAIN, VALID): total: 2044.69, 2048.39      recon: 2030.31, 2034.14,     kl: 11.89, 11.75,     l2: 2.49625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:445, step:11150 (TRAIN, VALID): total: 2044.73, 2047.19      recon: 2030.29, 2033.00,     kl: 11.94, 11.69,     l2: 2.49839,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:446, step:11175 (TRAIN, VALID): total: 2044.70, 2048.76      recon: 2030.33, 2034.59,     kl: 11.87, 11.68,     l2: 2.49710,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:447, step:11200 (TRAIN, VALID): total: 2044.73, 2048.90      recon: 2030.27, 2034.60,     kl: 11.96, 11.80,     l2: 2.49805,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:448, step:11225 (TRAIN, VALID): total: 2045.09, 2045.98      recon: 2030.60, 2031.74,     kl: 11.99, 11.75,     l2: 2.49703,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001840.\n",
      "Epoch:449, step:11250 (TRAIN, VALID): total: 2045.32, 2047.97      recon: 2030.74, 2033.66,     kl: 12.09, 11.81,     l2: 2.49887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:450, step:11275 (TRAIN, VALID): total: 2044.95, 2049.01      recon: 2030.44, 2034.74,     kl: 12.02, 11.77,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:451, step:11300 (TRAIN, VALID): total: 2045.17, 2047.59      recon: 2030.68, 2033.34,     kl: 11.99, 11.76,     l2: 2.49841,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:452, step:11325 (TRAIN, VALID): total: 2044.60, 2047.53      recon: 2030.18, 2033.22,     kl: 11.92, 11.81,     l2: 2.49751,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:453, step:11350 (TRAIN, VALID): total: 2044.65, 2047.65      recon: 2030.16, 2033.36,     kl: 11.99, 11.79,     l2: 2.49906,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:454, step:11375 (TRAIN, VALID): total: 2045.89, 2049.44      recon: 2031.29, 2035.00,     kl: 12.09, 11.94,     l2: 2.49745,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:455, step:11400 (TRAIN, VALID): total: 2045.10, 2047.29      recon: 2030.58, 2032.95,     kl: 12.02, 11.85,     l2: 2.49620,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:456, step:11425 (TRAIN, VALID): total: 2044.89, 2046.98      recon: 2030.37, 2032.79,     kl: 12.03, 11.70,     l2: 2.49693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:457, step:11450 (TRAIN, VALID): total: 2044.54, 2047.40      recon: 2030.08, 2033.19,     kl: 11.96, 11.71,     l2: 2.49831,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:458, step:11475 (TRAIN, VALID): total: 2044.66, 2049.52      recon: 2030.25, 2035.19,     kl: 11.91, 11.83,     l2: 2.49828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:459, step:11500 (TRAIN, VALID): total: 2044.84, 2047.34      recon: 2030.29, 2032.85,     kl: 12.04, 11.99,     l2: 2.49762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:460, step:11525 (TRAIN, VALID): total: 2044.80, 2047.82      recon: 2030.25, 2033.39,     kl: 12.05, 11.93,     l2: 2.49774,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:461, step:11550 (TRAIN, VALID): total: 2044.94, 2048.08      recon: 2030.29, 2033.77,     kl: 12.15, 11.81,     l2: 2.49767,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:462, step:11575 (TRAIN, VALID): total: 2044.81, 2048.06      recon: 2030.34, 2033.86,     kl: 11.97, 11.70,     l2: 2.49673,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:463, step:11600 (TRAIN, VALID): total: 2044.84, 2048.23      recon: 2030.34, 2033.97,     kl: 12.01, 11.76,     l2: 2.49661,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:464, step:11625 (TRAIN, VALID): total: 2044.58, 2049.35      recon: 2030.11, 2035.17,     kl: 11.96, 11.68,     l2: 2.49726,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:465, step:11650 (TRAIN, VALID): total: 2044.92, 2049.04      recon: 2030.48, 2034.68,     kl: 11.95, 11.86,     l2: 2.49578,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:466, step:11675 (TRAIN, VALID): total: 2044.83, 2048.03      recon: 2030.35, 2033.68,     kl: 11.98, 11.85,     l2: 2.49688,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:467, step:11700 (TRAIN, VALID): total: 2044.70, 2047.42      recon: 2030.22, 2033.09,     kl: 11.98, 11.83,     l2: 2.49606,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:468, step:11725 (TRAIN, VALID): total: 2045.20, 2048.76      recon: 2030.64, 2034.38,     kl: 12.07, 11.88,     l2: 2.49550,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001748.\n",
      "Epoch:469, step:11750 (TRAIN, VALID): total: 2045.11, 2047.48      recon: 2030.48, 2033.16,     kl: 12.14, 11.83,     l2: 2.49714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:470, step:11775 (TRAIN, VALID): total: 2044.61, 2047.79      recon: 2030.11, 2033.51,     kl: 12.01, 11.78,     l2: 2.49714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:471, step:11800 (TRAIN, VALID): total: 2044.50, 2047.84      recon: 2030.07, 2033.56,     kl: 11.94, 11.78,     l2: 2.49775,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:472, step:11825 (TRAIN, VALID): total: 2044.43, 2047.62      recon: 2030.01, 2033.49,     kl: 11.93, 11.63,     l2: 2.49900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:473, step:11850 (TRAIN, VALID): total: 2044.58, 2048.07      recon: 2030.12, 2033.70,     kl: 11.97, 11.88,     l2: 2.49979,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:474, step:11875 (TRAIN, VALID): total: 2044.74, 2047.03      recon: 2030.22, 2032.78,     kl: 12.02, 11.75,     l2: 2.49895,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:475, step:11900 (TRAIN, VALID): total: 2044.36, 2048.38      recon: 2029.89, 2034.08,     kl: 11.98, 11.80,     l2: 2.49760,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:476, step:11925 (TRAIN, VALID): total: 2044.55, 2047.98      recon: 2029.94, 2033.68,     kl: 12.11, 11.81,     l2: 2.49804,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:477, step:11950 (TRAIN, VALID): total: 2044.47, 2047.70      recon: 2029.99, 2033.42,     kl: 11.99, 11.78,     l2: 2.49937,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:478, step:11975 (TRAIN, VALID): total: 2044.65, 2047.76      recon: 2030.15, 2033.43,     kl: 12.00, 11.82,     l2: 2.49925,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:479, step:12000 (TRAIN, VALID): total: 2044.70, 2047.86      recon: 2030.18, 2033.56,     kl: 12.03, 11.80,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:480, step:12025 (TRAIN, VALID): total: 2044.83, 2047.01      recon: 2030.41, 2032.76,     kl: 11.92, 11.75,     l2: 2.49830,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001661.\n",
      "Epoch:481, step:12050 (TRAIN, VALID): total: 2044.68, 2049.44      recon: 2030.24, 2035.31,     kl: 11.95, 11.63,     l2: 2.49796,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:482, step:12075 (TRAIN, VALID): total: 2044.67, 2047.64      recon: 2030.21, 2033.55,     kl: 11.96, 11.59,     l2: 2.49849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:483, step:12100 (TRAIN, VALID): total: 2044.45, 2046.24      recon: 2030.02, 2031.83,     kl: 11.93, 11.91,     l2: 2.49920,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:484, step:12125 (TRAIN, VALID): total: 2044.35, 2048.06      recon: 2029.87, 2033.78,     kl: 11.98, 11.78,     l2: 2.50075,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:485, step:12150 (TRAIN, VALID): total: 2044.58, 2047.54      recon: 2030.08, 2033.28,     kl: 12.00, 11.75,     l2: 2.50103,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:486, step:12175 (TRAIN, VALID): total: 2044.46, 2048.01      recon: 2029.88, 2033.73,     kl: 12.08, 11.79,     l2: 2.50039,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:487, step:12200 (TRAIN, VALID): total: 2044.46, 2046.85      recon: 2030.01, 2032.68,     kl: 11.95, 11.67,     l2: 2.50001,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:488, step:12225 (TRAIN, VALID): total: 2044.41, 2046.80      recon: 2029.94, 2032.55,     kl: 11.97, 11.75,     l2: 2.50070,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:489, step:12250 (TRAIN, VALID): total: 2044.25, 2047.20      recon: 2029.85, 2033.03,     kl: 11.90, 11.67,     l2: 2.49993,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:490, step:12275 (TRAIN, VALID): total: 2044.27, 2047.41      recon: 2029.88, 2033.19,     kl: 11.89, 11.72,     l2: 2.50083,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:491, step:12300 (TRAIN, VALID): total: 2044.47, 2047.23      recon: 2030.04, 2032.97,     kl: 11.93, 11.77,     l2: 2.49882,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:492, step:12325 (TRAIN, VALID): total: 2044.44, 2048.07      recon: 2030.01, 2033.86,     kl: 11.93, 11.71,     l2: 2.49926,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:493, step:12350 (TRAIN, VALID): total: 2044.37, 2047.42      recon: 2029.90, 2033.19,     kl: 11.98, 11.72,     l2: 2.49963,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:494, step:12375 (TRAIN, VALID): total: 2044.41, 2046.03      recon: 2030.06, 2031.72,     kl: 11.85, 11.82,     l2: 2.50043,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:495, step:12400 (TRAIN, VALID): total: 2044.58, 2046.69      recon: 2030.12, 2032.58,     kl: 11.95, 11.61,     l2: 2.50017,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001578.\n",
      "Epoch:496, step:12425 (TRAIN, VALID): total: 2044.30, 2046.72      recon: 2029.92, 2032.52,     kl: 11.88, 11.70,     l2: 2.49946,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:497, step:12450 (TRAIN, VALID): total: 2044.44, 2047.40      recon: 2029.97, 2033.16,     kl: 11.97, 11.74,     l2: 2.49995,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:498, step:12475 (TRAIN, VALID): total: 2044.38, 2047.91      recon: 2029.89, 2033.52,     kl: 11.98, 11.89,     l2: 2.50129,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:499, step:12500 (TRAIN, VALID): total: 2044.21, 2047.40      recon: 2029.73, 2033.18,     kl: 11.97, 11.72,     l2: 2.50219,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:500, step:12525 (TRAIN, VALID): total: 2044.43, 2049.79      recon: 2029.92, 2035.37,     kl: 12.01, 11.91,     l2: 2.50204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:501, step:12550 (TRAIN, VALID): total: 2044.94, 2047.89      recon: 2030.32, 2033.53,     kl: 12.11, 11.86,     l2: 2.50186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:502, step:12575 (TRAIN, VALID): total: 2044.31, 2049.50      recon: 2029.89, 2035.35,     kl: 11.92, 11.65,     l2: 2.50179,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:503, step:12600 (TRAIN, VALID): total: 2044.39, 2046.49      recon: 2029.92, 2032.35,     kl: 11.96, 11.64,     l2: 2.50146,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:504, step:12625 (TRAIN, VALID): total: 2044.39, 2047.69      recon: 2029.95, 2033.36,     kl: 11.93, 11.83,     l2: 2.50077,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:505, step:12650 (TRAIN, VALID): total: 2044.14, 2047.54      recon: 2029.74, 2033.26,     kl: 11.90, 11.78,     l2: 2.50133,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:506, step:12675 (TRAIN, VALID): total: 2044.37, 2048.13      recon: 2029.98, 2033.97,     kl: 11.88, 11.66,     l2: 2.50093,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:507, step:12700 (TRAIN, VALID): total: 2044.44, 2047.77      recon: 2029.94, 2033.40,     kl: 12.00, 11.87,     l2: 2.50255,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:508, step:12725 (TRAIN, VALID): total: 2044.52, 2049.28      recon: 2030.05, 2035.06,     kl: 11.97, 11.72,     l2: 2.50158,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001499.\n",
      "Epoch:509, step:12750 (TRAIN, VALID): total: 2044.74, 2048.22      recon: 2030.17, 2033.71,     kl: 12.06, 12.00,     l2: 2.50217,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:510, step:12775 (TRAIN, VALID): total: 2044.38, 2047.14      recon: 2029.84, 2032.94,     kl: 12.04, 11.70,     l2: 2.50156,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:511, step:12800 (TRAIN, VALID): total: 2044.19, 2048.97      recon: 2029.81, 2034.55,     kl: 11.88, 11.92,     l2: 2.50213,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:512, step:12825 (TRAIN, VALID): total: 2044.99, 2049.41      recon: 2030.35, 2035.05,     kl: 12.14, 11.86,     l2: 2.50214,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:513, step:12850 (TRAIN, VALID): total: 2044.49, 2048.60      recon: 2029.94, 2034.36,     kl: 12.05, 11.74,     l2: 2.50320,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:514, step:12875 (TRAIN, VALID): total: 2044.30, 2046.68      recon: 2029.80, 2032.45,     kl: 12.00, 11.73,     l2: 2.50328,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:515, step:12900 (TRAIN, VALID): total: 2044.24, 2047.44      recon: 2029.80, 2033.12,     kl: 11.93, 11.82,     l2: 2.50322,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:516, step:12925 (TRAIN, VALID): total: 2044.24, 2049.06      recon: 2029.79, 2034.78,     kl: 11.95, 11.78,     l2: 2.50325,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:517, step:12950 (TRAIN, VALID): total: 2044.04, 2048.16      recon: 2029.59, 2034.03,     kl: 11.95, 11.63,     l2: 2.50270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:518, step:12975 (TRAIN, VALID): total: 2044.47, 2047.41      recon: 2030.04, 2033.11,     kl: 11.93, 11.80,     l2: 2.50311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:519, step:13000 (TRAIN, VALID): total: 2044.30, 2047.33      recon: 2029.76, 2033.01,     kl: 12.04, 11.81,     l2: 2.50241,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:520, step:13025 (TRAIN, VALID): total: 2044.03, 2048.09      recon: 2029.62, 2033.94,     kl: 11.92, 11.65,     l2: 2.50343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:521, step:13050 (TRAIN, VALID): total: 2043.99, 2047.76      recon: 2029.59, 2033.55,     kl: 11.90, 11.70,     l2: 2.50294,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:522, step:13075 (TRAIN, VALID): total: 2044.16, 2048.11      recon: 2029.78, 2033.81,     kl: 11.88, 11.79,     l2: 2.50335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:523, step:13100 (TRAIN, VALID): total: 2044.20, 2047.19      recon: 2029.68, 2032.83,     kl: 12.01, 11.86,     l2: 2.50437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:524, step:13125 (TRAIN, VALID): total: 2044.38, 2048.56      recon: 2029.84, 2034.21,     kl: 12.04, 11.85,     l2: 2.50401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:525, step:13150 (TRAIN, VALID): total: 2044.14, 2048.01      recon: 2029.62, 2033.82,     kl: 12.02, 11.69,     l2: 2.50407,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:526, step:13175 (TRAIN, VALID): total: 2044.07, 2046.75      recon: 2029.62, 2032.42,     kl: 11.94, 11.82,     l2: 2.50356,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:527, step:13200 (TRAIN, VALID): total: 2044.03, 2048.07      recon: 2029.50, 2033.58,     kl: 12.03, 11.99,     l2: 2.50385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:528, step:13225 (TRAIN, VALID): total: 2043.89, 2046.24      recon: 2029.40, 2032.07,     kl: 11.99, 11.67,     l2: 2.50330,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:529, step:13250 (TRAIN, VALID): total: 2044.16, 2048.11      recon: 2029.67, 2033.87,     kl: 11.98, 11.74,     l2: 2.50451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:530, step:13275 (TRAIN, VALID): total: 2044.32, 2047.40      recon: 2029.87, 2033.16,     kl: 11.95, 11.74,     l2: 2.50474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:531, step:13300 (TRAIN, VALID): total: 2044.14, 2047.41      recon: 2029.63, 2033.19,     kl: 12.01, 11.72,     l2: 2.50401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:532, step:13325 (TRAIN, VALID): total: 2044.11, 2047.99      recon: 2029.61, 2033.73,     kl: 12.00, 11.75,     l2: 2.50418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:533, step:13350 (TRAIN, VALID): total: 2044.13, 2047.33      recon: 2029.67, 2032.79,     kl: 11.96, 12.04,     l2: 2.50447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:534, step:13375 (TRAIN, VALID): total: 2044.53, 2047.84      recon: 2029.80, 2033.73,     kl: 12.22, 11.60,     l2: 2.50504,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001424.\n",
      "Epoch:535, step:13400 (TRAIN, VALID): total: 2044.06, 2048.08      recon: 2029.63, 2033.89,     kl: 11.92, 11.68,     l2: 2.50566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:536, step:13425 (TRAIN, VALID): total: 2044.13, 2047.81      recon: 2029.73, 2033.57,     kl: 11.89, 11.73,     l2: 2.50438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:537, step:13450 (TRAIN, VALID): total: 2043.99, 2046.92      recon: 2029.55, 2032.72,     kl: 11.93, 11.69,     l2: 2.50452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:538, step:13475 (TRAIN, VALID): total: 2044.22, 2046.53      recon: 2029.80, 2032.18,     kl: 11.92, 11.84,     l2: 2.50459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:539, step:13500 (TRAIN, VALID): total: 2044.48, 2046.85      recon: 2029.95, 2032.57,     kl: 12.02, 11.78,     l2: 2.50257,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:540, step:13525 (TRAIN, VALID): total: 2044.11, 2046.75      recon: 2029.56, 2032.29,     kl: 12.04, 11.95,     l2: 2.50321,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:541, step:13550 (TRAIN, VALID): total: 2043.89, 2047.33      recon: 2029.41, 2033.11,     kl: 11.97, 11.71,     l2: 2.50523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:542, step:13575 (TRAIN, VALID): total: 2043.94, 2046.83      recon: 2029.52, 2032.66,     kl: 11.92, 11.66,     l2: 2.50336,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:543, step:13600 (TRAIN, VALID): total: 2044.53, 2046.82      recon: 2029.98, 2032.55,     kl: 12.05, 11.77,     l2: 2.50318,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001353.\n",
      "Epoch:544, step:13625 (TRAIN, VALID): total: 2043.92, 2047.08      recon: 2029.51, 2032.97,     kl: 11.90, 11.61,     l2: 2.50350,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:545, step:13650 (TRAIN, VALID): total: 2043.91, 2047.47      recon: 2029.43, 2033.24,     kl: 11.98, 11.72,     l2: 2.50377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:546, step:13675 (TRAIN, VALID): total: 2043.90, 2047.99      recon: 2029.44, 2033.75,     kl: 11.95, 11.74,     l2: 2.50345,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:547, step:13700 (TRAIN, VALID): total: 2043.77, 2047.67      recon: 2029.36, 2033.53,     kl: 11.91, 11.64,     l2: 2.50377,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:548, step:13725 (TRAIN, VALID): total: 2044.09, 2047.26      recon: 2029.66, 2033.00,     kl: 11.93, 11.76,     l2: 2.50406,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:549, step:13750 (TRAIN, VALID): total: 2044.67, 2047.77      recon: 2030.16, 2033.51,     kl: 12.01, 11.75,     l2: 2.50234,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:550, step:13775 (TRAIN, VALID): total: 2044.05, 2048.00      recon: 2029.63, 2033.59,     kl: 11.91, 11.91,     l2: 2.50351,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:551, step:13800 (TRAIN, VALID): total: 2044.03, 2047.69      recon: 2029.51, 2033.47,     kl: 12.02, 11.72,     l2: 2.50418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:552, step:13825 (TRAIN, VALID): total: 2043.86, 2048.12      recon: 2029.45, 2033.86,     kl: 11.91, 11.76,     l2: 2.50414,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:553, step:13850 (TRAIN, VALID): total: 2044.44, 2046.56      recon: 2029.90, 2032.18,     kl: 12.03, 11.87,     l2: 2.50350,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:554, step:13875 (TRAIN, VALID): total: 2044.16, 2047.57      recon: 2029.58, 2033.20,     kl: 12.08, 11.86,     l2: 2.50459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:555, step:13900 (TRAIN, VALID): total: 2044.31, 2046.87      recon: 2029.73, 2032.51,     kl: 12.07, 11.86,     l2: 2.50376,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:556, step:13925 (TRAIN, VALID): total: 2044.06, 2048.04      recon: 2029.59, 2033.95,     kl: 11.97, 11.59,     l2: 2.50391,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:557, step:13950 (TRAIN, VALID): total: 2044.27, 2047.77      recon: 2029.73, 2033.34,     kl: 12.04, 11.92,     l2: 2.50534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:558, step:13975 (TRAIN, VALID): total: 2043.93, 2047.37      recon: 2029.45, 2033.08,     kl: 11.98, 11.79,     l2: 2.50475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:559, step:14000 (TRAIN, VALID): total: 2044.02, 2047.64      recon: 2029.54, 2033.43,     kl: 11.97, 11.70,     l2: 2.50397,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:560, step:14025 (TRAIN, VALID): total: 2043.79, 2047.76      recon: 2029.36, 2033.58,     kl: 11.93, 11.68,     l2: 2.50352,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:561, step:14050 (TRAIN, VALID): total: 2044.02, 2048.11      recon: 2029.52, 2033.78,     kl: 11.99, 11.82,     l2: 2.50461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:562, step:14075 (TRAIN, VALID): total: 2043.88, 2049.18      recon: 2029.45, 2034.88,     kl: 11.93, 11.79,     l2: 2.50536,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:563, step:14100 (TRAIN, VALID): total: 2043.88, 2047.91      recon: 2029.36, 2033.61,     kl: 12.02, 11.80,     l2: 2.50537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:564, step:14125 (TRAIN, VALID): total: 2043.91, 2046.36      recon: 2029.43, 2032.07,     kl: 11.98, 11.78,     l2: 2.50595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:565, step:14150 (TRAIN, VALID): total: 2044.15, 2046.33      recon: 2029.64, 2032.06,     kl: 12.00, 11.77,     l2: 2.50493,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001285.\n",
      "Epoch:566, step:14175 (TRAIN, VALID): total: 2044.42, 2046.50      recon: 2029.78, 2032.08,     kl: 12.14, 11.92,     l2: 2.50584,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:567, step:14200 (TRAIN, VALID): total: 2044.43, 2047.18      recon: 2029.89, 2032.77,     kl: 12.03, 11.91,     l2: 2.50577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:568, step:14225 (TRAIN, VALID): total: 2043.98, 2047.42      recon: 2029.41, 2033.15,     kl: 12.07, 11.76,     l2: 2.50691,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:569, step:14250 (TRAIN, VALID): total: 2043.91, 2047.28      recon: 2029.36, 2032.92,     kl: 12.04, 11.86,     l2: 2.50643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:570, step:14275 (TRAIN, VALID): total: 2043.91, 2047.60      recon: 2029.38, 2033.42,     kl: 12.02, 11.68,     l2: 2.50788,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:571, step:14300 (TRAIN, VALID): total: 2043.95, 2047.03      recon: 2029.51, 2032.85,     kl: 11.94, 11.67,     l2: 2.50818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:572, step:14325 (TRAIN, VALID): total: 2044.11, 2048.29      recon: 2029.54, 2033.85,     kl: 12.06, 11.93,     l2: 2.50756,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:573, step:14350 (TRAIN, VALID): total: 2043.89, 2047.20      recon: 2029.35, 2032.97,     kl: 12.04, 11.72,     l2: 2.50705,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:574, step:14375 (TRAIN, VALID): total: 2043.87, 2047.51      recon: 2029.44, 2033.21,     kl: 11.92, 11.79,     l2: 2.50714,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:575, step:14400 (TRAIN, VALID): total: 2043.85, 2046.99      recon: 2029.37, 2032.74,     kl: 11.97, 11.74,     l2: 2.50640,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:576, step:14425 (TRAIN, VALID): total: 2043.95, 2047.14      recon: 2029.42, 2032.78,     kl: 12.02, 11.85,     l2: 2.50701,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:577, step:14450 (TRAIN, VALID): total: 2043.87, 2047.94      recon: 2029.34, 2033.47,     kl: 12.02, 11.97,     l2: 2.50835,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:578, step:14475 (TRAIN, VALID): total: 2044.15, 2047.41      recon: 2029.57, 2033.06,     kl: 12.07, 11.85,     l2: 2.50888,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001221.\n",
      "Epoch:579, step:14500 (TRAIN, VALID): total: 2044.18, 2045.64      recon: 2029.59, 2031.37,     kl: 12.09, 11.76,     l2: 2.50957,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:580, step:14525 (TRAIN, VALID): total: 2043.96, 2047.36      recon: 2029.40, 2032.85,     kl: 12.05, 12.00,     l2: 2.50876,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:581, step:14550 (TRAIN, VALID): total: 2044.16, 2047.00      recon: 2029.52, 2032.80,     kl: 12.14, 11.69,     l2: 2.50900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:582, step:14575 (TRAIN, VALID): total: 2043.76, 2049.58      recon: 2029.29, 2035.35,     kl: 11.96, 11.72,     l2: 2.50948,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:583, step:14600 (TRAIN, VALID): total: 2043.86, 2046.77      recon: 2029.44, 2032.49,     kl: 11.91, 11.77,     l2: 2.50885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:584, step:14625 (TRAIN, VALID): total: 2043.80, 2047.08      recon: 2029.23, 2032.64,     kl: 12.06, 11.93,     l2: 2.50959,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:585, step:14650 (TRAIN, VALID): total: 2043.63, 2046.91      recon: 2029.13, 2032.63,     kl: 11.99, 11.77,     l2: 2.51052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:586, step:14675 (TRAIN, VALID): total: 2044.22, 2046.64      recon: 2029.61, 2032.37,     kl: 12.10, 11.76,     l2: 2.51028,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001160.\n",
      "Epoch:587, step:14700 (TRAIN, VALID): total: 2043.97, 2046.12      recon: 2029.43, 2031.77,     kl: 12.03, 11.84,     l2: 2.50987,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:588, step:14725 (TRAIN, VALID): total: 2043.58, 2047.13      recon: 2029.06, 2032.93,     kl: 12.01, 11.69,     l2: 2.50958,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:589, step:14750 (TRAIN, VALID): total: 2043.65, 2048.59      recon: 2029.25, 2034.35,     kl: 11.89, 11.73,     l2: 2.51102,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:590, step:14775 (TRAIN, VALID): total: 2043.77, 2047.74      recon: 2029.28, 2033.56,     kl: 11.98, 11.67,     l2: 2.51059,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:591, step:14800 (TRAIN, VALID): total: 2043.69, 2047.23      recon: 2029.16, 2032.87,     kl: 12.01, 11.85,     l2: 2.51203,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:592, step:14825 (TRAIN, VALID): total: 2043.58, 2047.59      recon: 2029.10, 2033.39,     kl: 11.97, 11.69,     l2: 2.51223,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:593, step:14850 (TRAIN, VALID): total: 2044.23, 2047.39      recon: 2029.68, 2033.09,     kl: 12.04, 11.79,     l2: 2.51175,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001102.\n",
      "Epoch:594, step:14875 (TRAIN, VALID): total: 2043.64, 2046.06      recon: 2029.15, 2031.75,     kl: 11.97, 11.79,     l2: 2.51202,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:595, step:14900 (TRAIN, VALID): total: 2043.69, 2046.84      recon: 2029.20, 2032.58,     kl: 11.98, 11.75,     l2: 2.51281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:596, step:14925 (TRAIN, VALID): total: 2043.79, 2047.21      recon: 2029.23, 2032.92,     kl: 12.05, 11.78,     l2: 2.51218,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:597, step:14950 (TRAIN, VALID): total: 2043.69, 2046.60      recon: 2029.24, 2032.33,     kl: 11.94, 11.76,     l2: 2.51198,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:598, step:14975 (TRAIN, VALID): total: 2043.54, 2046.60      recon: 2029.05, 2032.31,     kl: 11.97, 11.77,     l2: 2.51224,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:599, step:15000 (TRAIN, VALID): total: 2043.52, 2047.47      recon: 2029.01, 2033.24,     kl: 12.00, 11.73,     l2: 2.51201,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:600, step:15025 (TRAIN, VALID): total: 2043.49, 2047.40      recon: 2029.08, 2033.13,     kl: 11.90, 11.76,     l2: 2.51185,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:601, step:15050 (TRAIN, VALID): total: 2043.68, 2048.21      recon: 2029.17, 2033.84,     kl: 12.00, 11.86,     l2: 2.51126,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:602, step:15075 (TRAIN, VALID): total: 2043.75, 2046.40      recon: 2029.16, 2032.20,     kl: 12.08, 11.69,     l2: 2.51176,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:603, step:15100 (TRAIN, VALID): total: 2043.64, 2048.46      recon: 2029.16, 2034.15,     kl: 11.97, 11.80,     l2: 2.51100,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:604, step:15125 (TRAIN, VALID): total: 2043.71, 2047.60      recon: 2029.15, 2033.26,     kl: 12.05, 11.82,     l2: 2.51218,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:605, step:15150 (TRAIN, VALID): total: 2043.75, 2046.87      recon: 2029.29, 2032.46,     kl: 11.95, 11.90,     l2: 2.51217,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:606, step:15175 (TRAIN, VALID): total: 2043.75, 2046.38      recon: 2029.20, 2032.14,     kl: 12.03, 11.73,     l2: 2.51323,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:607, step:15200 (TRAIN, VALID): total: 2043.62, 2047.03      recon: 2029.09, 2032.68,     kl: 12.02, 11.83,     l2: 2.51317,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:608, step:15225 (TRAIN, VALID): total: 2043.50, 2046.61      recon: 2029.04, 2032.44,     kl: 11.94, 11.65,     l2: 2.51385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:609, step:15250 (TRAIN, VALID): total: 2043.41, 2046.53      recon: 2028.90, 2032.30,     kl: 11.99, 11.72,     l2: 2.51400,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:610, step:15275 (TRAIN, VALID): total: 2043.83, 2047.61      recon: 2029.35, 2033.26,     kl: 11.97, 11.83,     l2: 2.51389,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.001047.\n",
      "Epoch:611, step:15300 (TRAIN, VALID): total: 2043.58, 2046.93      recon: 2029.04, 2032.72,     kl: 12.02, 11.69,     l2: 2.51401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:612, step:15325 (TRAIN, VALID): total: 2043.71, 2045.97      recon: 2029.28, 2031.76,     kl: 11.92, 11.69,     l2: 2.51333,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:613, step:15350 (TRAIN, VALID): total: 2043.30, 2046.98      recon: 2028.89, 2032.80,     kl: 11.90, 11.66,     l2: 2.51369,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:614, step:15375 (TRAIN, VALID): total: 2044.35, 2046.16      recon: 2029.74, 2031.89,     kl: 12.10, 11.76,     l2: 2.51303,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:615, step:15400 (TRAIN, VALID): total: 2043.60, 2048.13      recon: 2029.13, 2033.88,     kl: 11.96, 11.73,     l2: 2.51327,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:616, step:15425 (TRAIN, VALID): total: 2043.53, 2048.46      recon: 2029.02, 2034.20,     kl: 11.99, 11.75,     l2: 2.51361,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:617, step:15450 (TRAIN, VALID): total: 2043.73, 2047.83      recon: 2029.26, 2033.56,     kl: 11.96, 11.76,     l2: 2.51351,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:618, step:15475 (TRAIN, VALID): total: 2043.46, 2046.34      recon: 2028.98, 2032.07,     kl: 11.97, 11.75,     l2: 2.51424,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:619, step:15500 (TRAIN, VALID): total: 2043.49, 2047.18      recon: 2029.01, 2032.88,     kl: 11.97, 11.78,     l2: 2.51500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:620, step:15525 (TRAIN, VALID): total: 2043.38, 2046.61      recon: 2028.90, 2032.41,     kl: 11.97, 11.69,     l2: 2.51392,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:621, step:15550 (TRAIN, VALID): total: 2043.40, 2046.59      recon: 2029.00, 2032.46,     kl: 11.89, 11.61,     l2: 2.51456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:622, step:15575 (TRAIN, VALID): total: 2043.83, 2046.43      recon: 2029.31, 2032.17,     kl: 12.00, 11.75,     l2: 2.51519,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000994.\n",
      "Epoch:623, step:15600 (TRAIN, VALID): total: 2043.34, 2047.59      recon: 2028.82, 2033.30,     kl: 12.00, 11.78,     l2: 2.51527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:624, step:15625 (TRAIN, VALID): total: 2043.72, 2047.62      recon: 2029.16, 2033.14,     kl: 12.04, 11.96,     l2: 2.51387,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:625, step:15650 (TRAIN, VALID): total: 2043.47, 2046.75      recon: 2028.86, 2032.50,     kl: 12.09, 11.73,     l2: 2.51527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:626, step:15675 (TRAIN, VALID): total: 2043.52, 2048.71      recon: 2029.05, 2034.31,     kl: 11.96, 11.89,     l2: 2.51432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:627, step:15700 (TRAIN, VALID): total: 2043.79, 2046.26      recon: 2029.22, 2032.02,     kl: 12.05, 11.73,     l2: 2.51443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:628, step:15725 (TRAIN, VALID): total: 2043.33, 2047.23      recon: 2028.86, 2032.92,     kl: 11.96, 11.79,     l2: 2.51471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:629, step:15750 (TRAIN, VALID): total: 2043.51, 2045.70      recon: 2029.02, 2031.47,     kl: 11.98, 11.71,     l2: 2.51510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:630, step:15775 (TRAIN, VALID): total: 2043.37, 2046.78      recon: 2028.92, 2032.58,     kl: 11.94, 11.69,     l2: 2.51511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:631, step:15800 (TRAIN, VALID): total: 2043.40, 2048.17      recon: 2028.87, 2033.79,     kl: 12.02, 11.87,     l2: 2.51624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:632, step:15825 (TRAIN, VALID): total: 2043.62, 2047.43      recon: 2029.09, 2033.13,     kl: 12.01, 11.79,     l2: 2.51554,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:633, step:15850 (TRAIN, VALID): total: 2043.40, 2047.77      recon: 2028.88, 2033.55,     kl: 12.01, 11.70,     l2: 2.51626,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:634, step:15875 (TRAIN, VALID): total: 2043.52, 2048.85      recon: 2028.94, 2034.53,     kl: 12.06, 11.80,     l2: 2.51598,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:635, step:15900 (TRAIN, VALID): total: 2043.48, 2046.16      recon: 2029.01, 2031.89,     kl: 11.96, 11.75,     l2: 2.51530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:636, step:15925 (TRAIN, VALID): total: 2043.35, 2047.31      recon: 2028.81, 2033.03,     kl: 12.02, 11.76,     l2: 2.51536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:637, step:15950 (TRAIN, VALID): total: 2043.38, 2047.62      recon: 2028.93, 2033.34,     kl: 11.93, 11.77,     l2: 2.51498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:638, step:15975 (TRAIN, VALID): total: 2043.63, 2048.00      recon: 2029.08, 2033.65,     kl: 12.03, 11.83,     l2: 2.51575,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000945.\n",
      "Epoch:639, step:16000 (TRAIN, VALID): total: 2043.76, 2046.48      recon: 2029.19, 2032.21,     kl: 12.05, 11.76,     l2: 2.51574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:640, step:16025 (TRAIN, VALID): total: 2043.43, 2047.56      recon: 2028.89, 2033.27,     kl: 12.02, 11.77,     l2: 2.51504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:641, step:16050 (TRAIN, VALID): total: 2043.30, 2046.12      recon: 2028.83, 2031.97,     kl: 11.95, 11.64,     l2: 2.51605,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:642, step:16075 (TRAIN, VALID): total: 2043.74, 2048.11      recon: 2029.25, 2033.78,     kl: 11.97, 11.82,     l2: 2.51494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:643, step:16100 (TRAIN, VALID): total: 2043.49, 2046.87      recon: 2028.96, 2032.65,     kl: 12.01, 11.70,     l2: 2.51488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:644, step:16125 (TRAIN, VALID): total: 2043.40, 2046.47      recon: 2028.93, 2032.18,     kl: 11.96, 11.78,     l2: 2.51458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:645, step:16150 (TRAIN, VALID): total: 2043.53, 2047.06      recon: 2028.99, 2032.70,     kl: 12.02, 11.84,     l2: 2.51569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:646, step:16175 (TRAIN, VALID): total: 2043.75, 2047.39      recon: 2029.17, 2033.07,     kl: 12.07, 11.81,     l2: 2.51623,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000897.\n",
      "Epoch:647, step:16200 (TRAIN, VALID): total: 2043.45, 2047.12      recon: 2028.82, 2032.72,     kl: 12.11, 11.88,     l2: 2.51601,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:648, step:16225 (TRAIN, VALID): total: 2043.40, 2046.60      recon: 2028.84, 2032.32,     kl: 12.05, 11.76,     l2: 2.51577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:649, step:16250 (TRAIN, VALID): total: 2043.26, 2046.94      recon: 2028.81, 2032.76,     kl: 11.93, 11.66,     l2: 2.51653,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:650, step:16275 (TRAIN, VALID): total: 2043.81, 2048.09      recon: 2029.21, 2033.72,     kl: 12.09, 11.86,     l2: 2.51690,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:651, step:16300 (TRAIN, VALID): total: 2043.41, 2046.71      recon: 2028.93, 2032.45,     kl: 11.96, 11.74,     l2: 2.51619,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:652, step:16325 (TRAIN, VALID): total: 2043.38, 2047.23      recon: 2028.88, 2032.95,     kl: 11.98, 11.77,     l2: 2.51625,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:653, step:16350 (TRAIN, VALID): total: 2043.23, 2047.89      recon: 2028.75, 2033.67,     kl: 11.96, 11.70,     l2: 2.51704,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:654, step:16375 (TRAIN, VALID): total: 2043.35, 2047.63      recon: 2028.86, 2033.37,     kl: 11.96, 11.74,     l2: 2.51656,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:655, step:16400 (TRAIN, VALID): total: 2043.78, 2047.03      recon: 2029.17, 2032.65,     kl: 12.10, 11.86,     l2: 2.51692,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:656, step:16425 (TRAIN, VALID): total: 2043.37, 2046.87      recon: 2028.81, 2032.67,     kl: 12.04, 11.68,     l2: 2.51633,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:657, step:16450 (TRAIN, VALID): total: 2043.30, 2046.54      recon: 2028.86, 2032.25,     kl: 11.92, 11.77,     l2: 2.51604,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:658, step:16475 (TRAIN, VALID): total: 2043.51, 2047.05      recon: 2028.75, 2032.59,     kl: 12.25, 11.94,     l2: 2.51550,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:659, step:16500 (TRAIN, VALID): total: 2043.40, 2046.69      recon: 2028.82, 2032.39,     kl: 12.07, 11.78,     l2: 2.51614,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:660, step:16525 (TRAIN, VALID): total: 2043.41, 2048.01      recon: 2028.84, 2033.63,     kl: 12.05, 11.86,     l2: 2.51558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:661, step:16550 (TRAIN, VALID): total: 2043.36, 2046.23      recon: 2028.84, 2031.91,     kl: 12.01, 11.80,     l2: 2.51567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:662, step:16575 (TRAIN, VALID): total: 2043.43, 2046.11      recon: 2028.86, 2031.68,     kl: 12.06, 11.91,     l2: 2.51546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:663, step:16600 (TRAIN, VALID): total: 2043.35, 2047.18      recon: 2028.78, 2032.87,     kl: 12.05, 11.79,     l2: 2.51548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:664, step:16625 (TRAIN, VALID): total: 2043.32, 2047.28      recon: 2028.81, 2032.98,     kl: 11.99, 11.78,     l2: 2.51600,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:665, step:16650 (TRAIN, VALID): total: 2043.43, 2046.58      recon: 2028.96, 2032.21,     kl: 11.95, 11.85,     l2: 2.51681,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:666, step:16675 (TRAIN, VALID): total: 2043.53, 2046.71      recon: 2028.91, 2032.37,     kl: 12.10, 11.82,     l2: 2.51565,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000853.\n",
      "Epoch:667, step:16700 (TRAIN, VALID): total: 2043.20, 2047.42      recon: 2028.69, 2033.17,     kl: 11.99, 11.73,     l2: 2.51719,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:668, step:16725 (TRAIN, VALID): total: 2043.28, 2046.30      recon: 2028.81, 2032.04,     kl: 11.95, 11.75,     l2: 2.51686,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:669, step:16750 (TRAIN, VALID): total: 2043.42, 2046.49      recon: 2028.95, 2032.20,     kl: 11.96, 11.78,     l2: 2.51643,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:670, step:16775 (TRAIN, VALID): total: 2043.10, 2047.66      recon: 2028.62, 2033.48,     kl: 11.97, 11.67,     l2: 2.51743,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:671, step:16800 (TRAIN, VALID): total: 2043.31, 2047.20      recon: 2028.83, 2032.87,     kl: 11.97, 11.81,     l2: 2.51705,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:672, step:16825 (TRAIN, VALID): total: 2043.30, 2046.79      recon: 2028.76, 2032.45,     kl: 12.03, 11.83,     l2: 2.51716,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:673, step:16850 (TRAIN, VALID): total: 2043.45, 2048.46      recon: 2028.94, 2034.17,     kl: 11.99, 11.77,     l2: 2.51726,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000810.\n",
      "Epoch:674, step:16875 (TRAIN, VALID): total: 2043.15, 2047.79      recon: 2028.65, 2033.46,     kl: 11.98, 11.81,     l2: 2.51776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:675, step:16900 (TRAIN, VALID): total: 2043.13, 2047.30      recon: 2028.57, 2033.06,     kl: 12.05, 11.73,     l2: 2.51859,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:676, step:16925 (TRAIN, VALID): total: 2043.28, 2047.31      recon: 2028.84, 2032.99,     kl: 11.91, 11.80,     l2: 2.51894,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:677, step:16950 (TRAIN, VALID): total: 2043.53, 2047.24      recon: 2028.88, 2032.92,     kl: 12.13, 11.81,     l2: 2.51961,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:678, step:16975 (TRAIN, VALID): total: 2043.30, 2047.96      recon: 2028.76, 2033.53,     kl: 12.02, 11.91,     l2: 2.51896,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:679, step:17000 (TRAIN, VALID): total: 2043.18, 2046.49      recon: 2028.61, 2032.06,     kl: 12.06, 11.90,     l2: 2.51902,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:680, step:17025 (TRAIN, VALID): total: 2043.20, 2047.61      recon: 2028.55, 2033.22,     kl: 12.13, 11.87,     l2: 2.51904,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:681, step:17050 (TRAIN, VALID): total: 2043.31, 2046.85      recon: 2028.72, 2032.59,     kl: 12.07, 11.73,     l2: 2.51851,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:682, step:17075 (TRAIN, VALID): total: 2043.12, 2047.62      recon: 2028.62, 2033.33,     kl: 11.98, 11.77,     l2: 2.51908,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:683, step:17100 (TRAIN, VALID): total: 2043.14, 2046.09      recon: 2028.65, 2031.75,     kl: 11.97, 11.82,     l2: 2.51884,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:684, step:17125 (TRAIN, VALID): total: 2043.17, 2047.67      recon: 2028.60, 2033.26,     kl: 12.04, 11.90,     l2: 2.51889,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:685, step:17150 (TRAIN, VALID): total: 2043.06, 2048.45      recon: 2028.53, 2034.23,     kl: 12.00, 11.70,     l2: 2.51863,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:686, step:17175 (TRAIN, VALID): total: 2043.17, 2047.31      recon: 2028.70, 2033.02,     kl: 11.95, 11.77,     l2: 2.51908,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:687, step:17200 (TRAIN, VALID): total: 2043.50, 2047.41      recon: 2028.91, 2032.93,     kl: 12.06, 11.96,     l2: 2.51926,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000769.\n",
      "Epoch:688, step:17225 (TRAIN, VALID): total: 2043.19, 2046.32      recon: 2028.67, 2032.17,     kl: 12.00, 11.64,     l2: 2.51900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:689, step:17250 (TRAIN, VALID): total: 2043.28, 2046.59      recon: 2028.82, 2032.23,     kl: 11.94, 11.84,     l2: 2.51887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:690, step:17275 (TRAIN, VALID): total: 2043.12, 2047.06      recon: 2028.60, 2032.73,     kl: 12.01, 11.80,     l2: 2.51910,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:691, step:17300 (TRAIN, VALID): total: 2043.03, 2046.79      recon: 2028.54, 2032.52,     kl: 11.97, 11.75,     l2: 2.51885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:692, step:17325 (TRAIN, VALID): total: 2043.03, 2046.07      recon: 2028.51, 2031.76,     kl: 12.00, 11.79,     l2: 2.51829,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:693, step:17350 (TRAIN, VALID): total: 2043.03, 2045.59      recon: 2028.55, 2031.34,     kl: 11.97, 11.73,     l2: 2.51902,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:694, step:17375 (TRAIN, VALID): total: 2043.04, 2047.50      recon: 2028.58, 2033.22,     kl: 11.95, 11.76,     l2: 2.51917,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:695, step:17400 (TRAIN, VALID): total: 2043.06, 2048.21      recon: 2028.54, 2033.90,     kl: 12.00, 11.79,     l2: 2.51941,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:696, step:17425 (TRAIN, VALID): total: 2043.00, 2047.78      recon: 2028.47, 2033.58,     kl: 12.01, 11.68,     l2: 2.52015,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:697, step:17450 (TRAIN, VALID): total: 2043.04, 2047.63      recon: 2028.58, 2033.36,     kl: 11.94, 11.76,     l2: 2.51923,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:698, step:17475 (TRAIN, VALID): total: 2043.37, 2046.60      recon: 2028.86, 2032.22,     kl: 11.99, 11.85,     l2: 2.51920,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000731.\n",
      "Epoch:699, step:17500 (TRAIN, VALID): total: 2043.22, 2046.78      recon: 2028.68, 2032.57,     kl: 12.02, 11.69,     l2: 2.51973,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:700, step:17525 (TRAIN, VALID): total: 2042.95, 2047.71      recon: 2028.49, 2033.41,     kl: 11.94, 11.78,     l2: 2.52070,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:701, step:17550 (TRAIN, VALID): total: 2043.37, 2046.72      recon: 2028.83, 2032.41,     kl: 12.01, 11.79,     l2: 2.52104,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:702, step:17575 (TRAIN, VALID): total: 2043.03, 2047.26      recon: 2028.54, 2033.09,     kl: 11.98, 11.65,     l2: 2.52100,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:703, step:17600 (TRAIN, VALID): total: 2043.39, 2048.41      recon: 2028.86, 2034.01,     kl: 12.01, 11.88,     l2: 2.52028,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:704, step:17625 (TRAIN, VALID): total: 2042.95, 2047.48      recon: 2028.45, 2033.33,     kl: 11.98, 11.63,     l2: 2.52052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:705, step:17650 (TRAIN, VALID): total: 2043.07, 2048.20      recon: 2028.57, 2033.78,     kl: 11.97, 11.90,     l2: 2.52054,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:706, step:17675 (TRAIN, VALID): total: 2043.04, 2047.50      recon: 2028.50, 2033.19,     kl: 12.03, 11.79,     l2: 2.52119,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:707, step:17700 (TRAIN, VALID): total: 2043.01, 2046.86      recon: 2028.57, 2032.58,     kl: 11.92, 11.77,     l2: 2.52066,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:708, step:17725 (TRAIN, VALID): total: 2043.17, 2046.82      recon: 2028.57, 2032.44,     kl: 12.07, 11.86,     l2: 2.52010,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:709, step:17750 (TRAIN, VALID): total: 2042.92, 2046.80      recon: 2028.46, 2032.54,     kl: 11.95, 11.74,     l2: 2.51949,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:710, step:17775 (TRAIN, VALID): total: 2043.25, 2047.95      recon: 2028.61, 2033.42,     kl: 12.13, 12.00,     l2: 2.52021,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000694.\n",
      "Epoch:711, step:17800 (TRAIN, VALID): total: 2043.09, 2046.86      recon: 2028.53, 2032.64,     kl: 12.05, 11.70,     l2: 2.51965,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:712, step:17825 (TRAIN, VALID): total: 2043.25, 2047.23      recon: 2028.68, 2032.82,     kl: 12.05, 11.89,     l2: 2.51980,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:713, step:17850 (TRAIN, VALID): total: 2042.96, 2046.96      recon: 2028.41, 2032.71,     kl: 12.03, 11.73,     l2: 2.52032,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:714, step:17875 (TRAIN, VALID): total: 2042.86, 2046.63      recon: 2028.38, 2032.29,     kl: 11.96, 11.82,     l2: 2.52068,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:715, step:17900 (TRAIN, VALID): total: 2043.18, 2047.96      recon: 2028.63, 2033.63,     kl: 12.02, 11.80,     l2: 2.52125,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:716, step:17925 (TRAIN, VALID): total: 2043.16, 2046.94      recon: 2028.60, 2032.66,     kl: 12.04, 11.76,     l2: 2.51997,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:717, step:17950 (TRAIN, VALID): total: 2042.95, 2046.97      recon: 2028.48, 2032.76,     kl: 11.95, 11.69,     l2: 2.51961,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:718, step:17975 (TRAIN, VALID): total: 2043.07, 2047.25      recon: 2028.58, 2032.97,     kl: 11.96, 11.76,     l2: 2.51974,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:719, step:18000 (TRAIN, VALID): total: 2043.18, 2047.39      recon: 2028.59, 2032.95,     kl: 12.06, 11.93,     l2: 2.52033,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000660.\n",
      "Epoch:720, step:18025 (TRAIN, VALID): total: 2043.14, 2047.77      recon: 2028.56, 2033.41,     kl: 12.07, 11.84,     l2: 2.51989,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:721, step:18050 (TRAIN, VALID): total: 2042.94, 2046.32      recon: 2028.40, 2032.08,     kl: 12.02, 11.72,     l2: 2.52026,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:722, step:18075 (TRAIN, VALID): total: 2042.91, 2046.45      recon: 2028.51, 2032.21,     kl: 11.88, 11.71,     l2: 2.52024,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:723, step:18100 (TRAIN, VALID): total: 2042.94, 2047.72      recon: 2028.48, 2033.44,     kl: 11.94, 11.77,     l2: 2.52064,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:724, step:18125 (TRAIN, VALID): total: 2043.07, 2047.06      recon: 2028.49, 2032.78,     kl: 12.07, 11.76,     l2: 2.52011,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:725, step:18150 (TRAIN, VALID): total: 2042.96, 2047.74      recon: 2028.41, 2033.41,     kl: 12.03, 11.82,     l2: 2.52069,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:726, step:18175 (TRAIN, VALID): total: 2042.88, 2046.73      recon: 2028.38, 2032.52,     kl: 11.98, 11.69,     l2: 2.52065,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:727, step:18200 (TRAIN, VALID): total: 2042.85, 2047.90      recon: 2028.42, 2033.67,     kl: 11.91, 11.71,     l2: 2.52101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:728, step:18225 (TRAIN, VALID): total: 2042.85, 2046.64      recon: 2028.39, 2032.46,     kl: 11.93, 11.66,     l2: 2.52063,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:729, step:18250 (TRAIN, VALID): total: 2042.78, 2046.58      recon: 2028.38, 2032.40,     kl: 11.88, 11.65,     l2: 2.52102,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:730, step:18275 (TRAIN, VALID): total: 2042.89, 2046.50      recon: 2028.40, 2032.24,     kl: 11.97, 11.74,     l2: 2.52095,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:731, step:18300 (TRAIN, VALID): total: 2043.01, 2045.82      recon: 2028.55, 2031.54,     kl: 11.94, 11.76,     l2: 2.52052,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000627.\n",
      "Epoch:732, step:18325 (TRAIN, VALID): total: 2043.24, 2046.97      recon: 2028.70, 2032.71,     kl: 12.02, 11.74,     l2: 2.52101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:733, step:18350 (TRAIN, VALID): total: 2043.01, 2046.06      recon: 2028.50, 2031.79,     kl: 11.99, 11.75,     l2: 2.52136,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:734, step:18375 (TRAIN, VALID): total: 2042.99, 2047.31      recon: 2028.51, 2033.05,     kl: 11.95, 11.74,     l2: 2.52168,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:735, step:18400 (TRAIN, VALID): total: 2042.85, 2047.61      recon: 2028.37, 2033.40,     kl: 11.96, 11.69,     l2: 2.52124,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:736, step:18425 (TRAIN, VALID): total: 2043.28, 2046.08      recon: 2028.61, 2031.53,     kl: 12.15, 12.03,     l2: 2.52248,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:737, step:18450 (TRAIN, VALID): total: 2042.86, 2045.73      recon: 2028.29, 2031.51,     kl: 12.05, 11.70,     l2: 2.52256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:738, step:18475 (TRAIN, VALID): total: 2042.85, 2048.33      recon: 2028.41, 2034.08,     kl: 11.92, 11.73,     l2: 2.52178,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:739, step:18500 (TRAIN, VALID): total: 2042.90, 2048.02      recon: 2028.35, 2033.49,     kl: 12.03, 12.01,     l2: 2.52193,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:740, step:18525 (TRAIN, VALID): total: 2043.07, 2047.34      recon: 2028.39, 2033.00,     kl: 12.15, 11.81,     l2: 2.52270,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:741, step:18550 (TRAIN, VALID): total: 2042.92, 2046.67      recon: 2028.37, 2032.36,     kl: 12.03, 11.79,     l2: 2.52205,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:742, step:18575 (TRAIN, VALID): total: 2042.83, 2046.40      recon: 2028.35, 2032.11,     kl: 11.96, 11.77,     l2: 2.52222,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:743, step:18600 (TRAIN, VALID): total: 2042.96, 2045.40      recon: 2028.43, 2031.12,     kl: 12.01, 11.76,     l2: 2.52266,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:744, step:18625 (TRAIN, VALID): total: 2042.94, 2046.55      recon: 2028.38, 2032.17,     kl: 12.04, 11.86,     l2: 2.52232,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:745, step:18650 (TRAIN, VALID): total: 2042.84, 2046.32      recon: 2028.29, 2032.10,     kl: 12.03, 11.69,     l2: 2.52212,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:746, step:18675 (TRAIN, VALID): total: 2042.94, 2047.59      recon: 2028.45, 2033.23,     kl: 11.97, 11.84,     l2: 2.52190,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:747, step:18700 (TRAIN, VALID): total: 2042.83, 2046.79      recon: 2028.35, 2032.64,     kl: 11.97, 11.63,     l2: 2.52151,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:748, step:18725 (TRAIN, VALID): total: 2042.86, 2046.80      recon: 2028.42, 2032.59,     kl: 11.93, 11.69,     l2: 2.52252,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:749, step:18750 (TRAIN, VALID): total: 2042.87, 2047.48      recon: 2028.41, 2033.21,     kl: 11.94, 11.75,     l2: 2.52210,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:750, step:18775 (TRAIN, VALID): total: 2042.76, 2046.40      recon: 2028.28, 2032.19,     kl: 11.96, 11.70,     l2: 2.52254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:751, step:18800 (TRAIN, VALID): total: 2042.88, 2047.37      recon: 2028.45, 2033.15,     kl: 11.90, 11.69,     l2: 2.52210,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:752, step:18825 (TRAIN, VALID): total: 2042.96, 2046.98      recon: 2028.51, 2032.69,     kl: 11.92, 11.76,     l2: 2.52255,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000595.\n",
      "Epoch:753, step:18850 (TRAIN, VALID): total: 2043.07, 2046.37      recon: 2028.38, 2031.85,     kl: 12.16, 12.00,     l2: 2.52245,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:754, step:18875 (TRAIN, VALID): total: 2042.87, 2046.95      recon: 2028.32, 2032.74,     kl: 12.03, 11.69,     l2: 2.52264,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:755, step:18900 (TRAIN, VALID): total: 2042.85, 2047.35      recon: 2028.31, 2033.02,     kl: 12.01, 11.80,     l2: 2.52284,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:756, step:18925 (TRAIN, VALID): total: 2043.00, 2046.36      recon: 2028.41, 2032.03,     kl: 12.07, 11.81,     l2: 2.52254,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:757, step:18950 (TRAIN, VALID): total: 2042.71, 2046.66      recon: 2028.20, 2032.47,     kl: 11.99, 11.67,     l2: 2.52333,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:758, step:18975 (TRAIN, VALID): total: 2042.75, 2047.20      recon: 2028.28, 2032.89,     kl: 11.95, 11.79,     l2: 2.52360,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:759, step:19000 (TRAIN, VALID): total: 2042.84, 2047.21      recon: 2028.35, 2032.96,     kl: 11.97, 11.72,     l2: 2.52308,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:760, step:19025 (TRAIN, VALID): total: 2042.84, 2047.07      recon: 2028.35, 2032.84,     kl: 11.97, 11.70,     l2: 2.52306,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:761, step:19050 (TRAIN, VALID): total: 2043.03, 2046.15      recon: 2028.54, 2031.83,     kl: 11.97, 11.80,     l2: 2.52317,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000566.\n",
      "Epoch:762, step:19075 (TRAIN, VALID): total: 2042.74, 2047.12      recon: 2028.24, 2032.88,     kl: 11.98, 11.72,     l2: 2.52259,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:763, step:19100 (TRAIN, VALID): total: 2042.76, 2047.46      recon: 2028.31, 2033.24,     kl: 11.93, 11.70,     l2: 2.52240,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:764, step:19125 (TRAIN, VALID): total: 2042.65, 2046.60      recon: 2028.16, 2032.39,     kl: 11.96, 11.69,     l2: 2.52303,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:765, step:19150 (TRAIN, VALID): total: 2042.69, 2047.48      recon: 2028.21, 2033.27,     kl: 11.95, 11.69,     l2: 2.52343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:766, step:19175 (TRAIN, VALID): total: 2042.93, 2046.69      recon: 2028.47, 2032.33,     kl: 11.93, 11.84,     l2: 2.52344,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:767, step:19200 (TRAIN, VALID): total: 2042.82, 2046.19      recon: 2028.28, 2031.92,     kl: 12.02, 11.74,     l2: 2.52323,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:768, step:19225 (TRAIN, VALID): total: 2042.81, 2048.58      recon: 2028.30, 2034.23,     kl: 11.99, 11.83,     l2: 2.52278,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:769, step:19250 (TRAIN, VALID): total: 2043.13, 2047.28      recon: 2028.56, 2032.97,     kl: 12.04, 11.79,     l2: 2.52303,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000537.\n",
      "Epoch:770, step:19275 (TRAIN, VALID): total: 2042.90, 2047.98      recon: 2028.35, 2033.67,     kl: 12.03, 11.79,     l2: 2.52347,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:771, step:19300 (TRAIN, VALID): total: 2042.84, 2047.75      recon: 2028.37, 2033.52,     kl: 11.94, 11.71,     l2: 2.52335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:772, step:19325 (TRAIN, VALID): total: 2042.80, 2046.10      recon: 2028.32, 2031.88,     kl: 11.95, 11.70,     l2: 2.52284,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:773, step:19350 (TRAIN, VALID): total: 2042.83, 2047.52      recon: 2028.33, 2033.15,     kl: 11.98, 11.85,     l2: 2.52256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:774, step:19375 (TRAIN, VALID): total: 2042.81, 2045.28      recon: 2028.27, 2031.02,     kl: 12.02, 11.74,     l2: 2.52322,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:775, step:19400 (TRAIN, VALID): total: 2042.76, 2046.59      recon: 2028.21, 2032.30,     kl: 12.02, 11.77,     l2: 2.52327,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:776, step:19425 (TRAIN, VALID): total: 2042.73, 2046.90      recon: 2028.23, 2032.61,     kl: 11.97, 11.77,     l2: 2.52339,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:777, step:19450 (TRAIN, VALID): total: 2042.74, 2047.50      recon: 2028.19, 2033.23,     kl: 12.03, 11.74,     l2: 2.52360,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:778, step:19475 (TRAIN, VALID): total: 2042.85, 2046.78      recon: 2028.35, 2032.48,     kl: 11.97, 11.78,     l2: 2.52380,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000510.\n",
      "Epoch:779, step:19500 (TRAIN, VALID): total: 2042.68, 2046.67      recon: 2028.14, 2032.38,     kl: 12.02, 11.76,     l2: 2.52370,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:780, step:19525 (TRAIN, VALID): total: 2042.75, 2046.33      recon: 2028.21, 2032.10,     kl: 12.02, 11.70,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:781, step:19550 (TRAIN, VALID): total: 2042.71, 2046.92      recon: 2028.20, 2032.61,     kl: 11.98, 11.78,     l2: 2.52426,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:782, step:19575 (TRAIN, VALID): total: 2042.66, 2046.51      recon: 2028.15, 2032.26,     kl: 11.98, 11.73,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:783, step:19600 (TRAIN, VALID): total: 2043.14, 2046.56      recon: 2028.62, 2032.06,     kl: 12.00, 11.97,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:784, step:19625 (TRAIN, VALID): total: 2042.79, 2046.63      recon: 2028.12, 2032.37,     kl: 12.15, 11.73,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:785, step:19650 (TRAIN, VALID): total: 2042.73, 2046.82      recon: 2028.25, 2032.53,     kl: 11.96, 11.77,     l2: 2.52418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:786, step:19675 (TRAIN, VALID): total: 2042.71, 2047.32      recon: 2028.19, 2033.04,     kl: 12.00, 11.75,     l2: 2.52379,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:787, step:19700 (TRAIN, VALID): total: 2042.65, 2045.83      recon: 2028.16, 2031.59,     kl: 11.96, 11.71,     l2: 2.52402,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:788, step:19725 (TRAIN, VALID): total: 2042.75, 2047.03      recon: 2028.25, 2032.76,     kl: 11.98, 11.74,     l2: 2.52404,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:789, step:19750 (TRAIN, VALID): total: 2042.75, 2045.43      recon: 2028.24, 2031.15,     kl: 11.98, 11.76,     l2: 2.52398,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:790, step:19775 (TRAIN, VALID): total: 2042.68, 2047.16      recon: 2028.22, 2032.86,     kl: 11.93, 11.77,     l2: 2.52418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:791, step:19800 (TRAIN, VALID): total: 2042.85, 2047.28      recon: 2028.29, 2032.95,     kl: 12.03, 11.80,     l2: 2.52391,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000485.\n",
      "Epoch:792, step:19825 (TRAIN, VALID): total: 2042.68, 2046.94      recon: 2028.19, 2032.71,     kl: 11.97, 11.70,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:793, step:19850 (TRAIN, VALID): total: 2042.88, 2047.32      recon: 2028.32, 2032.91,     kl: 12.03, 11.88,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:794, step:19875 (TRAIN, VALID): total: 2042.71, 2046.14      recon: 2028.11, 2031.83,     kl: 12.08, 11.79,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:795, step:19900 (TRAIN, VALID): total: 2042.67, 2048.65      recon: 2028.16, 2034.36,     kl: 11.99, 11.76,     l2: 2.52411,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:796, step:19925 (TRAIN, VALID): total: 2042.70, 2047.24      recon: 2028.20, 2032.96,     kl: 11.98, 11.75,     l2: 2.52407,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:797, step:19950 (TRAIN, VALID): total: 2042.62, 2046.60      recon: 2028.11, 2032.34,     kl: 11.98, 11.74,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:798, step:19975 (TRAIN, VALID): total: 2042.72, 2045.72      recon: 2028.24, 2031.42,     kl: 11.96, 11.77,     l2: 2.52409,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:799, step:20000 (TRAIN, VALID): total: 2042.59, 2046.96      recon: 2028.08, 2032.71,     kl: 11.98, 11.72,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:800, step:20025 (TRAIN, VALID): total: 2042.72, 2046.11      recon: 2028.29, 2031.81,     kl: 11.91, 11.77,     l2: 2.52457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:801, step:20050 (TRAIN, VALID): total: 2042.65, 2046.58      recon: 2028.07, 2032.25,     kl: 12.06, 11.80,     l2: 2.52427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:802, step:20075 (TRAIN, VALID): total: 2042.74, 2047.37      recon: 2028.17, 2033.00,     kl: 12.05, 11.84,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000461.\n",
      "Epoch:803, step:20100 (TRAIN, VALID): total: 2042.78, 2048.72      recon: 2028.25, 2034.37,     kl: 12.00, 11.82,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:804, step:20125 (TRAIN, VALID): total: 2042.62, 2047.08      recon: 2028.08, 2032.83,     kl: 12.02, 11.72,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:805, step:20150 (TRAIN, VALID): total: 2042.65, 2046.61      recon: 2028.13, 2032.32,     kl: 12.00, 11.77,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:806, step:20175 (TRAIN, VALID): total: 2042.66, 2047.83      recon: 2028.16, 2033.52,     kl: 11.97, 11.79,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:807, step:20200 (TRAIN, VALID): total: 2042.70, 2048.01      recon: 2028.19, 2033.75,     kl: 11.99, 11.74,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:808, step:20225 (TRAIN, VALID): total: 2042.58, 2047.49      recon: 2028.12, 2033.24,     kl: 11.94, 11.73,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:809, step:20250 (TRAIN, VALID): total: 2042.97, 2047.07      recon: 2028.46, 2032.75,     kl: 11.98, 11.80,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000438.\n",
      "Epoch:810, step:20275 (TRAIN, VALID): total: 2042.73, 2046.96      recon: 2028.10, 2032.57,     kl: 12.10, 11.87,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:811, step:20300 (TRAIN, VALID): total: 2042.63, 2046.88      recon: 2028.12, 2032.62,     kl: 11.98, 11.73,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:812, step:20325 (TRAIN, VALID): total: 2042.58, 2046.67      recon: 2028.06, 2032.39,     kl: 12.00, 11.75,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:813, step:20350 (TRAIN, VALID): total: 2042.52, 2046.98      recon: 2028.04, 2032.74,     kl: 11.96, 11.71,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:814, step:20375 (TRAIN, VALID): total: 2042.62, 2047.31      recon: 2028.16, 2033.12,     kl: 11.94, 11.67,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:815, step:20400 (TRAIN, VALID): total: 2042.69, 2047.25      recon: 2028.22, 2032.97,     kl: 11.94, 11.75,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:816, step:20425 (TRAIN, VALID): total: 2042.50, 2046.35      recon: 2028.00, 2032.02,     kl: 11.98, 11.81,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:817, step:20450 (TRAIN, VALID): total: 2042.53, 2047.68      recon: 2028.01, 2033.45,     kl: 11.99, 11.70,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:818, step:20475 (TRAIN, VALID): total: 2042.60, 2047.01      recon: 2028.16, 2032.76,     kl: 11.91, 11.73,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:819, step:20500 (TRAIN, VALID): total: 2042.62, 2046.91      recon: 2028.12, 2032.62,     kl: 11.98, 11.76,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:820, step:20525 (TRAIN, VALID): total: 2042.61, 2046.10      recon: 2028.10, 2031.87,     kl: 11.99, 11.70,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:821, step:20550 (TRAIN, VALID): total: 2042.59, 2046.87      recon: 2028.06, 2032.47,     kl: 12.01, 11.87,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:822, step:20575 (TRAIN, VALID): total: 2042.58, 2046.79      recon: 2028.02, 2032.52,     kl: 12.03, 11.74,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:823, step:20600 (TRAIN, VALID): total: 2042.57, 2046.37      recon: 2028.09, 2032.11,     kl: 11.96, 11.73,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:824, step:20625 (TRAIN, VALID): total: 2042.59, 2045.13      recon: 2028.08, 2030.89,     kl: 11.99, 11.71,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:825, step:20650 (TRAIN, VALID): total: 2043.08, 2047.37      recon: 2028.48, 2032.91,     kl: 12.08, 11.94,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000416.\n",
      "Epoch:826, step:20675 (TRAIN, VALID): total: 2042.75, 2047.18      recon: 2028.12, 2032.80,     kl: 12.10, 11.85,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:827, step:20700 (TRAIN, VALID): total: 2042.60, 2046.93      recon: 2027.99, 2032.62,     kl: 12.08, 11.78,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:828, step:20725 (TRAIN, VALID): total: 2042.51, 2046.85      recon: 2027.98, 2032.58,     kl: 12.00, 11.74,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:829, step:20750 (TRAIN, VALID): total: 2042.82, 2046.69      recon: 2028.29, 2032.41,     kl: 12.01, 11.76,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:830, step:20775 (TRAIN, VALID): total: 2042.77, 2046.23      recon: 2028.21, 2031.87,     kl: 12.03, 11.84,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:831, step:20800 (TRAIN, VALID): total: 2042.52, 2046.13      recon: 2028.00, 2031.90,     kl: 11.99, 11.70,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:832, step:20825 (TRAIN, VALID): total: 2042.55, 2047.72      recon: 2028.06, 2033.41,     kl: 11.96, 11.79,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:833, step:20850 (TRAIN, VALID): total: 2042.83, 2046.59      recon: 2028.27, 2032.33,     kl: 12.04, 11.74,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000395.\n",
      "Epoch:834, step:20875 (TRAIN, VALID): total: 2042.49, 2047.47      recon: 2028.00, 2033.20,     kl: 11.96, 11.74,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:835, step:20900 (TRAIN, VALID): total: 2042.43, 2046.45      recon: 2027.99, 2032.22,     kl: 11.92, 11.70,     l2: 2.52583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:836, step:20925 (TRAIN, VALID): total: 2042.54, 2046.11      recon: 2028.03, 2031.78,     kl: 11.98, 11.80,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:837, step:20950 (TRAIN, VALID): total: 2042.57, 2047.23      recon: 2028.04, 2032.93,     kl: 12.00, 11.77,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:838, step:20975 (TRAIN, VALID): total: 2042.53, 2046.68      recon: 2028.02, 2032.36,     kl: 11.98, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:839, step:21000 (TRAIN, VALID): total: 2042.48, 2047.19      recon: 2027.97, 2032.86,     kl: 11.99, 11.81,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:840, step:21025 (TRAIN, VALID): total: 2042.49, 2047.10      recon: 2027.92, 2032.84,     kl: 12.04, 11.73,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:841, step:21050 (TRAIN, VALID): total: 2042.42, 2047.64      recon: 2027.96, 2033.44,     kl: 11.93, 11.67,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:842, step:21075 (TRAIN, VALID): total: 2042.75, 2046.84      recon: 2028.19, 2032.41,     kl: 12.03, 11.91,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000375.\n",
      "Epoch:843, step:21100 (TRAIN, VALID): total: 2042.64, 2047.06      recon: 2027.99, 2032.72,     kl: 12.12, 11.82,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:844, step:21125 (TRAIN, VALID): total: 2042.55, 2047.13      recon: 2028.05, 2032.85,     kl: 11.98, 11.75,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:845, step:21150 (TRAIN, VALID): total: 2042.61, 2047.82      recon: 2028.07, 2033.49,     kl: 12.02, 11.81,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:846, step:21175 (TRAIN, VALID): total: 2042.80, 2046.80      recon: 2028.26, 2032.43,     kl: 12.02, 11.84,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:847, step:21200 (TRAIN, VALID): total: 2042.62, 2045.64      recon: 2028.08, 2031.33,     kl: 12.02, 11.79,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:848, step:21225 (TRAIN, VALID): total: 2042.50, 2047.21      recon: 2027.95, 2032.93,     kl: 12.02, 11.75,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:849, step:21250 (TRAIN, VALID): total: 2042.56, 2046.89      recon: 2028.03, 2032.59,     kl: 12.01, 11.77,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:850, step:21275 (TRAIN, VALID): total: 2042.49, 2046.01      recon: 2027.97, 2031.72,     kl: 12.00, 11.77,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:851, step:21300 (TRAIN, VALID): total: 2042.63, 2046.55      recon: 2028.11, 2032.25,     kl: 11.99, 11.77,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:852, step:21325 (TRAIN, VALID): total: 2042.53, 2046.55      recon: 2028.00, 2032.24,     kl: 12.01, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:853, step:21350 (TRAIN, VALID): total: 2042.50, 2045.88      recon: 2027.96, 2031.57,     kl: 12.02, 11.79,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:854, step:21375 (TRAIN, VALID): total: 2042.44, 2046.81      recon: 2027.95, 2032.55,     kl: 11.97, 11.73,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:855, step:21400 (TRAIN, VALID): total: 2042.55, 2047.70      recon: 2028.00, 2033.39,     kl: 12.03, 11.79,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:856, step:21425 (TRAIN, VALID): total: 2042.73, 2046.29      recon: 2028.21, 2032.02,     kl: 12.00, 11.74,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000356.\n",
      "Epoch:857, step:21450 (TRAIN, VALID): total: 2042.65, 2046.61      recon: 2028.14, 2032.32,     kl: 11.99, 11.77,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:858, step:21475 (TRAIN, VALID): total: 2042.48, 2046.64      recon: 2027.95, 2032.30,     kl: 12.00, 11.81,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:859, step:21500 (TRAIN, VALID): total: 2042.47, 2047.92      recon: 2027.93, 2033.56,     kl: 12.02, 11.83,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:860, step:21525 (TRAIN, VALID): total: 2042.76, 2047.37      recon: 2028.18, 2033.02,     kl: 12.06, 11.83,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:861, step:21550 (TRAIN, VALID): total: 2042.54, 2046.08      recon: 2027.94, 2031.72,     kl: 12.07, 11.84,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:862, step:21575 (TRAIN, VALID): total: 2042.49, 2047.88      recon: 2027.94, 2033.62,     kl: 12.02, 11.74,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:863, step:21600 (TRAIN, VALID): total: 2042.45, 2046.55      recon: 2027.94, 2032.17,     kl: 11.98, 11.85,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:864, step:21625 (TRAIN, VALID): total: 2042.27, 2047.57      recon: 2027.72, 2033.31,     kl: 12.03, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:865, step:21650 (TRAIN, VALID): total: 2042.42, 2047.31      recon: 2027.95, 2033.09,     kl: 11.95, 11.69,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:866, step:21675 (TRAIN, VALID): total: 2042.43, 2047.01      recon: 2027.95, 2032.75,     kl: 11.95, 11.73,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:867, step:21700 (TRAIN, VALID): total: 2042.49, 2047.52      recon: 2028.00, 2033.22,     kl: 11.97, 11.78,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:868, step:21725 (TRAIN, VALID): total: 2042.47, 2046.88      recon: 2027.96, 2032.57,     kl: 11.98, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:869, step:21750 (TRAIN, VALID): total: 2042.45, 2046.37      recon: 2027.95, 2032.05,     kl: 11.98, 11.79,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:870, step:21775 (TRAIN, VALID): total: 2042.49, 2046.86      recon: 2027.94, 2032.54,     kl: 12.03, 11.79,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000339.\n",
      "Epoch:871, step:21800 (TRAIN, VALID): total: 2042.52, 2046.34      recon: 2027.90, 2031.98,     kl: 12.10, 11.83,     l2: 2.52595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:872, step:21825 (TRAIN, VALID): total: 2042.39, 2046.18      recon: 2027.86, 2031.89,     kl: 12.00, 11.76,     l2: 2.52593,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:873, step:21850 (TRAIN, VALID): total: 2042.49, 2047.67      recon: 2028.01, 2033.44,     kl: 11.95, 11.70,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:874, step:21875 (TRAIN, VALID): total: 2042.42, 2047.22      recon: 2027.93, 2032.99,     kl: 11.96, 11.70,     l2: 2.52592,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:875, step:21900 (TRAIN, VALID): total: 2042.39, 2047.90      recon: 2027.91, 2033.63,     kl: 11.96, 11.74,     l2: 2.52596,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:876, step:21925 (TRAIN, VALID): total: 2042.64, 2047.76      recon: 2028.15, 2033.45,     kl: 11.97, 11.79,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:877, step:21950 (TRAIN, VALID): total: 2042.40, 2047.06      recon: 2027.86, 2032.77,     kl: 12.01, 11.77,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:878, step:21975 (TRAIN, VALID): total: 2042.37, 2046.09      recon: 2027.85, 2031.81,     kl: 11.99, 11.75,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:879, step:22000 (TRAIN, VALID): total: 2042.35, 2045.58      recon: 2027.87, 2031.30,     kl: 11.95, 11.76,     l2: 2.52587,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:880, step:22025 (TRAIN, VALID): total: 2042.52, 2046.90      recon: 2028.02, 2032.61,     kl: 11.97, 11.76,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:881, step:22050 (TRAIN, VALID): total: 2042.48, 2047.86      recon: 2028.02, 2033.62,     kl: 11.94, 11.72,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:882, step:22075 (TRAIN, VALID): total: 2042.41, 2047.28      recon: 2027.94, 2032.99,     kl: 11.94, 11.76,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:883, step:22100 (TRAIN, VALID): total: 2042.67, 2047.25      recon: 2028.08, 2032.87,     kl: 12.07, 11.85,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000322.\n",
      "Epoch:884, step:22125 (TRAIN, VALID): total: 2042.46, 2046.09      recon: 2027.89, 2031.82,     kl: 12.05, 11.75,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:885, step:22150 (TRAIN, VALID): total: 2042.69, 2046.38      recon: 2028.13, 2032.08,     kl: 12.03, 11.78,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:886, step:22175 (TRAIN, VALID): total: 2042.58, 2046.68      recon: 2027.93, 2032.23,     kl: 12.13, 11.93,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:887, step:22200 (TRAIN, VALID): total: 2042.43, 2047.14      recon: 2027.86, 2032.81,     kl: 12.05, 11.80,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:888, step:22225 (TRAIN, VALID): total: 2042.31, 2045.99      recon: 2027.76, 2031.74,     kl: 12.03, 11.72,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:889, step:22250 (TRAIN, VALID): total: 2042.63, 2045.64      recon: 2028.10, 2031.31,     kl: 12.01, 11.81,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:890, step:22275 (TRAIN, VALID): total: 2042.30, 2046.43      recon: 2027.71, 2032.14,     kl: 12.07, 11.77,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:891, step:22300 (TRAIN, VALID): total: 2042.46, 2046.93      recon: 2027.94, 2032.64,     kl: 12.00, 11.76,     l2: 2.52605,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:892, step:22325 (TRAIN, VALID): total: 2042.66, 2047.17      recon: 2028.09, 2032.83,     kl: 12.05, 11.81,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000306.\n",
      "Epoch:893, step:22350 (TRAIN, VALID): total: 2042.38, 2046.57      recon: 2027.87, 2032.30,     kl: 11.98, 11.75,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:894, step:22375 (TRAIN, VALID): total: 2042.31, 2046.10      recon: 2027.82, 2031.83,     kl: 11.97, 11.75,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:895, step:22400 (TRAIN, VALID): total: 2042.31, 2046.64      recon: 2027.84, 2032.43,     kl: 11.94, 11.69,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:896, step:22425 (TRAIN, VALID): total: 2042.50, 2046.32      recon: 2028.02, 2032.02,     kl: 11.95, 11.77,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:897, step:22450 (TRAIN, VALID): total: 2042.75, 2046.16      recon: 2028.19, 2031.85,     kl: 12.04, 11.79,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:898, step:22475 (TRAIN, VALID): total: 2042.34, 2045.73      recon: 2027.84, 2031.46,     kl: 11.97, 11.74,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:899, step:22500 (TRAIN, VALID): total: 2042.58, 2045.34      recon: 2028.04, 2031.03,     kl: 12.02, 11.79,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:900, step:22525 (TRAIN, VALID): total: 2042.72, 2046.18      recon: 2028.17, 2031.86,     kl: 12.02, 11.79,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:901, step:22550 (TRAIN, VALID): total: 2042.40, 2046.39      recon: 2027.87, 2032.08,     kl: 12.00, 11.78,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:902, step:22575 (TRAIN, VALID): total: 2042.53, 2046.02      recon: 2027.95, 2031.62,     kl: 12.05, 11.87,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:903, step:22600 (TRAIN, VALID): total: 2042.52, 2047.43      recon: 2027.94, 2033.14,     kl: 12.06, 11.77,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:904, step:22625 (TRAIN, VALID): total: 2042.32, 2046.31      recon: 2027.77, 2032.07,     kl: 12.02, 11.71,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:905, step:22650 (TRAIN, VALID): total: 2042.49, 2045.90      recon: 2028.03, 2031.60,     kl: 11.94, 11.78,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:906, step:22675 (TRAIN, VALID): total: 2042.39, 2046.52      recon: 2027.84, 2032.20,     kl: 12.02, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:907, step:22700 (TRAIN, VALID): total: 2042.34, 2047.22      recon: 2027.79, 2032.90,     kl: 12.02, 11.79,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:908, step:22725 (TRAIN, VALID): total: 2042.44, 2047.02      recon: 2027.92, 2032.71,     kl: 11.99, 11.78,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:909, step:22750 (TRAIN, VALID): total: 2042.27, 2047.20      recon: 2027.76, 2032.97,     kl: 11.99, 11.71,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:910, step:22775 (TRAIN, VALID): total: 2042.46, 2046.44      recon: 2027.98, 2032.15,     kl: 11.95, 11.76,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:911, step:22800 (TRAIN, VALID): total: 2042.53, 2046.44      recon: 2027.95, 2032.08,     kl: 12.06, 11.84,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000290.\n",
      "Epoch:912, step:22825 (TRAIN, VALID): total: 2042.40, 2046.30      recon: 2027.83, 2031.98,     kl: 12.05, 11.80,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:913, step:22850 (TRAIN, VALID): total: 2042.29, 2045.91      recon: 2027.79, 2031.62,     kl: 11.97, 11.76,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:914, step:22875 (TRAIN, VALID): total: 2042.37, 2046.35      recon: 2027.85, 2032.08,     kl: 12.00, 11.74,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:915, step:22900 (TRAIN, VALID): total: 2042.29, 2046.45      recon: 2027.78, 2032.19,     kl: 11.99, 11.74,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:916, step:22925 (TRAIN, VALID): total: 2042.31, 2047.61      recon: 2027.78, 2033.31,     kl: 12.01, 11.77,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:917, step:22950 (TRAIN, VALID): total: 2042.30, 2047.49      recon: 2027.77, 2033.16,     kl: 12.00, 11.80,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:918, step:22975 (TRAIN, VALID): total: 2042.42, 2047.40      recon: 2027.88, 2033.11,     kl: 12.01, 11.77,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000276.\n",
      "Epoch:919, step:23000 (TRAIN, VALID): total: 2042.20, 2048.46      recon: 2027.70, 2034.21,     kl: 11.98, 11.72,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:920, step:23025 (TRAIN, VALID): total: 2042.37, 2045.76      recon: 2027.89, 2031.46,     kl: 11.96, 11.77,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:921, step:23050 (TRAIN, VALID): total: 2042.49, 2045.49      recon: 2027.93, 2031.16,     kl: 12.04, 11.81,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:922, step:23075 (TRAIN, VALID): total: 2042.44, 2046.55      recon: 2027.90, 2032.21,     kl: 12.01, 11.81,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:923, step:23100 (TRAIN, VALID): total: 2042.40, 2047.10      recon: 2027.85, 2032.76,     kl: 12.03, 11.81,     l2: 2.52604,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:924, step:23125 (TRAIN, VALID): total: 2042.69, 2047.67      recon: 2028.10, 2033.30,     kl: 12.07, 11.84,     l2: 2.52594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:925, step:23150 (TRAIN, VALID): total: 2042.63, 2047.32      recon: 2028.04, 2032.96,     kl: 12.06, 11.83,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:926, step:23175 (TRAIN, VALID): total: 2042.33, 2046.81      recon: 2027.73, 2032.46,     kl: 12.07, 11.82,     l2: 2.52590,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:927, step:23200 (TRAIN, VALID): total: 2042.26, 2048.42      recon: 2027.71, 2034.13,     kl: 12.02, 11.76,     l2: 2.52585,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:928, step:23225 (TRAIN, VALID): total: 2042.32, 2046.67      recon: 2027.79, 2032.37,     kl: 12.00, 11.78,     l2: 2.52581,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:929, step:23250 (TRAIN, VALID): total: 2042.30, 2046.63      recon: 2027.77, 2032.32,     kl: 12.00, 11.79,     l2: 2.52616,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:930, step:23275 (TRAIN, VALID): total: 2042.32, 2047.40      recon: 2027.79, 2033.09,     kl: 12.01, 11.78,     l2: 2.52599,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:931, step:23300 (TRAIN, VALID): total: 2042.23, 2046.27      recon: 2027.70, 2032.02,     kl: 12.01, 11.73,     l2: 2.52632,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:932, step:23325 (TRAIN, VALID): total: 2042.32, 2045.93      recon: 2027.83, 2031.64,     kl: 11.96, 11.76,     l2: 2.52597,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:933, step:23350 (TRAIN, VALID): total: 2042.56, 2046.47      recon: 2028.04, 2032.17,     kl: 12.00, 11.77,     l2: 2.52602,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000262.\n",
      "Epoch:934, step:23375 (TRAIN, VALID): total: 2042.37, 2046.56      recon: 2027.82, 2032.22,     kl: 12.03, 11.81,     l2: 2.52586,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:935, step:23400 (TRAIN, VALID): total: 2042.30, 2046.45      recon: 2027.75, 2032.13,     kl: 12.02, 11.80,     l2: 2.52602,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:936, step:23425 (TRAIN, VALID): total: 2042.32, 2047.42      recon: 2027.79, 2033.10,     kl: 12.00, 11.79,     l2: 2.52595,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:937, step:23450 (TRAIN, VALID): total: 2042.24, 2046.66      recon: 2027.71, 2032.42,     kl: 12.01, 11.72,     l2: 2.52594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:938, step:23475 (TRAIN, VALID): total: 2042.64, 2046.95      recon: 2028.15, 2032.67,     kl: 11.96, 11.76,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:939, step:23500 (TRAIN, VALID): total: 2042.34, 2046.32      recon: 2027.78, 2031.96,     kl: 12.04, 11.83,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:940, step:23525 (TRAIN, VALID): total: 2042.25, 2048.51      recon: 2027.71, 2034.25,     kl: 12.01, 11.73,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:941, step:23550 (TRAIN, VALID): total: 2042.32, 2046.44      recon: 2027.83, 2032.17,     kl: 11.96, 11.75,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:942, step:23575 (TRAIN, VALID): total: 2042.43, 2047.11      recon: 2027.88, 2032.72,     kl: 12.02, 11.87,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:943, step:23600 (TRAIN, VALID): total: 2042.38, 2047.08      recon: 2027.79, 2032.76,     kl: 12.07, 11.80,     l2: 2.52578,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:944, step:23625 (TRAIN, VALID): total: 2042.47, 2046.44      recon: 2027.94, 2032.14,     kl: 12.01, 11.77,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:945, step:23650 (TRAIN, VALID): total: 2042.32, 2046.60      recon: 2027.78, 2032.26,     kl: 12.01, 11.81,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:946, step:23675 (TRAIN, VALID): total: 2042.48, 2045.59      recon: 2027.97, 2031.30,     kl: 11.99, 11.76,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000249.\n",
      "Epoch:947, step:23700 (TRAIN, VALID): total: 2042.37, 2047.12      recon: 2027.80, 2032.77,     kl: 12.04, 11.83,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:948, step:23725 (TRAIN, VALID): total: 2042.29, 2046.09      recon: 2027.70, 2031.76,     kl: 12.06, 11.80,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:949, step:23750 (TRAIN, VALID): total: 2042.28, 2047.14      recon: 2027.71, 2032.81,     kl: 12.04, 11.81,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:950, step:23775 (TRAIN, VALID): total: 2042.21, 2046.56      recon: 2027.68, 2032.27,     kl: 12.00, 11.76,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:951, step:23800 (TRAIN, VALID): total: 2042.28, 2045.95      recon: 2027.73, 2031.62,     kl: 12.03, 11.81,     l2: 2.52567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:952, step:23825 (TRAIN, VALID): total: 2042.79, 2047.39      recon: 2028.20, 2033.00,     kl: 12.07, 11.86,     l2: 2.52583,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:953, step:23850 (TRAIN, VALID): total: 2042.29, 2046.44      recon: 2027.70, 2032.14,     kl: 12.07, 11.78,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:954, step:23875 (TRAIN, VALID): total: 2042.30, 2046.61      recon: 2027.76, 2032.32,     kl: 12.02, 11.76,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:955, step:23900 (TRAIN, VALID): total: 2042.30, 2047.90      recon: 2027.75, 2033.59,     kl: 12.03, 11.78,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:956, step:23925 (TRAIN, VALID): total: 2042.33, 2046.33      recon: 2027.76, 2032.01,     kl: 12.04, 11.79,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:957, step:23950 (TRAIN, VALID): total: 2042.38, 2047.36      recon: 2027.85, 2032.99,     kl: 12.01, 11.85,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:958, step:23975 (TRAIN, VALID): total: 2042.24, 2046.65      recon: 2027.65, 2032.25,     kl: 12.07, 11.87,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:959, step:24000 (TRAIN, VALID): total: 2042.36, 2045.77      recon: 2027.80, 2031.51,     kl: 12.03, 11.74,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:960, step:24025 (TRAIN, VALID): total: 2042.41, 2047.38      recon: 2027.85, 2033.03,     kl: 12.04, 11.83,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000236.\n",
      "Epoch:961, step:24050 (TRAIN, VALID): total: 2042.48, 2047.33      recon: 2027.92, 2033.02,     kl: 12.03, 11.79,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:962, step:24075 (TRAIN, VALID): total: 2042.40, 2045.72      recon: 2027.77, 2031.33,     kl: 12.11, 11.87,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:963, step:24100 (TRAIN, VALID): total: 2042.19, 2047.63      recon: 2027.63, 2033.33,     kl: 12.04, 11.77,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:964, step:24125 (TRAIN, VALID): total: 2042.22, 2047.30      recon: 2027.70, 2033.00,     kl: 11.99, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:965, step:24150 (TRAIN, VALID): total: 2042.31, 2046.63      recon: 2027.74, 2032.28,     kl: 12.04, 11.83,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:966, step:24175 (TRAIN, VALID): total: 2042.17, 2046.75      recon: 2027.61, 2032.42,     kl: 12.04, 11.80,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:967, step:24200 (TRAIN, VALID): total: 2042.20, 2046.45      recon: 2027.69, 2032.19,     kl: 11.99, 11.74,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:968, step:24225 (TRAIN, VALID): total: 2042.27, 2045.80      recon: 2027.74, 2031.54,     kl: 12.00, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:969, step:24250 (TRAIN, VALID): total: 2042.24, 2046.34      recon: 2027.73, 2032.02,     kl: 11.99, 11.80,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:970, step:24275 (TRAIN, VALID): total: 2042.24, 2045.82      recon: 2027.72, 2031.52,     kl: 12.00, 11.77,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:971, step:24300 (TRAIN, VALID): total: 2042.48, 2047.84      recon: 2027.95, 2033.43,     kl: 12.01, 11.88,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000225.\n",
      "Epoch:972, step:24325 (TRAIN, VALID): total: 2042.24, 2046.82      recon: 2027.63, 2032.46,     kl: 12.09, 11.83,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:973, step:24350 (TRAIN, VALID): total: 2042.14, 2047.01      recon: 2027.61, 2032.75,     kl: 12.01, 11.74,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:974, step:24375 (TRAIN, VALID): total: 2042.43, 2046.50      recon: 2027.92, 2032.17,     kl: 11.99, 11.80,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:975, step:24400 (TRAIN, VALID): total: 2042.25, 2047.34      recon: 2027.68, 2033.02,     kl: 12.04, 11.80,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:976, step:24425 (TRAIN, VALID): total: 2042.28, 2046.36      recon: 2027.73, 2032.00,     kl: 12.03, 11.84,     l2: 2.52545,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:977, step:24450 (TRAIN, VALID): total: 2042.44, 2046.58      recon: 2027.85, 2032.16,     kl: 12.06, 11.90,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:978, step:24475 (TRAIN, VALID): total: 2042.22, 2045.64      recon: 2027.60, 2031.30,     kl: 12.09, 11.81,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:979, step:24500 (TRAIN, VALID): total: 2042.29, 2046.28      recon: 2027.74, 2031.95,     kl: 12.02, 11.81,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:980, step:24525 (TRAIN, VALID): total: 2042.34, 2046.62      recon: 2027.79, 2032.31,     kl: 12.03, 11.78,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:981, step:24550 (TRAIN, VALID): total: 2042.22, 2045.90      recon: 2027.68, 2031.58,     kl: 12.02, 11.79,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:982, step:24575 (TRAIN, VALID): total: 2042.48, 2047.52      recon: 2027.91, 2033.14,     kl: 12.05, 11.86,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000213.\n",
      "Epoch:983, step:24600 (TRAIN, VALID): total: 2042.40, 2046.70      recon: 2027.85, 2032.40,     kl: 12.03, 11.78,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:984, step:24625 (TRAIN, VALID): total: 2042.38, 2046.43      recon: 2027.86, 2032.13,     kl: 11.99, 11.78,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:985, step:24650 (TRAIN, VALID): total: 2042.31, 2046.28      recon: 2027.72, 2031.89,     kl: 12.06, 11.86,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:986, step:24675 (TRAIN, VALID): total: 2042.29, 2047.14      recon: 2027.71, 2032.80,     kl: 12.06, 11.81,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:987, step:24700 (TRAIN, VALID): total: 2042.20, 2046.01      recon: 2027.65, 2031.75,     kl: 12.02, 11.74,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:988, step:24725 (TRAIN, VALID): total: 2042.24, 2044.70      recon: 2027.66, 2030.34,     kl: 12.06, 11.83,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:989, step:24750 (TRAIN, VALID): total: 2042.23, 2046.66      recon: 2027.66, 2032.34,     kl: 12.04, 11.80,     l2: 2.52557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:990, step:24775 (TRAIN, VALID): total: 2042.22, 2047.40      recon: 2027.69, 2033.11,     kl: 12.01, 11.76,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:991, step:24800 (TRAIN, VALID): total: 2042.18, 2046.02      recon: 2027.66, 2031.72,     kl: 11.99, 11.77,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:992, step:24825 (TRAIN, VALID): total: 2042.14, 2046.68      recon: 2027.64, 2032.41,     kl: 11.97, 11.75,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:993, step:24850 (TRAIN, VALID): total: 2042.25, 2046.45      recon: 2027.74, 2032.13,     kl: 11.98, 11.79,     l2: 2.52599,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000203.\n",
      "Epoch:994, step:24875 (TRAIN, VALID): total: 2042.41, 2047.88      recon: 2027.84, 2033.55,     kl: 12.04, 11.80,     l2: 2.52586,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:995, step:24900 (TRAIN, VALID): total: 2042.42, 2046.47      recon: 2027.84, 2032.13,     kl: 12.06, 11.81,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:996, step:24925 (TRAIN, VALID): total: 2042.26, 2046.65      recon: 2027.69, 2032.30,     kl: 12.04, 11.82,     l2: 2.52579,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:997, step:24950 (TRAIN, VALID): total: 2042.25, 2046.36      recon: 2027.71, 2032.03,     kl: 12.02, 11.81,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:998, step:24975 (TRAIN, VALID): total: 2042.29, 2045.74      recon: 2027.75, 2031.45,     kl: 12.02, 11.76,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:999, step:25000 (TRAIN, VALID): total: 2042.18, 2046.01      recon: 2027.65, 2031.73,     kl: 12.01, 11.76,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1000, step:25025 (TRAIN, VALID): total: 2042.29, 2046.89      recon: 2027.76, 2032.59,     kl: 12.00, 11.77,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1001, step:25050 (TRAIN, VALID): total: 2042.17, 2047.47      recon: 2027.65, 2033.16,     kl: 12.00, 11.78,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1002, step:25075 (TRAIN, VALID): total: 2042.14, 2046.73      recon: 2027.61, 2032.48,     kl: 12.01, 11.73,     l2: 2.52566,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1003, step:25100 (TRAIN, VALID): total: 2042.05, 2047.25      recon: 2027.56, 2033.00,     kl: 11.97, 11.73,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1004, step:25125 (TRAIN, VALID): total: 2042.27, 2047.01      recon: 2027.78, 2032.71,     kl: 11.96, 11.77,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1005, step:25150 (TRAIN, VALID): total: 2042.39, 2046.81      recon: 2027.83, 2032.42,     kl: 12.04, 11.87,     l2: 2.52560,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000193.\n",
      "Epoch:1006, step:25175 (TRAIN, VALID): total: 2042.17, 2045.48      recon: 2027.57, 2031.14,     kl: 12.07, 11.81,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1007, step:25200 (TRAIN, VALID): total: 2042.19, 2045.48      recon: 2027.67, 2031.21,     kl: 11.99, 11.74,     l2: 2.52574,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1008, step:25225 (TRAIN, VALID): total: 2042.19, 2046.70      recon: 2027.65, 2032.39,     kl: 12.01, 11.79,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1009, step:25250 (TRAIN, VALID): total: 2042.17, 2046.15      recon: 2027.65, 2031.89,     kl: 11.99, 11.73,     l2: 2.52580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1010, step:25275 (TRAIN, VALID): total: 2042.42, 2046.14      recon: 2027.91, 2031.82,     kl: 11.98, 11.79,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1011, step:25300 (TRAIN, VALID): total: 2042.22, 2047.16      recon: 2027.68, 2032.87,     kl: 12.02, 11.77,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1012, step:25325 (TRAIN, VALID): total: 2042.18, 2046.02      recon: 2027.66, 2031.70,     kl: 12.00, 11.80,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1013, step:25350 (TRAIN, VALID): total: 2042.21, 2047.55      recon: 2027.63, 2033.22,     kl: 12.06, 11.80,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1014, step:25375 (TRAIN, VALID): total: 2042.11, 2045.00      recon: 2027.54, 2030.71,     kl: 12.04, 11.76,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1015, step:25400 (TRAIN, VALID): total: 2042.21, 2046.52      recon: 2027.68, 2032.21,     kl: 12.00, 11.79,     l2: 2.52568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1016, step:25425 (TRAIN, VALID): total: 2042.17, 2047.03      recon: 2027.66, 2032.72,     kl: 11.98, 11.78,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1017, step:25450 (TRAIN, VALID): total: 2042.19, 2047.06      recon: 2027.64, 2032.72,     kl: 12.03, 11.81,     l2: 2.52555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1018, step:25475 (TRAIN, VALID): total: 2042.13, 2046.15      recon: 2027.56, 2031.92,     kl: 12.04, 11.71,     l2: 2.52563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1019, step:25500 (TRAIN, VALID): total: 2042.23, 2047.33      recon: 2027.74, 2033.04,     kl: 11.97, 11.76,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000183.\n",
      "Epoch:1020, step:25525 (TRAIN, VALID): total: 2042.26, 2046.83      recon: 2027.71, 2032.47,     kl: 12.03, 11.84,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1021, step:25550 (TRAIN, VALID): total: 2042.24, 2047.25      recon: 2027.68, 2032.88,     kl: 12.04, 11.85,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1022, step:25575 (TRAIN, VALID): total: 2042.25, 2045.99      recon: 2027.67, 2031.65,     kl: 12.05, 11.81,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1023, step:25600 (TRAIN, VALID): total: 2042.15, 2046.59      recon: 2027.59, 2032.32,     kl: 12.04, 11.74,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1024, step:25625 (TRAIN, VALID): total: 2042.31, 2047.83      recon: 2027.77, 2033.46,     kl: 12.01, 11.85,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1025, step:25650 (TRAIN, VALID): total: 2042.18, 2047.78      recon: 2027.60, 2033.49,     kl: 12.05, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1026, step:25675 (TRAIN, VALID): total: 2042.18, 2046.14      recon: 2027.61, 2031.85,     kl: 12.04, 11.77,     l2: 2.52551,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1027, step:25700 (TRAIN, VALID): total: 2042.35, 2047.19      recon: 2027.80, 2032.86,     kl: 12.02, 11.81,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000174.\n",
      "Epoch:1028, step:25725 (TRAIN, VALID): total: 2042.09, 2046.54      recon: 2027.56, 2032.30,     kl: 12.01, 11.72,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1029, step:25750 (TRAIN, VALID): total: 2042.13, 2046.48      recon: 2027.64, 2032.22,     kl: 11.97, 11.73,     l2: 2.52575,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1030, step:25775 (TRAIN, VALID): total: 2042.33, 2046.11      recon: 2027.81, 2031.76,     kl: 12.00, 11.83,     l2: 2.52577,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1031, step:25800 (TRAIN, VALID): total: 2042.15, 2047.27      recon: 2027.59, 2032.94,     kl: 12.04, 11.80,     l2: 2.52573,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1032, step:25825 (TRAIN, VALID): total: 2042.15, 2046.30      recon: 2027.62, 2031.99,     kl: 12.00, 11.78,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1033, step:25850 (TRAIN, VALID): total: 2042.05, 2045.94      recon: 2027.51, 2031.65,     kl: 12.02, 11.77,     l2: 2.52553,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1034, step:25875 (TRAIN, VALID): total: 2042.13, 2046.44      recon: 2027.63, 2032.17,     kl: 11.97, 11.74,     l2: 2.52559,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1035, step:25900 (TRAIN, VALID): total: 2042.16, 2047.40      recon: 2027.67, 2033.12,     kl: 11.97, 11.76,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1036, step:25925 (TRAIN, VALID): total: 2042.12, 2046.78      recon: 2027.61, 2032.50,     kl: 11.99, 11.76,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1037, step:25950 (TRAIN, VALID): total: 2042.21, 2047.04      recon: 2027.73, 2032.77,     kl: 11.96, 11.75,     l2: 2.52554,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000165.\n",
      "Epoch:1038, step:25975 (TRAIN, VALID): total: 2042.54, 2046.80      recon: 2028.00, 2032.47,     kl: 12.01, 11.80,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1039, step:26000 (TRAIN, VALID): total: 2042.36, 2045.91      recon: 2027.81, 2031.56,     kl: 12.02, 11.82,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1040, step:26025 (TRAIN, VALID): total: 2042.17, 2046.46      recon: 2027.61, 2032.15,     kl: 12.04, 11.79,     l2: 2.52571,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1041, step:26050 (TRAIN, VALID): total: 2042.14, 2046.38      recon: 2027.61, 2032.12,     kl: 12.00, 11.74,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1042, step:26075 (TRAIN, VALID): total: 2042.10, 2046.70      recon: 2027.57, 2032.42,     kl: 12.00, 11.76,     l2: 2.52561,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1043, step:26100 (TRAIN, VALID): total: 2042.16, 2046.90      recon: 2027.65, 2032.54,     kl: 11.99, 11.83,     l2: 2.52576,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1044, step:26125 (TRAIN, VALID): total: 2042.18, 2047.36      recon: 2027.63, 2033.04,     kl: 12.03, 11.80,     l2: 2.52570,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1045, step:26150 (TRAIN, VALID): total: 2042.25, 2045.68      recon: 2027.70, 2031.33,     kl: 12.03, 11.83,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1046, step:26175 (TRAIN, VALID): total: 2042.39, 2047.83      recon: 2027.79, 2033.47,     kl: 12.07, 11.84,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000157.\n",
      "Epoch:1047, step:26200 (TRAIN, VALID): total: 2042.47, 2047.22      recon: 2027.90, 2032.87,     kl: 12.04, 11.83,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1048, step:26225 (TRAIN, VALID): total: 2042.11, 2046.28      recon: 2027.54, 2031.97,     kl: 12.04, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1049, step:26250 (TRAIN, VALID): total: 2042.11, 2047.66      recon: 2027.55, 2033.33,     kl: 12.04, 11.80,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1050, step:26275 (TRAIN, VALID): total: 2042.20, 2046.52      recon: 2027.69, 2032.24,     kl: 11.98, 11.75,     l2: 2.52541,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1051, step:26300 (TRAIN, VALID): total: 2042.19, 2046.13      recon: 2027.70, 2031.86,     kl: 11.96, 11.75,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1052, step:26325 (TRAIN, VALID): total: 2042.07, 2046.72      recon: 2027.52, 2032.42,     kl: 12.03, 11.78,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1053, step:26350 (TRAIN, VALID): total: 2042.32, 2046.12      recon: 2027.80, 2031.79,     kl: 11.99, 11.80,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1054, step:26375 (TRAIN, VALID): total: 2042.05, 2048.17      recon: 2027.49, 2033.83,     kl: 12.04, 11.82,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1055, step:26400 (TRAIN, VALID): total: 2042.18, 2047.17      recon: 2027.64, 2032.84,     kl: 12.01, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1056, step:26425 (TRAIN, VALID): total: 2042.24, 2045.34      recon: 2027.68, 2031.02,     kl: 12.03, 11.79,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1057, step:26450 (TRAIN, VALID): total: 2042.20, 2046.87      recon: 2027.62, 2032.50,     kl: 12.05, 11.85,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1058, step:26475 (TRAIN, VALID): total: 2042.04, 2046.34      recon: 2027.46, 2032.02,     kl: 12.05, 11.80,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1059, step:26500 (TRAIN, VALID): total: 2042.14, 2047.67      recon: 2027.60, 2033.34,     kl: 12.02, 11.80,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1060, step:26525 (TRAIN, VALID): total: 2042.13, 2046.00      recon: 2027.60, 2031.70,     kl: 12.00, 11.78,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1061, step:26550 (TRAIN, VALID): total: 2042.14, 2046.43      recon: 2027.64, 2032.14,     kl: 11.98, 11.76,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1062, step:26575 (TRAIN, VALID): total: 2042.18, 2046.30      recon: 2027.63, 2031.95,     kl: 12.02, 11.82,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1063, step:26600 (TRAIN, VALID): total: 2042.00, 2046.71      recon: 2027.45, 2032.42,     kl: 12.03, 11.76,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1064, step:26625 (TRAIN, VALID): total: 2042.03, 2047.41      recon: 2027.54, 2033.12,     kl: 11.97, 11.76,     l2: 2.52545,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1065, step:26650 (TRAIN, VALID): total: 2042.16, 2048.03      recon: 2027.65, 2033.75,     kl: 11.99, 11.76,     l2: 2.52516,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1066, step:26675 (TRAIN, VALID): total: 2042.07, 2047.51      recon: 2027.55, 2033.22,     kl: 12.00, 11.77,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1067, step:26700 (TRAIN, VALID): total: 2042.11, 2047.26      recon: 2027.56, 2032.93,     kl: 12.02, 11.80,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1068, step:26725 (TRAIN, VALID): total: 2042.14, 2046.63      recon: 2027.60, 2032.27,     kl: 12.01, 11.83,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1069, step:26750 (TRAIN, VALID): total: 2042.09, 2047.76      recon: 2027.54, 2033.47,     kl: 12.03, 11.77,     l2: 2.52550,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1070, step:26775 (TRAIN, VALID): total: 2042.17, 2046.31      recon: 2027.62, 2031.93,     kl: 12.02, 11.85,     l2: 2.52562,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000149.\n",
      "Epoch:1071, step:26800 (TRAIN, VALID): total: 2042.22, 2047.40      recon: 2027.60, 2033.02,     kl: 12.09, 11.85,     l2: 2.52558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1072, step:26825 (TRAIN, VALID): total: 2042.11, 2046.63      recon: 2027.52, 2032.29,     kl: 12.06, 11.81,     l2: 2.52569,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1073, step:26850 (TRAIN, VALID): total: 2042.10, 2046.58      recon: 2027.51, 2032.24,     kl: 12.06, 11.81,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1074, step:26875 (TRAIN, VALID): total: 2042.13, 2047.17      recon: 2027.56, 2032.86,     kl: 12.04, 11.78,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1075, step:26900 (TRAIN, VALID): total: 2042.17, 2046.61      recon: 2027.62, 2032.26,     kl: 12.03, 11.83,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1076, step:26925 (TRAIN, VALID): total: 2042.12, 2046.43      recon: 2027.57, 2032.08,     kl: 12.02, 11.82,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1077, step:26950 (TRAIN, VALID): total: 2042.05, 2046.73      recon: 2027.50, 2032.40,     kl: 12.02, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1078, step:26975 (TRAIN, VALID): total: 2042.22, 2046.88      recon: 2027.65, 2032.57,     kl: 12.04, 11.79,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000142.\n",
      "Epoch:1079, step:27000 (TRAIN, VALID): total: 2042.19, 2046.33      recon: 2027.66, 2032.01,     kl: 12.01, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1080, step:27025 (TRAIN, VALID): total: 2042.13, 2047.50      recon: 2027.58, 2033.22,     kl: 12.02, 11.76,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1081, step:27050 (TRAIN, VALID): total: 2042.07, 2046.31      recon: 2027.56, 2032.03,     kl: 11.98, 11.76,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1082, step:27075 (TRAIN, VALID): total: 2042.51, 2046.09      recon: 2027.98, 2031.73,     kl: 12.01, 11.84,     l2: 2.52493,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1083, step:27100 (TRAIN, VALID): total: 2042.17, 2046.13      recon: 2027.56, 2031.75,     kl: 12.08, 11.85,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1084, step:27125 (TRAIN, VALID): total: 2042.14, 2046.77      recon: 2027.55, 2032.42,     kl: 12.06, 11.83,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1085, step:27150 (TRAIN, VALID): total: 2042.05, 2046.25      recon: 2027.47, 2031.93,     kl: 12.05, 11.80,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1086, step:27175 (TRAIN, VALID): total: 2042.09, 2048.37      recon: 2027.54, 2034.06,     kl: 12.02, 11.79,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1087, step:27200 (TRAIN, VALID): total: 2041.95, 2046.90      recon: 2027.45, 2032.61,     kl: 11.98, 11.77,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1088, step:27225 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.53, 2032.22,     kl: 11.99, 11.74,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1089, step:27250 (TRAIN, VALID): total: 2041.96, 2047.32      recon: 2027.48, 2033.08,     kl: 11.95, 11.71,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1090, step:27275 (TRAIN, VALID): total: 2042.16, 2046.94      recon: 2027.66, 2032.67,     kl: 11.97, 11.75,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Decreasing learning rate to 0.000135.\n",
      "Epoch:1091, step:27300 (TRAIN, VALID): total: 2042.30, 2047.08      recon: 2027.72, 2032.68,     kl: 12.05, 11.87,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1092, step:27325 (TRAIN, VALID): total: 2042.08, 2046.70      recon: 2027.51, 2032.34,     kl: 12.04, 11.83,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1093, step:27350 (TRAIN, VALID): total: 2042.15, 2045.70      recon: 2027.61, 2031.40,     kl: 12.01, 11.78,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1094, step:27375 (TRAIN, VALID): total: 2042.11, 2045.57      recon: 2027.58, 2031.25,     kl: 12.00, 11.80,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1095, step:27400 (TRAIN, VALID): total: 2042.37, 2047.77      recon: 2027.82, 2033.46,     kl: 12.03, 11.79,     l2: 2.52524,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1096, step:27425 (TRAIN, VALID): total: 2042.29, 2047.53      recon: 2027.77, 2033.22,     kl: 12.00, 11.78,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1097, step:27450 (TRAIN, VALID): total: 2042.04, 2047.54      recon: 2027.50, 2033.22,     kl: 12.01, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1098, step:27475 (TRAIN, VALID): total: 2042.31, 2047.08      recon: 2027.77, 2032.71,     kl: 12.02, 11.84,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1099, step:27500 (TRAIN, VALID): total: 2042.22, 2046.17      recon: 2027.67, 2031.84,     kl: 12.02, 11.81,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1100, step:27525 (TRAIN, VALID): total: 2042.20, 2046.37      recon: 2027.61, 2032.02,     kl: 12.06, 11.82,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1101, step:27550 (TRAIN, VALID): total: 2042.15, 2046.78      recon: 2027.59, 2032.46,     kl: 12.04, 11.79,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1102, step:27575 (TRAIN, VALID): total: 2042.33, 2047.43      recon: 2027.77, 2033.10,     kl: 12.03, 11.81,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000128.\n",
      "Epoch:1103, step:27600 (TRAIN, VALID): total: 2042.17, 2046.45      recon: 2027.61, 2032.13,     kl: 12.03, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1104, step:27625 (TRAIN, VALID): total: 2042.29, 2047.02      recon: 2027.74, 2032.67,     kl: 12.03, 11.82,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1105, step:27650 (TRAIN, VALID): total: 2042.17, 2046.55      recon: 2027.60, 2032.20,     kl: 12.04, 11.82,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1106, step:27675 (TRAIN, VALID): total: 2041.95, 2047.09      recon: 2027.42, 2032.76,     kl: 12.01, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1107, step:27700 (TRAIN, VALID): total: 2042.03, 2047.25      recon: 2027.50, 2032.93,     kl: 12.00, 11.79,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1108, step:27725 (TRAIN, VALID): total: 2042.11, 2047.47      recon: 2027.60, 2033.16,     kl: 11.98, 11.78,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1109, step:27750 (TRAIN, VALID): total: 2042.06, 2047.51      recon: 2027.56, 2033.21,     kl: 11.97, 11.78,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1110, step:27775 (TRAIN, VALID): total: 2042.22, 2046.02      recon: 2027.67, 2031.69,     kl: 12.03, 11.80,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1111, step:27800 (TRAIN, VALID): total: 2042.02, 2046.87      recon: 2027.45, 2032.53,     kl: 12.04, 11.81,     l2: 2.52546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1112, step:27825 (TRAIN, VALID): total: 2042.06, 2046.20      recon: 2027.49, 2031.88,     kl: 12.04, 11.79,     l2: 2.52527,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1113, step:27850 (TRAIN, VALID): total: 2042.17, 2045.68      recon: 2027.60, 2031.29,     kl: 12.05, 11.86,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1114, step:27875 (TRAIN, VALID): total: 2042.13, 2047.43      recon: 2027.50, 2033.04,     kl: 12.11, 11.87,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1115, step:27900 (TRAIN, VALID): total: 2041.95, 2046.69      recon: 2027.35, 2032.33,     kl: 12.07, 11.83,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1116, step:27925 (TRAIN, VALID): total: 2042.08, 2047.40      recon: 2027.52, 2033.05,     kl: 12.03, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1117, step:27950 (TRAIN, VALID): total: 2042.13, 2045.93      recon: 2027.60, 2031.59,     kl: 12.01, 11.82,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1118, step:27975 (TRAIN, VALID): total: 2042.11, 2047.08      recon: 2027.56, 2032.76,     kl: 12.02, 11.80,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1119, step:28000 (TRAIN, VALID): total: 2041.96, 2045.94      recon: 2027.39, 2031.66,     kl: 12.04, 11.76,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1120, step:28025 (TRAIN, VALID): total: 2041.99, 2046.33      recon: 2027.51, 2032.05,     kl: 11.96, 11.75,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1121, step:28050 (TRAIN, VALID): total: 2042.30, 2045.65      recon: 2027.79, 2031.32,     kl: 11.98, 11.81,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000121.\n",
      "Epoch:1122, step:28075 (TRAIN, VALID): total: 2042.13, 2045.67      recon: 2027.56, 2031.37,     kl: 12.04, 11.77,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1123, step:28100 (TRAIN, VALID): total: 2041.90, 2045.70      recon: 2027.38, 2031.45,     kl: 11.99, 11.72,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1124, step:28125 (TRAIN, VALID): total: 2042.06, 2046.88      recon: 2027.56, 2032.57,     kl: 11.98, 11.78,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1125, step:28150 (TRAIN, VALID): total: 2042.03, 2046.24      recon: 2027.50, 2031.90,     kl: 12.01, 11.81,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1126, step:28175 (TRAIN, VALID): total: 2041.92, 2046.87      recon: 2027.36, 2032.54,     kl: 12.03, 11.80,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1127, step:28200 (TRAIN, VALID): total: 2042.00, 2046.92      recon: 2027.48, 2032.63,     kl: 12.00, 11.76,     l2: 2.52552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1128, step:28225 (TRAIN, VALID): total: 2042.00, 2046.84      recon: 2027.51, 2032.56,     kl: 11.97, 11.75,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1129, step:28250 (TRAIN, VALID): total: 2041.98, 2046.84      recon: 2027.49, 2032.58,     kl: 11.96, 11.74,     l2: 2.52543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1130, step:28275 (TRAIN, VALID): total: 2041.97, 2046.90      recon: 2027.52, 2032.65,     kl: 11.93, 11.73,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1131, step:28300 (TRAIN, VALID): total: 2042.16, 2046.80      recon: 2027.67, 2032.56,     kl: 11.96, 11.71,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000115.\n",
      "Epoch:1132, step:28325 (TRAIN, VALID): total: 2042.20, 2046.14      recon: 2027.68, 2031.84,     kl: 11.99, 11.78,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1133, step:28350 (TRAIN, VALID): total: 2042.07, 2046.40      recon: 2027.55, 2032.13,     kl: 11.99, 11.74,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1134, step:28375 (TRAIN, VALID): total: 2042.04, 2045.99      recon: 2027.56, 2031.70,     kl: 11.96, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1135, step:28400 (TRAIN, VALID): total: 2042.04, 2046.99      recon: 2027.54, 2032.70,     kl: 11.98, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1136, step:28425 (TRAIN, VALID): total: 2042.15, 2047.24      recon: 2027.62, 2032.90,     kl: 12.00, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1137, step:28450 (TRAIN, VALID): total: 2042.00, 2046.03      recon: 2027.41, 2031.71,     kl: 12.07, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1138, step:28475 (TRAIN, VALID): total: 2042.12, 2048.55      recon: 2027.55, 2034.20,     kl: 12.04, 11.82,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1139, step:28500 (TRAIN, VALID): total: 2042.26, 2046.59      recon: 2027.72, 2032.26,     kl: 12.01, 11.81,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000110.\n",
      "Epoch:1140, step:28525 (TRAIN, VALID): total: 2041.97, 2047.45      recon: 2027.44, 2033.12,     kl: 12.01, 11.81,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1141, step:28550 (TRAIN, VALID): total: 2042.06, 2045.83      recon: 2027.51, 2031.50,     kl: 12.02, 11.80,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1142, step:28575 (TRAIN, VALID): total: 2042.05, 2047.30      recon: 2027.51, 2033.02,     kl: 12.02, 11.76,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1143, step:28600 (TRAIN, VALID): total: 2041.96, 2046.57      recon: 2027.43, 2032.26,     kl: 12.00, 11.78,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1144, step:28625 (TRAIN, VALID): total: 2042.00, 2045.82      recon: 2027.48, 2031.54,     kl: 11.99, 11.76,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1145, step:28650 (TRAIN, VALID): total: 2042.03, 2046.40      recon: 2027.52, 2032.15,     kl: 11.99, 11.73,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1146, step:28675 (TRAIN, VALID): total: 2042.13, 2047.35      recon: 2027.59, 2033.00,     kl: 12.01, 11.83,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000104.\n",
      "Epoch:1147, step:28700 (TRAIN, VALID): total: 2041.93, 2046.13      recon: 2027.40, 2031.84,     kl: 12.01, 11.77,     l2: 2.52535,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1148, step:28725 (TRAIN, VALID): total: 2041.98, 2046.53      recon: 2027.47, 2032.24,     kl: 11.98, 11.77,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1149, step:28750 (TRAIN, VALID): total: 2041.98, 2045.86      recon: 2027.47, 2031.54,     kl: 11.99, 11.79,     l2: 2.52526,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1150, step:28775 (TRAIN, VALID): total: 2041.98, 2046.65      recon: 2027.46, 2032.34,     kl: 11.99, 11.79,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1151, step:28800 (TRAIN, VALID): total: 2042.09, 2045.96      recon: 2027.57, 2031.63,     kl: 11.99, 11.81,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1152, step:28825 (TRAIN, VALID): total: 2042.03, 2046.68      recon: 2027.46, 2032.37,     kl: 12.04, 11.78,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1153, step:28850 (TRAIN, VALID): total: 2041.94, 2048.31      recon: 2027.42, 2034.04,     kl: 12.00, 11.74,     l2: 2.52534,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1154, step:28875 (TRAIN, VALID): total: 2042.02, 2045.55      recon: 2027.54, 2031.31,     kl: 11.95, 11.71,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1155, step:28900 (TRAIN, VALID): total: 2041.96, 2045.42      recon: 2027.46, 2031.19,     kl: 11.97, 11.71,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1156, step:28925 (TRAIN, VALID): total: 2042.10, 2047.00      recon: 2027.61, 2032.72,     kl: 11.96, 11.76,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000099.\n",
      "Epoch:1157, step:28950 (TRAIN, VALID): total: 2041.99, 2046.63      recon: 2027.43, 2032.31,     kl: 12.03, 11.80,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1158, step:28975 (TRAIN, VALID): total: 2042.20, 2045.91      recon: 2027.65, 2031.61,     kl: 12.03, 11.78,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1159, step:29000 (TRAIN, VALID): total: 2042.09, 2045.92      recon: 2027.55, 2031.63,     kl: 12.01, 11.77,     l2: 2.52531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1160, step:29025 (TRAIN, VALID): total: 2041.98, 2047.31      recon: 2027.46, 2033.01,     kl: 12.00, 11.77,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1161, step:29050 (TRAIN, VALID): total: 2042.07, 2047.57      recon: 2027.55, 2033.27,     kl: 11.99, 11.78,     l2: 2.52538,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1162, step:29075 (TRAIN, VALID): total: 2042.00, 2045.68      recon: 2027.47, 2031.38,     kl: 12.01, 11.77,     l2: 2.52523,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1163, step:29100 (TRAIN, VALID): total: 2042.15, 2047.43      recon: 2027.59, 2033.11,     kl: 12.03, 11.80,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1164, step:29125 (TRAIN, VALID): total: 2042.02, 2047.45      recon: 2027.47, 2033.11,     kl: 12.02, 11.81,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1165, step:29150 (TRAIN, VALID): total: 2042.08, 2047.25      recon: 2027.53, 2032.94,     kl: 12.02, 11.79,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1166, step:29175 (TRAIN, VALID): total: 2042.01, 2046.34      recon: 2027.47, 2032.03,     kl: 12.02, 11.79,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1167, step:29200 (TRAIN, VALID): total: 2042.19, 2047.04      recon: 2027.66, 2032.73,     kl: 12.01, 11.79,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000094.\n",
      "Epoch:1168, step:29225 (TRAIN, VALID): total: 2041.95, 2047.13      recon: 2027.42, 2032.84,     kl: 12.01, 11.76,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1169, step:29250 (TRAIN, VALID): total: 2041.91, 2046.91      recon: 2027.40, 2032.63,     kl: 11.99, 11.75,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1170, step:29275 (TRAIN, VALID): total: 2042.00, 2047.22      recon: 2027.49, 2032.96,     kl: 11.99, 11.74,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1171, step:29300 (TRAIN, VALID): total: 2042.02, 2047.09      recon: 2027.51, 2032.79,     kl: 11.98, 11.78,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1172, step:29325 (TRAIN, VALID): total: 2041.93, 2047.86      recon: 2027.41, 2033.56,     kl: 11.99, 11.78,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1173, step:29350 (TRAIN, VALID): total: 2042.05, 2045.89      recon: 2027.53, 2031.58,     kl: 12.00, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1174, step:29375 (TRAIN, VALID): total: 2042.00, 2046.24      recon: 2027.45, 2031.92,     kl: 12.02, 11.79,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1175, step:29400 (TRAIN, VALID): total: 2042.20, 2046.86      recon: 2027.66, 2032.50,     kl: 12.02, 11.84,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000089.\n",
      "Epoch:1176, step:29425 (TRAIN, VALID): total: 2042.03, 2046.46      recon: 2027.47, 2032.13,     kl: 12.03, 11.81,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1177, step:29450 (TRAIN, VALID): total: 2041.98, 2048.02      recon: 2027.39, 2033.68,     kl: 12.07, 11.82,     l2: 2.52533,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1178, step:29475 (TRAIN, VALID): total: 2042.02, 2046.86      recon: 2027.44, 2032.54,     kl: 12.06, 11.80,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1179, step:29500 (TRAIN, VALID): total: 2042.15, 2047.28      recon: 2027.58, 2032.92,     kl: 12.04, 11.83,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1180, step:29525 (TRAIN, VALID): total: 2042.00, 2045.32      recon: 2027.42, 2030.95,     kl: 12.06, 11.84,     l2: 2.52544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1181, step:29550 (TRAIN, VALID): total: 2041.95, 2046.32      recon: 2027.36, 2032.01,     kl: 12.06, 11.78,     l2: 2.52556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1182, step:29575 (TRAIN, VALID): total: 2041.88, 2046.83      recon: 2027.33, 2032.52,     kl: 12.03, 11.78,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1183, step:29600 (TRAIN, VALID): total: 2042.00, 2047.80      recon: 2027.46, 2033.47,     kl: 12.01, 11.81,     l2: 2.52564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1184, step:29625 (TRAIN, VALID): total: 2042.20, 2047.63      recon: 2027.67, 2033.33,     kl: 12.00, 11.77,     l2: 2.52565,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000085.\n",
      "Epoch:1185, step:29650 (TRAIN, VALID): total: 2042.00, 2046.64      recon: 2027.45, 2032.31,     kl: 12.03, 11.81,     l2: 2.52548,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1186, step:29675 (TRAIN, VALID): total: 2042.01, 2046.37      recon: 2027.46, 2032.06,     kl: 12.02, 11.78,     l2: 2.52549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1187, step:29700 (TRAIN, VALID): total: 2041.92, 2048.16      recon: 2027.40, 2033.85,     kl: 12.00, 11.79,     l2: 2.52547,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1188, step:29725 (TRAIN, VALID): total: 2041.95, 2046.82      recon: 2027.44, 2032.52,     kl: 11.99, 11.78,     l2: 2.52540,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1189, step:29750 (TRAIN, VALID): total: 2042.02, 2045.77      recon: 2027.50, 2031.49,     kl: 11.99, 11.75,     l2: 2.52539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1190, step:29775 (TRAIN, VALID): total: 2042.05, 2046.96      recon: 2027.52, 2032.67,     kl: 12.01, 11.76,     l2: 2.52542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1191, step:29800 (TRAIN, VALID): total: 2041.91, 2046.16      recon: 2027.39, 2031.89,     kl: 11.99, 11.75,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1192, step:29825 (TRAIN, VALID): total: 2042.00, 2047.95      recon: 2027.49, 2033.65,     kl: 11.99, 11.77,     l2: 2.52521,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1193, step:29850 (TRAIN, VALID): total: 2042.18, 2046.06      recon: 2027.65, 2031.77,     kl: 12.00, 11.77,     l2: 2.52515,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000081.\n",
      "Epoch:1194, step:29875 (TRAIN, VALID): total: 2042.03, 2045.94      recon: 2027.51, 2031.68,     kl: 12.00, 11.74,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1195, step:29900 (TRAIN, VALID): total: 2041.88, 2047.97      recon: 2027.38, 2033.69,     kl: 11.98, 11.75,     l2: 2.52532,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1196, step:29925 (TRAIN, VALID): total: 2042.04, 2046.02      recon: 2027.52, 2031.73,     kl: 11.99, 11.77,     l2: 2.52530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1197, step:29950 (TRAIN, VALID): total: 2041.95, 2046.81      recon: 2027.42, 2032.49,     kl: 12.01, 11.79,     l2: 2.52536,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1198, step:29975 (TRAIN, VALID): total: 2041.96, 2046.09      recon: 2027.43, 2031.76,     kl: 12.00, 11.80,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1199, step:30000 (TRAIN, VALID): total: 2042.02, 2046.97      recon: 2027.49, 2032.66,     kl: 12.00, 11.78,     l2: 2.52537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1200, step:30025 (TRAIN, VALID): total: 2042.04, 2045.83      recon: 2027.53, 2031.48,     kl: 11.99, 11.82,     l2: 2.52529,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000077.\n",
      "Epoch:1201, step:30050 (TRAIN, VALID): total: 2042.01, 2046.35      recon: 2027.45, 2032.00,     kl: 12.03, 11.82,     l2: 2.52528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1202, step:30075 (TRAIN, VALID): total: 2042.41, 2046.61      recon: 2027.83, 2032.22,     kl: 12.06, 11.86,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1203, step:30100 (TRAIN, VALID): total: 2041.97, 2045.84      recon: 2027.38, 2031.48,     kl: 12.07, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1204, step:30125 (TRAIN, VALID): total: 2042.03, 2047.40      recon: 2027.48, 2033.07,     kl: 12.02, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1205, step:30150 (TRAIN, VALID): total: 2042.16, 2045.86      recon: 2027.60, 2031.51,     kl: 12.03, 11.83,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1206, step:30175 (TRAIN, VALID): total: 2042.17, 2046.74      recon: 2027.60, 2032.40,     kl: 12.04, 11.82,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1207, step:30200 (TRAIN, VALID): total: 2042.05, 2047.46      recon: 2027.51, 2033.12,     kl: 12.02, 11.82,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1208, step:30225 (TRAIN, VALID): total: 2042.15, 2047.37      recon: 2027.57, 2033.02,     kl: 12.06, 11.82,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1209, step:30250 (TRAIN, VALID): total: 2042.10, 2048.06      recon: 2027.54, 2033.72,     kl: 12.03, 11.81,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1210, step:30275 (TRAIN, VALID): total: 2042.20, 2044.82      recon: 2027.65, 2030.52,     kl: 12.03, 11.78,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000073.\n",
      "Epoch:1211, step:30300 (TRAIN, VALID): total: 2041.93, 2046.92      recon: 2027.37, 2032.59,     kl: 12.03, 11.80,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1212, step:30325 (TRAIN, VALID): total: 2041.95, 2047.45      recon: 2027.41, 2033.15,     kl: 12.02, 11.78,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1213, step:30350 (TRAIN, VALID): total: 2041.90, 2047.29      recon: 2027.34, 2032.96,     kl: 12.03, 11.80,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1214, step:30375 (TRAIN, VALID): total: 2042.04, 2045.74      recon: 2027.50, 2031.44,     kl: 12.02, 11.77,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1215, step:30400 (TRAIN, VALID): total: 2041.94, 2047.07      recon: 2027.42, 2032.76,     kl: 12.00, 11.78,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1216, step:30425 (TRAIN, VALID): total: 2042.03, 2047.04      recon: 2027.49, 2032.75,     kl: 12.01, 11.77,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1217, step:30450 (TRAIN, VALID): total: 2041.96, 2046.41      recon: 2027.39, 2032.05,     kl: 12.04, 11.84,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1218, step:30475 (TRAIN, VALID): total: 2042.02, 2045.69      recon: 2027.41, 2031.35,     kl: 12.08, 11.82,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1219, step:30500 (TRAIN, VALID): total: 2042.01, 2047.41      recon: 2027.41, 2033.07,     kl: 12.08, 11.82,     l2: 2.52522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1220, step:30525 (TRAIN, VALID): total: 2042.18, 2045.90      recon: 2027.62, 2031.59,     kl: 12.04, 11.78,     l2: 2.52514,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000069.\n",
      "Epoch:1221, step:30550 (TRAIN, VALID): total: 2041.97, 2046.03      recon: 2027.37, 2031.71,     kl: 12.07, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1222, step:30575 (TRAIN, VALID): total: 2041.91, 2044.83      recon: 2027.34, 2030.49,     kl: 12.05, 11.82,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1223, step:30600 (TRAIN, VALID): total: 2042.10, 2045.00      recon: 2027.54, 2030.69,     kl: 12.04, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1224, step:30625 (TRAIN, VALID): total: 2041.97, 2048.68      recon: 2027.43, 2034.38,     kl: 12.02, 11.78,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1225, step:30650 (TRAIN, VALID): total: 2041.89, 2045.98      recon: 2027.36, 2031.65,     kl: 12.01, 11.80,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1226, step:30675 (TRAIN, VALID): total: 2041.91, 2047.74      recon: 2027.30, 2033.36,     kl: 12.09, 11.85,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1227, step:30700 (TRAIN, VALID): total: 2041.96, 2047.52      recon: 2027.40, 2033.17,     kl: 12.03, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1228, step:30725 (TRAIN, VALID): total: 2042.03, 2046.35      recon: 2027.48, 2032.06,     kl: 12.03, 11.77,     l2: 2.52525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1229, step:30750 (TRAIN, VALID): total: 2042.12, 2046.17      recon: 2027.56, 2031.82,     kl: 12.03, 11.82,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000066.\n",
      "Epoch:1230, step:30775 (TRAIN, VALID): total: 2041.91, 2047.62      recon: 2027.34, 2033.25,     kl: 12.04, 11.85,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1231, step:30800 (TRAIN, VALID): total: 2041.86, 2046.84      recon: 2027.31, 2032.52,     kl: 12.02, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1232, step:30825 (TRAIN, VALID): total: 2041.84, 2047.31      recon: 2027.29, 2032.99,     kl: 12.02, 11.80,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1233, step:30850 (TRAIN, VALID): total: 2041.90, 2046.81      recon: 2027.36, 2032.56,     kl: 12.01, 11.73,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1234, step:30875 (TRAIN, VALID): total: 2041.91, 2047.08      recon: 2027.39, 2032.83,     kl: 11.99, 11.73,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1235, step:30900 (TRAIN, VALID): total: 2041.90, 2046.62      recon: 2027.37, 2032.33,     kl: 12.00, 11.76,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1236, step:30925 (TRAIN, VALID): total: 2041.98, 2046.59      recon: 2027.46, 2032.28,     kl: 12.00, 11.78,     l2: 2.52516,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000062.\n",
      "Epoch:1237, step:30950 (TRAIN, VALID): total: 2041.93, 2046.31      recon: 2027.39, 2032.00,     kl: 12.02, 11.79,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1238, step:30975 (TRAIN, VALID): total: 2042.10, 2046.47      recon: 2027.56, 2032.15,     kl: 12.01, 11.80,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1239, step:31000 (TRAIN, VALID): total: 2041.97, 2046.73      recon: 2027.44, 2032.45,     kl: 12.01, 11.75,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1240, step:31025 (TRAIN, VALID): total: 2041.98, 2046.51      recon: 2027.44, 2032.20,     kl: 12.01, 11.79,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1241, step:31050 (TRAIN, VALID): total: 2041.96, 2047.26      recon: 2027.41, 2032.91,     kl: 12.03, 11.83,     l2: 2.52505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1242, step:31075 (TRAIN, VALID): total: 2042.15, 2047.84      recon: 2027.56, 2033.45,     kl: 12.07, 11.86,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1243, step:31100 (TRAIN, VALID): total: 2042.27, 2047.45      recon: 2027.67, 2033.06,     kl: 12.08, 11.87,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000059.\n",
      "Epoch:1244, step:31125 (TRAIN, VALID): total: 2041.93, 2046.46      recon: 2027.33, 2032.10,     kl: 12.08, 11.84,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1245, step:31150 (TRAIN, VALID): total: 2041.90, 2046.42      recon: 2027.32, 2032.04,     kl: 12.06, 11.85,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1246, step:31175 (TRAIN, VALID): total: 2041.82, 2046.24      recon: 2027.24, 2031.89,     kl: 12.05, 11.83,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1247, step:31200 (TRAIN, VALID): total: 2041.99, 2047.20      recon: 2027.43, 2032.88,     kl: 12.04, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1248, step:31225 (TRAIN, VALID): total: 2041.84, 2046.46      recon: 2027.30, 2032.14,     kl: 12.02, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1249, step:31250 (TRAIN, VALID): total: 2041.94, 2045.99      recon: 2027.39, 2031.65,     kl: 12.02, 11.81,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1250, step:31275 (TRAIN, VALID): total: 2041.90, 2045.45      recon: 2027.35, 2031.15,     kl: 12.02, 11.78,     l2: 2.52519,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1251, step:31300 (TRAIN, VALID): total: 2042.10, 2047.68      recon: 2027.54, 2033.36,     kl: 12.04, 11.80,     l2: 2.52520,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000056.\n",
      "Epoch:1252, step:31325 (TRAIN, VALID): total: 2041.88, 2046.08      recon: 2027.35, 2031.79,     kl: 12.01, 11.76,     l2: 2.52518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1253, step:31350 (TRAIN, VALID): total: 2042.00, 2047.01      recon: 2027.44, 2032.69,     kl: 12.03, 11.80,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1254, step:31375 (TRAIN, VALID): total: 2042.05, 2046.22      recon: 2027.50, 2031.90,     kl: 12.02, 11.79,     l2: 2.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1255, step:31400 (TRAIN, VALID): total: 2041.86, 2046.28      recon: 2027.33, 2031.96,     kl: 12.01, 11.79,     l2: 2.52517,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1256, step:31425 (TRAIN, VALID): total: 2042.22, 2045.59      recon: 2027.67, 2031.27,     kl: 12.02, 11.80,     l2: 2.52511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1257, step:31450 (TRAIN, VALID): total: 2041.91, 2047.32      recon: 2027.36, 2033.01,     kl: 12.02, 11.78,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1258, step:31475 (TRAIN, VALID): total: 2041.89, 2047.59      recon: 2027.38, 2033.30,     kl: 11.98, 11.77,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1259, step:31500 (TRAIN, VALID): total: 2041.96, 2045.66      recon: 2027.41, 2031.38,     kl: 12.02, 11.76,     l2: 2.52508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1260, step:31525 (TRAIN, VALID): total: 2042.13, 2046.81      recon: 2027.59, 2032.51,     kl: 12.02, 11.77,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1261, step:31550 (TRAIN, VALID): total: 2041.93, 2047.23      recon: 2027.37, 2032.92,     kl: 12.03, 11.79,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1262, step:31575 (TRAIN, VALID): total: 2041.91, 2046.32      recon: 2027.38, 2032.02,     kl: 12.01, 11.78,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1263, step:31600 (TRAIN, VALID): total: 2041.98, 2045.78      recon: 2027.46, 2031.49,     kl: 12.00, 11.77,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1264, step:31625 (TRAIN, VALID): total: 2042.00, 2046.43      recon: 2027.47, 2032.13,     kl: 12.00, 11.78,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1265, step:31650 (TRAIN, VALID): total: 2041.92, 2046.58      recon: 2027.37, 2032.26,     kl: 12.03, 11.79,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1266, step:31675 (TRAIN, VALID): total: 2042.08, 2046.87      recon: 2027.52, 2032.54,     kl: 12.03, 11.80,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1267, step:31700 (TRAIN, VALID): total: 2042.16, 2046.89      recon: 2027.60, 2032.56,     kl: 12.04, 11.81,     l2: 2.52513,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000053.\n",
      "Epoch:1268, step:31725 (TRAIN, VALID): total: 2042.00, 2046.09      recon: 2027.44, 2031.77,     kl: 12.03, 11.79,     l2: 2.52504,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1269, step:31750 (TRAIN, VALID): total: 2041.97, 2046.48      recon: 2027.42, 2032.16,     kl: 12.03, 11.79,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1270, step:31775 (TRAIN, VALID): total: 2041.94, 2046.62      recon: 2027.37, 2032.27,     kl: 12.04, 11.82,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1271, step:31800 (TRAIN, VALID): total: 2041.87, 2046.31      recon: 2027.33, 2031.96,     kl: 12.02, 11.82,     l2: 2.52503,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1272, step:31825 (TRAIN, VALID): total: 2041.95, 2047.24      recon: 2027.40, 2032.96,     kl: 12.03, 11.75,     l2: 2.52506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1273, step:31850 (TRAIN, VALID): total: 2041.94, 2045.95      recon: 2027.41, 2031.64,     kl: 12.01, 11.79,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1274, step:31875 (TRAIN, VALID): total: 2041.96, 2047.23      recon: 2027.43, 2032.92,     kl: 12.00, 11.78,     l2: 2.52507,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1275, step:31900 (TRAIN, VALID): total: 2042.19, 2046.85      recon: 2027.66, 2032.56,     kl: 12.00, 11.76,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000051.\n",
      "Epoch:1276, step:31925 (TRAIN, VALID): total: 2041.94, 2047.09      recon: 2027.41, 2032.80,     kl: 12.00, 11.77,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1277, step:31950 (TRAIN, VALID): total: 2041.91, 2047.16      recon: 2027.38, 2032.88,     kl: 12.00, 11.75,     l2: 2.52509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1278, step:31975 (TRAIN, VALID): total: 2041.92, 2045.68      recon: 2027.40, 2031.39,     kl: 11.99, 11.76,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1279, step:32000 (TRAIN, VALID): total: 2041.75, 2046.92      recon: 2027.25, 2032.65,     kl: 11.98, 11.75,     l2: 2.52510,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1280, step:32025 (TRAIN, VALID): total: 2042.35, 2046.74      recon: 2027.84, 2032.45,     kl: 11.99, 11.77,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1281, step:32050 (TRAIN, VALID): total: 2041.89, 2047.21      recon: 2027.37, 2032.90,     kl: 12.00, 11.78,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1282, step:32075 (TRAIN, VALID): total: 2041.94, 2046.87      recon: 2027.41, 2032.54,     kl: 12.00, 11.81,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1283, step:32100 (TRAIN, VALID): total: 2041.84, 2046.37      recon: 2027.31, 2032.09,     kl: 12.01, 11.76,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1284, step:32125 (TRAIN, VALID): total: 2041.90, 2048.08      recon: 2027.36, 2033.75,     kl: 12.01, 11.81,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1285, step:32150 (TRAIN, VALID): total: 2041.90, 2046.65      recon: 2027.38, 2032.34,     kl: 12.00, 11.79,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1286, step:32175 (TRAIN, VALID): total: 2042.02, 2045.82      recon: 2027.48, 2031.51,     kl: 12.02, 11.78,     l2: 2.52502,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1287, step:32200 (TRAIN, VALID): total: 2041.88, 2047.23      recon: 2027.31, 2032.92,     kl: 12.04, 11.79,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1288, step:32225 (TRAIN, VALID): total: 2041.90, 2047.25      recon: 2027.33, 2032.92,     kl: 12.04, 11.80,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1289, step:32250 (TRAIN, VALID): total: 2042.20, 2045.86      recon: 2027.66, 2031.54,     kl: 12.01, 11.79,     l2: 2.52501,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000048.\n",
      "Epoch:1290, step:32275 (TRAIN, VALID): total: 2042.00, 2046.36      recon: 2027.46, 2032.04,     kl: 12.02, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1291, step:32300 (TRAIN, VALID): total: 2041.92, 2045.87      recon: 2027.37, 2031.58,     kl: 12.02, 11.76,     l2: 2.52500,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1292, step:32325 (TRAIN, VALID): total: 2042.02, 2046.79      recon: 2027.46, 2032.47,     kl: 12.04, 11.79,     l2: 2.52495,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1293, step:32350 (TRAIN, VALID): total: 2041.93, 2046.05      recon: 2027.41, 2031.76,     kl: 12.00, 11.76,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1294, step:32375 (TRAIN, VALID): total: 2041.97, 2045.52      recon: 2027.45, 2031.21,     kl: 12.00, 11.78,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1295, step:32400 (TRAIN, VALID): total: 2041.92, 2046.74      recon: 2027.39, 2032.42,     kl: 12.01, 11.80,     l2: 2.52489,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1296, step:32425 (TRAIN, VALID): total: 2041.94, 2046.32      recon: 2027.39, 2032.00,     kl: 12.03, 11.79,     l2: 2.52496,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1297, step:32450 (TRAIN, VALID): total: 2041.99, 2046.80      recon: 2027.46, 2032.49,     kl: 12.01, 11.78,     l2: 2.52494,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1298, step:32475 (TRAIN, VALID): total: 2042.02, 2046.99      recon: 2027.50, 2032.67,     kl: 12.00, 11.80,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1299, step:32500 (TRAIN, VALID): total: 2042.06, 2046.11      recon: 2027.53, 2031.80,     kl: 12.00, 11.79,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000046.\n",
      "Epoch:1300, step:32525 (TRAIN, VALID): total: 2042.02, 2045.97      recon: 2027.49, 2031.65,     kl: 12.00, 11.80,     l2: 2.52498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1301, step:32550 (TRAIN, VALID): total: 2041.94, 2046.07      recon: 2027.40, 2031.72,     kl: 12.02, 11.82,     l2: 2.52499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1302, step:32575 (TRAIN, VALID): total: 2041.86, 2046.95      recon: 2027.32, 2032.63,     kl: 12.02, 11.80,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1303, step:32600 (TRAIN, VALID): total: 2042.24, 2047.60      recon: 2027.69, 2033.26,     kl: 12.03, 11.82,     l2: 2.52497,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1304, step:32625 (TRAIN, VALID): total: 2041.93, 2047.73      recon: 2027.36, 2033.38,     kl: 12.05, 11.83,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1305, step:32650 (TRAIN, VALID): total: 2041.86, 2047.29      recon: 2027.31, 2032.96,     kl: 12.03, 11.80,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1306, step:32675 (TRAIN, VALID): total: 2042.11, 2045.86      recon: 2027.55, 2031.49,     kl: 12.03, 11.84,     l2: 2.52492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1307, step:32700 (TRAIN, VALID): total: 2041.91, 2047.80      recon: 2027.33, 2033.47,     kl: 12.05, 11.81,     l2: 2.52491,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1308, step:32725 (TRAIN, VALID): total: 2042.26, 2046.68      recon: 2027.70, 2032.35,     kl: 12.03, 11.80,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000044.\n",
      "Epoch:1309, step:32750 (TRAIN, VALID): total: 2042.00, 2047.11      recon: 2027.45, 2032.79,     kl: 12.02, 11.80,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1310, step:32775 (TRAIN, VALID): total: 2041.83, 2047.02      recon: 2027.28, 2032.70,     kl: 12.02, 11.80,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1311, step:32800 (TRAIN, VALID): total: 2041.98, 2045.85      recon: 2027.45, 2031.53,     kl: 12.01, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1312, step:32825 (TRAIN, VALID): total: 2041.92, 2046.76      recon: 2027.36, 2032.46,     kl: 12.03, 11.77,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1313, step:32850 (TRAIN, VALID): total: 2041.98, 2048.03      recon: 2027.46, 2033.71,     kl: 12.00, 11.79,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1314, step:32875 (TRAIN, VALID): total: 2041.87, 2047.57      recon: 2027.35, 2033.25,     kl: 12.00, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1315, step:32900 (TRAIN, VALID): total: 2041.85, 2045.96      recon: 2027.33, 2031.66,     kl: 12.00, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1316, step:32925 (TRAIN, VALID): total: 2042.07, 2047.06      recon: 2027.53, 2032.73,     kl: 12.02, 11.80,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000041.\n",
      "Epoch:1317, step:32950 (TRAIN, VALID): total: 2041.94, 2045.81      recon: 2027.40, 2031.48,     kl: 12.02, 11.81,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1318, step:32975 (TRAIN, VALID): total: 2041.86, 2047.06      recon: 2027.32, 2032.72,     kl: 12.02, 11.82,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1319, step:33000 (TRAIN, VALID): total: 2041.95, 2046.04      recon: 2027.41, 2031.70,     kl: 12.02, 11.82,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1320, step:33025 (TRAIN, VALID): total: 2041.83, 2046.01      recon: 2027.27, 2031.69,     kl: 12.03, 11.80,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1321, step:33050 (TRAIN, VALID): total: 2041.93, 2045.05      recon: 2027.40, 2030.76,     kl: 12.01, 11.77,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1322, step:33075 (TRAIN, VALID): total: 2041.91, 2046.55      recon: 2027.35, 2032.25,     kl: 12.03, 11.77,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1323, step:33100 (TRAIN, VALID): total: 2042.04, 2046.58      recon: 2027.48, 2032.26,     kl: 12.03, 11.80,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000039.\n",
      "Epoch:1324, step:33125 (TRAIN, VALID): total: 2041.91, 2046.06      recon: 2027.38, 2031.74,     kl: 12.00, 11.80,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1325, step:33150 (TRAIN, VALID): total: 2041.84, 2046.89      recon: 2027.31, 2032.57,     kl: 12.00, 11.79,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1326, step:33175 (TRAIN, VALID): total: 2041.97, 2046.58      recon: 2027.42, 2032.25,     kl: 12.03, 11.81,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1327, step:33200 (TRAIN, VALID): total: 2041.83, 2046.98      recon: 2027.29, 2032.66,     kl: 12.02, 11.79,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1328, step:33225 (TRAIN, VALID): total: 2041.93, 2046.20      recon: 2027.40, 2031.90,     kl: 12.00, 11.77,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1329, step:33250 (TRAIN, VALID): total: 2042.00, 2047.79      recon: 2027.48, 2033.48,     kl: 12.00, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1330, step:33275 (TRAIN, VALID): total: 2041.90, 2046.91      recon: 2027.38, 2032.60,     kl: 12.00, 11.79,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1331, step:33300 (TRAIN, VALID): total: 2041.89, 2045.47      recon: 2027.37, 2031.18,     kl: 12.00, 11.77,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1332, step:33325 (TRAIN, VALID): total: 2041.98, 2046.19      recon: 2027.44, 2031.85,     kl: 12.01, 11.81,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1333, step:33350 (TRAIN, VALID): total: 2041.91, 2046.83      recon: 2027.36, 2032.53,     kl: 12.03, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1334, step:33375 (TRAIN, VALID): total: 2042.25, 2046.47      recon: 2027.69, 2032.17,     kl: 12.03, 11.78,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000037.\n",
      "Epoch:1335, step:33400 (TRAIN, VALID): total: 2041.95, 2046.46      recon: 2027.40, 2032.14,     kl: 12.02, 11.80,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1336, step:33425 (TRAIN, VALID): total: 2041.89, 2046.63      recon: 2027.34, 2032.31,     kl: 12.03, 11.79,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1337, step:33450 (TRAIN, VALID): total: 2041.96, 2046.78      recon: 2027.41, 2032.47,     kl: 12.02, 11.79,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1338, step:33475 (TRAIN, VALID): total: 2042.04, 2046.68      recon: 2027.49, 2032.35,     kl: 12.03, 11.80,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1339, step:33500 (TRAIN, VALID): total: 2042.00, 2046.73      recon: 2027.45, 2032.38,     kl: 12.03, 11.82,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1340, step:33525 (TRAIN, VALID): total: 2042.10, 2046.86      recon: 2027.56, 2032.51,     kl: 12.02, 11.82,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1341, step:33550 (TRAIN, VALID): total: 2042.08, 2046.17      recon: 2027.52, 2031.81,     kl: 12.03, 11.84,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1342, step:33575 (TRAIN, VALID): total: 2041.99, 2045.61      recon: 2027.41, 2031.26,     kl: 12.05, 11.82,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1343, step:33600 (TRAIN, VALID): total: 2042.10, 2046.99      recon: 2027.53, 2032.67,     kl: 12.04, 11.79,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1344, step:33625 (TRAIN, VALID): total: 2041.94, 2047.55      recon: 2027.38, 2033.18,     kl: 12.03, 11.84,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1345, step:33650 (TRAIN, VALID): total: 2041.95, 2046.92      recon: 2027.39, 2032.57,     kl: 12.03, 11.83,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1346, step:33675 (TRAIN, VALID): total: 2041.90, 2046.07      recon: 2027.31, 2031.74,     kl: 12.07, 11.81,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1347, step:33700 (TRAIN, VALID): total: 2042.06, 2047.08      recon: 2027.50, 2032.76,     kl: 12.03, 11.80,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1348, step:33725 (TRAIN, VALID): total: 2041.84, 2046.47      recon: 2027.31, 2032.15,     kl: 12.01, 11.80,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1349, step:33750 (TRAIN, VALID): total: 2041.92, 2046.63      recon: 2027.38, 2032.28,     kl: 12.01, 11.83,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1350, step:33775 (TRAIN, VALID): total: 2041.76, 2046.13      recon: 2027.20, 2031.80,     kl: 12.03, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1351, step:33800 (TRAIN, VALID): total: 2042.00, 2045.97      recon: 2027.45, 2031.66,     kl: 12.03, 11.79,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1352, step:33825 (TRAIN, VALID): total: 2041.94, 2046.81      recon: 2027.39, 2032.47,     kl: 12.03, 11.82,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1353, step:33850 (TRAIN, VALID): total: 2041.92, 2047.64      recon: 2027.36, 2033.31,     kl: 12.03, 11.80,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1354, step:33875 (TRAIN, VALID): total: 2041.85, 2046.18      recon: 2027.30, 2031.86,     kl: 12.02, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1355, step:33900 (TRAIN, VALID): total: 2041.88, 2046.73      recon: 2027.32, 2032.44,     kl: 12.03, 11.76,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1356, step:33925 (TRAIN, VALID): total: 2041.91, 2046.76      recon: 2027.36, 2032.46,     kl: 12.02, 11.77,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1357, step:33950 (TRAIN, VALID): total: 2041.97, 2046.76      recon: 2027.44, 2032.46,     kl: 12.01, 11.77,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1358, step:33975 (TRAIN, VALID): total: 2041.93, 2045.86      recon: 2027.38, 2031.56,     kl: 12.02, 11.77,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1359, step:34000 (TRAIN, VALID): total: 2041.93, 2046.95      recon: 2027.39, 2032.63,     kl: 12.01, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1360, step:34025 (TRAIN, VALID): total: 2041.80, 2047.12      recon: 2027.26, 2032.82,     kl: 12.02, 11.78,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1361, step:34050 (TRAIN, VALID): total: 2041.93, 2046.10      recon: 2027.38, 2031.82,     kl: 12.02, 11.75,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1362, step:34075 (TRAIN, VALID): total: 2041.90, 2046.46      recon: 2027.37, 2032.12,     kl: 12.01, 11.82,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1363, step:34100 (TRAIN, VALID): total: 2041.99, 2046.30      recon: 2027.45, 2032.01,     kl: 12.01, 11.77,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000035.\n",
      "Epoch:1364, step:34125 (TRAIN, VALID): total: 2041.87, 2046.13      recon: 2027.33, 2031.83,     kl: 12.01, 11.77,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1365, step:34150 (TRAIN, VALID): total: 2041.78, 2047.61      recon: 2027.24, 2033.28,     kl: 12.01, 11.81,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1366, step:34175 (TRAIN, VALID): total: 2041.95, 2047.81      recon: 2027.40, 2033.48,     kl: 12.03, 11.80,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1367, step:34200 (TRAIN, VALID): total: 2041.88, 2046.25      recon: 2027.33, 2031.91,     kl: 12.03, 11.81,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1368, step:34225 (TRAIN, VALID): total: 2041.89, 2046.13      recon: 2027.32, 2031.82,     kl: 12.04, 11.79,     l2: 2.52481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1369, step:34250 (TRAIN, VALID): total: 2041.89, 2045.94      recon: 2027.32, 2031.57,     kl: 12.04, 11.84,     l2: 2.52488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1370, step:34275 (TRAIN, VALID): total: 2042.04, 2046.67      recon: 2027.47, 2032.32,     kl: 12.05, 11.82,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000034.\n",
      "Epoch:1371, step:34300 (TRAIN, VALID): total: 2042.12, 2045.29      recon: 2027.55, 2030.95,     kl: 12.04, 11.81,     l2: 2.52480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1372, step:34325 (TRAIN, VALID): total: 2041.92, 2046.24      recon: 2027.36, 2031.92,     kl: 12.04, 11.80,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1373, step:34350 (TRAIN, VALID): total: 2041.89, 2047.17      recon: 2027.33, 2032.86,     kl: 12.04, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1374, step:34375 (TRAIN, VALID): total: 2041.91, 2046.48      recon: 2027.36, 2032.17,     kl: 12.02, 11.79,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1375, step:34400 (TRAIN, VALID): total: 2041.93, 2047.86      recon: 2027.39, 2033.55,     kl: 12.02, 11.79,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1376, step:34425 (TRAIN, VALID): total: 2042.00, 2047.00      recon: 2027.46, 2032.67,     kl: 12.02, 11.80,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1377, step:34450 (TRAIN, VALID): total: 2042.00, 2046.43      recon: 2027.43, 2032.09,     kl: 12.05, 11.82,     l2: 2.52484,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1378, step:34475 (TRAIN, VALID): total: 2041.89, 2048.02      recon: 2027.34, 2033.69,     kl: 12.03, 11.80,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1379, step:34500 (TRAIN, VALID): total: 2041.92, 2046.47      recon: 2027.36, 2032.13,     kl: 12.04, 11.81,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1380, step:34525 (TRAIN, VALID): total: 2041.78, 2046.73      recon: 2027.23, 2032.43,     kl: 12.03, 11.78,     l2: 2.52486,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1381, step:34550 (TRAIN, VALID): total: 2041.86, 2047.00      recon: 2027.31, 2032.64,     kl: 12.03, 11.83,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1382, step:34575 (TRAIN, VALID): total: 2041.92, 2046.37      recon: 2027.39, 2032.05,     kl: 12.00, 11.79,     l2: 2.52487,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1383, step:34600 (TRAIN, VALID): total: 2041.89, 2048.62      recon: 2027.36, 2034.29,     kl: 12.01, 11.80,     l2: 2.52482,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1384, step:34625 (TRAIN, VALID): total: 2041.87, 2047.26      recon: 2027.32, 2032.95,     kl: 12.03, 11.79,     l2: 2.52483,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1385, step:34650 (TRAIN, VALID): total: 2041.84, 2047.13      recon: 2027.31, 2032.83,     kl: 12.00, 11.77,     l2: 2.52478,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1386, step:34675 (TRAIN, VALID): total: 2042.09, 2046.98      recon: 2027.57, 2032.68,     kl: 11.99, 11.78,     l2: 2.52485,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000032.\n",
      "Epoch:1387, step:34700 (TRAIN, VALID): total: 2041.83, 2046.59      recon: 2027.32, 2032.29,     kl: 11.98, 11.77,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1388, step:34725 (TRAIN, VALID): total: 2041.86, 2045.89      recon: 2027.32, 2031.61,     kl: 12.02, 11.76,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1389, step:34750 (TRAIN, VALID): total: 2041.88, 2045.09      recon: 2027.35, 2030.82,     kl: 12.01, 11.74,     l2: 2.52479,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1390, step:34775 (TRAIN, VALID): total: 2041.99, 2047.45      recon: 2027.46, 2033.13,     kl: 12.01, 11.80,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1391, step:34800 (TRAIN, VALID): total: 2041.79, 2047.37      recon: 2027.27, 2033.06,     kl: 12.00, 11.78,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1392, step:34825 (TRAIN, VALID): total: 2041.98, 2047.56      recon: 2027.46, 2033.22,     kl: 12.00, 11.81,     l2: 2.52477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1393, step:34850 (TRAIN, VALID): total: 2041.84, 2046.27      recon: 2027.28, 2031.97,     kl: 12.03, 11.78,     l2: 2.52475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1394, step:34875 (TRAIN, VALID): total: 2041.90, 2047.32      recon: 2027.36, 2033.00,     kl: 12.01, 11.80,     l2: 2.52476,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1395, step:34900 (TRAIN, VALID): total: 2041.90, 2046.06      recon: 2027.35, 2031.77,     kl: 12.03, 11.76,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1396, step:34925 (TRAIN, VALID): total: 2042.00, 2047.09      recon: 2027.45, 2032.78,     kl: 12.03, 11.78,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000030.\n",
      "Epoch:1397, step:34950 (TRAIN, VALID): total: 2041.87, 2046.42      recon: 2027.33, 2032.10,     kl: 12.02, 11.80,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1398, step:34975 (TRAIN, VALID): total: 2041.74, 2046.71      recon: 2027.21, 2032.40,     kl: 12.01, 11.78,     l2: 2.52472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1399, step:35000 (TRAIN, VALID): total: 2041.93, 2046.59      recon: 2027.38, 2032.29,     kl: 12.02, 11.77,     l2: 2.52473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1400, step:35025 (TRAIN, VALID): total: 2041.91, 2045.80      recon: 2027.36, 2031.49,     kl: 12.02, 11.79,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1401, step:35050 (TRAIN, VALID): total: 2041.85, 2048.98      recon: 2027.31, 2034.66,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1402, step:35075 (TRAIN, VALID): total: 2041.96, 2046.21      recon: 2027.41, 2031.89,     kl: 12.03, 11.80,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1403, step:35100 (TRAIN, VALID): total: 2041.89, 2045.53      recon: 2027.35, 2031.23,     kl: 12.01, 11.78,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1404, step:35125 (TRAIN, VALID): total: 2041.81, 2046.80      recon: 2027.30, 2032.48,     kl: 11.99, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1405, step:35150 (TRAIN, VALID): total: 2041.93, 2047.20      recon: 2027.40, 2032.91,     kl: 12.00, 11.77,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1406, step:35175 (TRAIN, VALID): total: 2041.88, 2045.81      recon: 2027.34, 2031.50,     kl: 12.01, 11.79,     l2: 2.52469,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1407, step:35200 (TRAIN, VALID): total: 2041.88, 2046.15      recon: 2027.34, 2031.85,     kl: 12.02, 11.77,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1408, step:35225 (TRAIN, VALID): total: 2041.93, 2047.20      recon: 2027.41, 2032.90,     kl: 12.00, 11.77,     l2: 2.52468,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1409, step:35250 (TRAIN, VALID): total: 2041.88, 2046.44      recon: 2027.34, 2032.14,     kl: 12.01, 11.78,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1410, step:35275 (TRAIN, VALID): total: 2042.16, 2046.79      recon: 2027.61, 2032.44,     kl: 12.02, 11.82,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000029.\n",
      "Epoch:1411, step:35300 (TRAIN, VALID): total: 2041.88, 2045.91      recon: 2027.35, 2031.58,     kl: 12.01, 11.80,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1412, step:35325 (TRAIN, VALID): total: 2041.82, 2046.24      recon: 2027.28, 2031.93,     kl: 12.01, 11.79,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1413, step:35350 (TRAIN, VALID): total: 2041.93, 2046.10      recon: 2027.38, 2031.76,     kl: 12.03, 11.82,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1414, step:35375 (TRAIN, VALID): total: 2041.86, 2046.30      recon: 2027.31, 2031.96,     kl: 12.03, 11.82,     l2: 2.52471,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1415, step:35400 (TRAIN, VALID): total: 2041.92, 2046.05      recon: 2027.38, 2031.72,     kl: 12.02, 11.80,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1416, step:35425 (TRAIN, VALID): total: 2041.88, 2046.18      recon: 2027.33, 2031.89,     kl: 12.02, 11.76,     l2: 2.52466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1417, step:35450 (TRAIN, VALID): total: 2041.89, 2046.18      recon: 2027.36, 2031.87,     kl: 12.00, 11.78,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1418, step:35475 (TRAIN, VALID): total: 2041.81, 2047.49      recon: 2027.28, 2033.20,     kl: 12.00, 11.77,     l2: 2.52474,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1419, step:35500 (TRAIN, VALID): total: 2041.85, 2048.15      recon: 2027.33, 2033.85,     kl: 12.00, 11.78,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1420, step:35525 (TRAIN, VALID): total: 2041.83, 2046.70      recon: 2027.33, 2032.39,     kl: 11.98, 11.79,     l2: 2.52470,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1421, step:35550 (TRAIN, VALID): total: 2042.11, 2046.72      recon: 2027.58, 2032.43,     kl: 12.01, 11.77,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000027.\n",
      "Epoch:1422, step:35575 (TRAIN, VALID): total: 2041.86, 2047.80      recon: 2027.35, 2033.49,     kl: 11.99, 11.79,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1423, step:35600 (TRAIN, VALID): total: 2041.95, 2046.57      recon: 2027.41, 2032.27,     kl: 12.02, 11.78,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1424, step:35625 (TRAIN, VALID): total: 2041.91, 2047.89      recon: 2027.39, 2033.57,     kl: 12.00, 11.80,     l2: 2.52467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1425, step:35650 (TRAIN, VALID): total: 2041.90, 2046.91      recon: 2027.35, 2032.57,     kl: 12.03, 11.82,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1426, step:35675 (TRAIN, VALID): total: 2041.88, 2046.50      recon: 2027.33, 2032.18,     kl: 12.03, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1427, step:35700 (TRAIN, VALID): total: 2041.82, 2046.51      recon: 2027.29, 2032.25,     kl: 12.00, 11.74,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1428, step:35725 (TRAIN, VALID): total: 2041.96, 2046.35      recon: 2027.44, 2032.05,     kl: 12.00, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000026.\n",
      "Epoch:1429, step:35750 (TRAIN, VALID): total: 2041.84, 2047.13      recon: 2027.30, 2032.82,     kl: 12.02, 11.79,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1430, step:35775 (TRAIN, VALID): total: 2041.94, 2046.66      recon: 2027.42, 2032.37,     kl: 12.00, 11.77,     l2: 2.52458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1431, step:35800 (TRAIN, VALID): total: 2041.81, 2046.44      recon: 2027.27, 2032.12,     kl: 12.02, 11.79,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1432, step:35825 (TRAIN, VALID): total: 2042.25, 2046.91      recon: 2027.72, 2032.59,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1433, step:35850 (TRAIN, VALID): total: 2041.90, 2047.67      recon: 2027.34, 2033.36,     kl: 12.03, 11.79,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1434, step:35875 (TRAIN, VALID): total: 2041.80, 2047.41      recon: 2027.25, 2033.11,     kl: 12.02, 11.77,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1435, step:35900 (TRAIN, VALID): total: 2042.05, 2046.06      recon: 2027.51, 2031.74,     kl: 12.02, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1436, step:35925 (TRAIN, VALID): total: 2041.91, 2046.49      recon: 2027.35, 2032.19,     kl: 12.03, 11.77,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1437, step:35950 (TRAIN, VALID): total: 2041.89, 2045.06      recon: 2027.35, 2030.77,     kl: 12.01, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1438, step:35975 (TRAIN, VALID): total: 2042.12, 2046.76      recon: 2027.60, 2032.45,     kl: 12.00, 11.79,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1439, step:36000 (TRAIN, VALID): total: 2041.80, 2047.59      recon: 2027.27, 2033.27,     kl: 12.01, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1440, step:36025 (TRAIN, VALID): total: 2041.78, 2045.80      recon: 2027.25, 2031.51,     kl: 12.01, 11.77,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1441, step:36050 (TRAIN, VALID): total: 2041.94, 2046.23      recon: 2027.41, 2031.92,     kl: 12.01, 11.78,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1442, step:36075 (TRAIN, VALID): total: 2041.86, 2046.68      recon: 2027.33, 2032.34,     kl: 12.00, 11.82,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1443, step:36100 (TRAIN, VALID): total: 2041.98, 2046.74      recon: 2027.45, 2032.41,     kl: 12.01, 11.80,     l2: 2.52463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1444, step:36125 (TRAIN, VALID): total: 2041.81, 2045.97      recon: 2027.25, 2031.68,     kl: 12.03, 11.76,     l2: 2.52454,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1445, step:36150 (TRAIN, VALID): total: 2041.93, 2047.03      recon: 2027.41, 2032.71,     kl: 12.00, 11.80,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1446, step:36175 (TRAIN, VALID): total: 2041.92, 2046.09      recon: 2027.39, 2031.76,     kl: 12.01, 11.81,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1447, step:36200 (TRAIN, VALID): total: 2041.85, 2046.84      recon: 2027.33, 2032.52,     kl: 12.00, 11.79,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1448, step:36225 (TRAIN, VALID): total: 2041.98, 2046.48      recon: 2027.45, 2032.15,     kl: 12.01, 11.81,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000025.\n",
      "Epoch:1449, step:36250 (TRAIN, VALID): total: 2041.82, 2047.28      recon: 2027.26, 2032.95,     kl: 12.03, 11.81,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1450, step:36275 (TRAIN, VALID): total: 2041.82, 2046.74      recon: 2027.27, 2032.41,     kl: 12.02, 11.80,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1451, step:36300 (TRAIN, VALID): total: 2041.90, 2046.57      recon: 2027.35, 2032.24,     kl: 12.02, 11.80,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1452, step:36325 (TRAIN, VALID): total: 2041.89, 2046.72      recon: 2027.34, 2032.42,     kl: 12.03, 11.77,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1453, step:36350 (TRAIN, VALID): total: 2041.95, 2048.11      recon: 2027.41, 2033.81,     kl: 12.01, 11.78,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1454, step:36375 (TRAIN, VALID): total: 2041.76, 2046.86      recon: 2027.22, 2032.57,     kl: 12.02, 11.77,     l2: 2.52457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1455, step:36400 (TRAIN, VALID): total: 2041.92, 2047.24      recon: 2027.38, 2032.91,     kl: 12.01, 11.81,     l2: 2.52464,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1456, step:36425 (TRAIN, VALID): total: 2041.87, 2047.08      recon: 2027.36, 2032.78,     kl: 11.99, 11.77,     l2: 2.52455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1457, step:36450 (TRAIN, VALID): total: 2041.87, 2044.97      recon: 2027.33, 2030.69,     kl: 12.01, 11.76,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1458, step:36475 (TRAIN, VALID): total: 2042.03, 2046.92      recon: 2027.49, 2032.61,     kl: 12.02, 11.79,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000024.\n",
      "Epoch:1459, step:36500 (TRAIN, VALID): total: 2041.86, 2047.04      recon: 2027.30, 2032.71,     kl: 12.03, 11.80,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1460, step:36525 (TRAIN, VALID): total: 2041.93, 2047.77      recon: 2027.38, 2033.41,     kl: 12.03, 11.84,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1461, step:36550 (TRAIN, VALID): total: 2041.84, 2046.18      recon: 2027.29, 2031.87,     kl: 12.03, 11.79,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1462, step:36575 (TRAIN, VALID): total: 2041.90, 2045.40      recon: 2027.34, 2031.11,     kl: 12.03, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1463, step:36600 (TRAIN, VALID): total: 2042.07, 2046.29      recon: 2027.54, 2031.98,     kl: 12.01, 11.78,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1464, step:36625 (TRAIN, VALID): total: 2041.77, 2046.17      recon: 2027.23, 2031.88,     kl: 12.02, 11.77,     l2: 2.52461,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1465, step:36650 (TRAIN, VALID): total: 2041.81, 2045.76      recon: 2027.27, 2031.44,     kl: 12.01, 11.80,     l2: 2.52465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1466, step:36675 (TRAIN, VALID): total: 2041.88, 2045.86      recon: 2027.33, 2031.55,     kl: 12.03, 11.78,     l2: 2.52460,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1467, step:36700 (TRAIN, VALID): total: 2041.92, 2046.29      recon: 2027.38, 2031.96,     kl: 12.02, 11.81,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1468, step:36725 (TRAIN, VALID): total: 2041.89, 2046.51      recon: 2027.34, 2032.15,     kl: 12.03, 11.83,     l2: 2.52462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1469, step:36750 (TRAIN, VALID): total: 2041.94, 2048.17      recon: 2027.41, 2033.82,     kl: 12.01, 11.82,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1470, step:36775 (TRAIN, VALID): total: 2041.80, 2045.89      recon: 2027.25, 2031.55,     kl: 12.03, 11.81,     l2: 2.52459,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1471, step:36800 (TRAIN, VALID): total: 2041.87, 2047.62      recon: 2027.34, 2033.26,     kl: 12.00, 11.83,     l2: 2.52458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1472, step:36825 (TRAIN, VALID): total: 2041.92, 2046.37      recon: 2027.38, 2032.08,     kl: 12.02, 11.76,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1473, step:36850 (TRAIN, VALID): total: 2042.06, 2047.37      recon: 2027.52, 2033.06,     kl: 12.02, 11.78,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000022.\n",
      "Epoch:1474, step:36875 (TRAIN, VALID): total: 2041.87, 2046.36      recon: 2027.30, 2032.06,     kl: 12.04, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1475, step:36900 (TRAIN, VALID): total: 2041.92, 2046.82      recon: 2027.37, 2032.52,     kl: 12.03, 11.78,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1476, step:36925 (TRAIN, VALID): total: 2041.89, 2046.79      recon: 2027.34, 2032.51,     kl: 12.02, 11.76,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1477, step:36950 (TRAIN, VALID): total: 2041.84, 2045.83      recon: 2027.30, 2031.52,     kl: 12.02, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1478, step:36975 (TRAIN, VALID): total: 2041.90, 2046.40      recon: 2027.34, 2032.09,     kl: 12.03, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1479, step:37000 (TRAIN, VALID): total: 2041.86, 2046.02      recon: 2027.32, 2031.71,     kl: 12.02, 11.78,     l2: 2.52454,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1480, step:37025 (TRAIN, VALID): total: 2041.90, 2046.56      recon: 2027.36, 2032.24,     kl: 12.02, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1481, step:37050 (TRAIN, VALID): total: 2041.83, 2046.98      recon: 2027.28, 2032.68,     kl: 12.02, 11.77,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1482, step:37075 (TRAIN, VALID): total: 2041.86, 2046.83      recon: 2027.29, 2032.50,     kl: 12.04, 11.80,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1483, step:37100 (TRAIN, VALID): total: 2041.78, 2046.54      recon: 2027.24, 2032.24,     kl: 12.01, 11.78,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1484, step:37125 (TRAIN, VALID): total: 2041.89, 2046.40      recon: 2027.36, 2032.11,     kl: 12.01, 11.76,     l2: 2.52455,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1485, step:37150 (TRAIN, VALID): total: 2041.83, 2046.50      recon: 2027.29, 2032.19,     kl: 12.02, 11.79,     l2: 2.52456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1486, step:37175 (TRAIN, VALID): total: 2041.89, 2047.31      recon: 2027.35, 2033.01,     kl: 12.02, 11.78,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1487, step:37200 (TRAIN, VALID): total: 2041.82, 2047.38      recon: 2027.27, 2033.07,     kl: 12.02, 11.79,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1488, step:37225 (TRAIN, VALID): total: 2041.75, 2046.65      recon: 2027.20, 2032.33,     kl: 12.02, 11.79,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1489, step:37250 (TRAIN, VALID): total: 2041.87, 2047.58      recon: 2027.33, 2033.25,     kl: 12.02, 11.80,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1490, step:37275 (TRAIN, VALID): total: 2041.86, 2047.16      recon: 2027.34, 2032.83,     kl: 12.00, 11.81,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1491, step:37300 (TRAIN, VALID): total: 2041.90, 2046.29      recon: 2027.36, 2032.00,     kl: 12.02, 11.77,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000021.\n",
      "Epoch:1492, step:37325 (TRAIN, VALID): total: 2042.03, 2048.00      recon: 2027.50, 2033.69,     kl: 12.01, 11.78,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1493, step:37350 (TRAIN, VALID): total: 2042.08, 2046.88      recon: 2027.51, 2032.57,     kl: 12.05, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1494, step:37375 (TRAIN, VALID): total: 2041.90, 2047.25      recon: 2027.35, 2032.90,     kl: 12.03, 11.82,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1495, step:37400 (TRAIN, VALID): total: 2041.86, 2046.14      recon: 2027.32, 2031.84,     kl: 12.02, 11.78,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1496, step:37425 (TRAIN, VALID): total: 2042.03, 2047.58      recon: 2027.49, 2033.24,     kl: 12.02, 11.82,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1497, step:37450 (TRAIN, VALID): total: 2041.88, 2045.92      recon: 2027.32, 2031.61,     kl: 12.04, 11.79,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1498, step:37475 (TRAIN, VALID): total: 2042.16, 2046.64      recon: 2027.61, 2032.33,     kl: 12.03, 11.78,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000020.\n",
      "Epoch:1499, step:37500 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.48, 2032.14,     kl: 12.04, 11.82,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1500, step:37525 (TRAIN, VALID): total: 2041.88, 2046.20      recon: 2027.31, 2031.89,     kl: 12.04, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1501, step:37550 (TRAIN, VALID): total: 2042.00, 2047.11      recon: 2027.43, 2032.79,     kl: 12.05, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1502, step:37575 (TRAIN, VALID): total: 2042.14, 2046.55      recon: 2027.60, 2032.21,     kl: 12.02, 11.82,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1503, step:37600 (TRAIN, VALID): total: 2041.88, 2046.29      recon: 2027.30, 2031.96,     kl: 12.05, 11.81,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1504, step:37625 (TRAIN, VALID): total: 2041.86, 2047.11      recon: 2027.31, 2032.77,     kl: 12.02, 11.82,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1505, step:37650 (TRAIN, VALID): total: 2041.87, 2046.85      recon: 2027.32, 2032.53,     kl: 12.03, 11.80,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1506, step:37675 (TRAIN, VALID): total: 2041.87, 2046.87      recon: 2027.33, 2032.54,     kl: 12.01, 11.81,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1507, step:37700 (TRAIN, VALID): total: 2041.76, 2046.90      recon: 2027.20, 2032.58,     kl: 12.04, 11.80,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1508, step:37725 (TRAIN, VALID): total: 2041.82, 2047.46      recon: 2027.26, 2033.16,     kl: 12.03, 11.78,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1509, step:37750 (TRAIN, VALID): total: 2042.05, 2046.42      recon: 2027.50, 2032.11,     kl: 12.03, 11.79,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000019.\n",
      "Epoch:1510, step:37775 (TRAIN, VALID): total: 2041.97, 2046.66      recon: 2027.44, 2032.28,     kl: 12.01, 11.85,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1511, step:37800 (TRAIN, VALID): total: 2041.91, 2047.70      recon: 2027.38, 2033.39,     kl: 12.00, 11.79,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1512, step:37825 (TRAIN, VALID): total: 2041.83, 2047.14      recon: 2027.29, 2032.83,     kl: 12.01, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1513, step:37850 (TRAIN, VALID): total: 2041.76, 2047.22      recon: 2027.21, 2032.89,     kl: 12.03, 11.81,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1514, step:37875 (TRAIN, VALID): total: 2042.01, 2045.34      recon: 2027.46, 2031.00,     kl: 12.03, 11.81,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1515, step:37900 (TRAIN, VALID): total: 2041.99, 2047.57      recon: 2027.46, 2033.25,     kl: 12.01, 11.80,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1516, step:37925 (TRAIN, VALID): total: 2041.87, 2046.63      recon: 2027.32, 2032.28,     kl: 12.03, 11.83,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1517, step:37950 (TRAIN, VALID): total: 2041.80, 2046.82      recon: 2027.25, 2032.50,     kl: 12.02, 11.80,     l2: 2.52453,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1518, step:37975 (TRAIN, VALID): total: 2041.88, 2046.84      recon: 2027.32, 2032.51,     kl: 12.03, 11.81,     l2: 2.52451,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1519, step:38000 (TRAIN, VALID): total: 2041.87, 2046.24      recon: 2027.32, 2031.93,     kl: 12.02, 11.79,     l2: 2.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1520, step:38025 (TRAIN, VALID): total: 2041.86, 2046.55      recon: 2027.32, 2032.25,     kl: 12.02, 11.78,     l2: 2.52450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1521, step:38050 (TRAIN, VALID): total: 2041.86, 2047.05      recon: 2027.31, 2032.73,     kl: 12.02, 11.79,     l2: 2.52449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1522, step:38075 (TRAIN, VALID): total: 2041.79, 2046.76      recon: 2027.25, 2032.48,     kl: 12.01, 11.76,     l2: 2.52452,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1523, step:38100 (TRAIN, VALID): total: 2042.04, 2046.48      recon: 2027.49, 2032.18,     kl: 12.03, 11.78,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000018.\n",
      "Epoch:1524, step:38125 (TRAIN, VALID): total: 2041.93, 2046.23      recon: 2027.40, 2031.90,     kl: 12.01, 11.81,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1525, step:38150 (TRAIN, VALID): total: 2041.83, 2046.23      recon: 2027.30, 2031.89,     kl: 12.01, 11.81,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1526, step:38175 (TRAIN, VALID): total: 2041.91, 2046.45      recon: 2027.38, 2032.12,     kl: 12.00, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1527, step:38200 (TRAIN, VALID): total: 2041.93, 2046.13      recon: 2027.38, 2031.82,     kl: 12.03, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1528, step:38225 (TRAIN, VALID): total: 2041.88, 2045.70      recon: 2027.32, 2031.38,     kl: 12.03, 11.79,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1529, step:38250 (TRAIN, VALID): total: 2041.83, 2046.91      recon: 2027.30, 2032.54,     kl: 12.01, 11.85,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1530, step:38275 (TRAIN, VALID): total: 2041.89, 2046.19      recon: 2027.33, 2031.87,     kl: 12.04, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1531, step:38300 (TRAIN, VALID): total: 2041.91, 2047.03      recon: 2027.36, 2032.68,     kl: 12.03, 11.83,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1532, step:38325 (TRAIN, VALID): total: 2041.79, 2046.41      recon: 2027.24, 2032.09,     kl: 12.03, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1533, step:38350 (TRAIN, VALID): total: 2041.72, 2047.08      recon: 2027.16, 2032.77,     kl: 12.03, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1534, step:38375 (TRAIN, VALID): total: 2041.84, 2045.73      recon: 2027.30, 2031.41,     kl: 12.01, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1535, step:38400 (TRAIN, VALID): total: 2041.92, 2046.25      recon: 2027.39, 2031.92,     kl: 12.01, 11.80,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000017.\n",
      "Epoch:1536, step:38425 (TRAIN, VALID): total: 2041.86, 2047.58      recon: 2027.31, 2033.29,     kl: 12.02, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1537, step:38450 (TRAIN, VALID): total: 2041.87, 2045.43      recon: 2027.33, 2031.12,     kl: 12.02, 11.78,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1538, step:38475 (TRAIN, VALID): total: 2041.78, 2045.79      recon: 2027.24, 2031.48,     kl: 12.02, 11.79,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1539, step:38500 (TRAIN, VALID): total: 2041.82, 2047.21      recon: 2027.29, 2032.87,     kl: 12.00, 11.81,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1540, step:38525 (TRAIN, VALID): total: 2041.77, 2045.57      recon: 2027.24, 2031.25,     kl: 12.01, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1541, step:38550 (TRAIN, VALID): total: 2041.81, 2046.64      recon: 2027.27, 2032.32,     kl: 12.02, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1542, step:38575 (TRAIN, VALID): total: 2041.76, 2046.60      recon: 2027.22, 2032.28,     kl: 12.02, 11.79,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1543, step:38600 (TRAIN, VALID): total: 2041.81, 2046.18      recon: 2027.27, 2031.87,     kl: 12.02, 11.78,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1544, step:38625 (TRAIN, VALID): total: 2041.89, 2046.50      recon: 2027.38, 2032.19,     kl: 11.98, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000016.\n",
      "Epoch:1545, step:38650 (TRAIN, VALID): total: 2041.85, 2044.65      recon: 2027.31, 2030.35,     kl: 12.02, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1546, step:38675 (TRAIN, VALID): total: 2041.87, 2047.73      recon: 2027.34, 2033.42,     kl: 12.00, 11.79,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1547, step:38700 (TRAIN, VALID): total: 2041.79, 2048.15      recon: 2027.27, 2033.82,     kl: 12.00, 11.80,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1548, step:38725 (TRAIN, VALID): total: 2041.86, 2046.80      recon: 2027.34, 2032.50,     kl: 11.99, 11.78,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1549, step:38750 (TRAIN, VALID): total: 2041.83, 2046.20      recon: 2027.29, 2031.89,     kl: 12.02, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1550, step:38775 (TRAIN, VALID): total: 2041.86, 2047.19      recon: 2027.33, 2032.87,     kl: 12.01, 11.79,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1551, step:38800 (TRAIN, VALID): total: 2041.84, 2045.81      recon: 2027.32, 2031.51,     kl: 12.00, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1552, step:38825 (TRAIN, VALID): total: 2042.30, 2047.48      recon: 2027.75, 2033.16,     kl: 12.03, 11.80,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000016.\n",
      "Epoch:1553, step:38850 (TRAIN, VALID): total: 2041.76, 2045.94      recon: 2027.20, 2031.65,     kl: 12.03, 11.77,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1554, step:38875 (TRAIN, VALID): total: 2041.82, 2047.96      recon: 2027.29, 2033.66,     kl: 12.01, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1555, step:38900 (TRAIN, VALID): total: 2041.82, 2047.30      recon: 2027.27, 2033.02,     kl: 12.03, 11.75,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1556, step:38925 (TRAIN, VALID): total: 2041.82, 2046.89      recon: 2027.27, 2032.59,     kl: 12.02, 11.78,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1557, step:38950 (TRAIN, VALID): total: 2041.87, 2046.23      recon: 2027.34, 2031.94,     kl: 12.01, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1558, step:38975 (TRAIN, VALID): total: 2041.77, 2045.67      recon: 2027.23, 2031.40,     kl: 12.01, 11.74,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1559, step:39000 (TRAIN, VALID): total: 2041.84, 2047.24      recon: 2027.32, 2032.91,     kl: 11.99, 11.81,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1560, step:39025 (TRAIN, VALID): total: 2041.86, 2045.78      recon: 2027.34, 2031.46,     kl: 12.00, 11.80,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1561, step:39050 (TRAIN, VALID): total: 2041.91, 2047.16      recon: 2027.39, 2032.88,     kl: 12.00, 11.76,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000015.\n",
      "Epoch:1562, step:39075 (TRAIN, VALID): total: 2041.82, 2046.99      recon: 2027.29, 2032.69,     kl: 12.01, 11.78,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1563, step:39100 (TRAIN, VALID): total: 2041.75, 2046.76      recon: 2027.23, 2032.46,     kl: 12.00, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1564, step:39125 (TRAIN, VALID): total: 2041.97, 2045.56      recon: 2027.43, 2031.25,     kl: 12.02, 11.78,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1565, step:39150 (TRAIN, VALID): total: 2041.75, 2046.66      recon: 2027.22, 2032.33,     kl: 12.00, 11.81,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1566, step:39175 (TRAIN, VALID): total: 2041.80, 2046.00      recon: 2027.30, 2031.74,     kl: 11.98, 11.74,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1567, step:39200 (TRAIN, VALID): total: 2041.84, 2046.49      recon: 2027.33, 2032.18,     kl: 11.98, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1568, step:39225 (TRAIN, VALID): total: 2041.81, 2046.39      recon: 2027.30, 2032.11,     kl: 11.99, 11.76,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1569, step:39250 (TRAIN, VALID): total: 2041.82, 2048.37      recon: 2027.30, 2034.05,     kl: 12.00, 11.79,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1570, step:39275 (TRAIN, VALID): total: 2041.87, 2045.81      recon: 2027.35, 2031.51,     kl: 11.99, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1571, step:39300 (TRAIN, VALID): total: 2041.80, 2046.89      recon: 2027.30, 2032.61,     kl: 11.98, 11.76,     l2: 2.52447,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1572, step:39325 (TRAIN, VALID): total: 2041.73, 2046.71      recon: 2027.23, 2032.40,     kl: 11.98, 11.78,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1573, step:39350 (TRAIN, VALID): total: 2041.83, 2046.74      recon: 2027.30, 2032.45,     kl: 12.01, 11.77,     l2: 2.52446,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1574, step:39375 (TRAIN, VALID): total: 2041.93, 2047.27      recon: 2027.41, 2032.98,     kl: 12.00, 11.77,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000014.\n",
      "Epoch:1575, step:39400 (TRAIN, VALID): total: 2041.86, 2046.70      recon: 2027.35, 2032.40,     kl: 11.99, 11.77,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1576, step:39425 (TRAIN, VALID): total: 2041.89, 2048.37      recon: 2027.37, 2034.04,     kl: 12.00, 11.80,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1577, step:39450 (TRAIN, VALID): total: 2041.74, 2046.14      recon: 2027.21, 2031.86,     kl: 12.01, 11.75,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1578, step:39475 (TRAIN, VALID): total: 2041.79, 2046.93      recon: 2027.25, 2032.61,     kl: 12.01, 11.80,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1579, step:39500 (TRAIN, VALID): total: 2041.88, 2046.27      recon: 2027.35, 2031.98,     kl: 12.00, 11.77,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1580, step:39525 (TRAIN, VALID): total: 2042.10, 2045.85      recon: 2027.56, 2031.58,     kl: 12.01, 11.75,     l2: 2.52445,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1581, step:39550 (TRAIN, VALID): total: 2042.14, 2047.35      recon: 2027.61, 2033.07,     kl: 12.00, 11.76,     l2: 2.52444,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000013.\n",
      "Epoch:1582, step:39575 (TRAIN, VALID): total: 2041.83, 2046.59      recon: 2027.29, 2032.27,     kl: 12.02, 11.79,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1583, step:39600 (TRAIN, VALID): total: 2041.85, 2047.09      recon: 2027.30, 2032.76,     kl: 12.03, 11.81,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1584, step:39625 (TRAIN, VALID): total: 2041.86, 2047.73      recon: 2027.30, 2033.40,     kl: 12.03, 11.80,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1585, step:39650 (TRAIN, VALID): total: 2041.91, 2047.11      recon: 2027.37, 2032.79,     kl: 12.02, 11.79,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1586, step:39675 (TRAIN, VALID): total: 2041.83, 2045.82      recon: 2027.28, 2031.51,     kl: 12.02, 11.78,     l2: 2.52441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1587, step:39700 (TRAIN, VALID): total: 2041.84, 2046.95      recon: 2027.31, 2032.62,     kl: 12.00, 11.80,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1588, step:39725 (TRAIN, VALID): total: 2041.83, 2046.08      recon: 2027.30, 2031.73,     kl: 12.01, 11.83,     l2: 2.52443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1589, step:39750 (TRAIN, VALID): total: 2041.79, 2047.32      recon: 2027.25, 2033.02,     kl: 12.01, 11.78,     l2: 2.52442,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1590, step:39775 (TRAIN, VALID): total: 2041.86, 2046.09      recon: 2027.34, 2031.83,     kl: 12.00, 11.74,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1591, step:39800 (TRAIN, VALID): total: 2041.78, 2047.51      recon: 2027.24, 2033.22,     kl: 12.02, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1592, step:39825 (TRAIN, VALID): total: 2041.70, 2046.70      recon: 2027.17, 2032.41,     kl: 12.01, 11.76,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1593, step:39850 (TRAIN, VALID): total: 2042.09, 2046.09      recon: 2027.56, 2031.81,     kl: 12.00, 11.76,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000013.\n",
      "Epoch:1594, step:39875 (TRAIN, VALID): total: 2041.86, 2046.96      recon: 2027.33, 2032.66,     kl: 12.01, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1595, step:39900 (TRAIN, VALID): total: 2041.85, 2046.58      recon: 2027.32, 2032.28,     kl: 12.01, 11.77,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1596, step:39925 (TRAIN, VALID): total: 2041.91, 2047.33      recon: 2027.36, 2033.02,     kl: 12.02, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1597, step:39950 (TRAIN, VALID): total: 2041.83, 2047.07      recon: 2027.28, 2032.76,     kl: 12.03, 11.78,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1598, step:39975 (TRAIN, VALID): total: 2041.89, 2047.43      recon: 2027.36, 2033.10,     kl: 12.00, 11.81,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1599, step:40000 (TRAIN, VALID): total: 2041.86, 2045.07      recon: 2027.31, 2030.78,     kl: 12.03, 11.76,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1600, step:40025 (TRAIN, VALID): total: 2041.88, 2046.07      recon: 2027.34, 2031.77,     kl: 12.01, 11.78,     l2: 2.52438,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1601, step:40050 (TRAIN, VALID): total: 2041.92, 2046.90      recon: 2027.39, 2032.60,     kl: 12.00, 11.78,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000012.\n",
      "Epoch:1602, step:40075 (TRAIN, VALID): total: 2042.11, 2046.33      recon: 2027.57, 2032.00,     kl: 12.01, 11.80,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1603, step:40100 (TRAIN, VALID): total: 2041.88, 2046.54      recon: 2027.35, 2032.21,     kl: 12.01, 11.80,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1604, step:40125 (TRAIN, VALID): total: 2042.01, 2046.67      recon: 2027.45, 2032.36,     kl: 12.04, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1605, step:40150 (TRAIN, VALID): total: 2041.88, 2045.35      recon: 2027.33, 2031.03,     kl: 12.02, 11.79,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1606, step:40175 (TRAIN, VALID): total: 2041.95, 2047.56      recon: 2027.40, 2033.24,     kl: 12.03, 11.80,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1607, step:40200 (TRAIN, VALID): total: 2042.04, 2047.06      recon: 2027.49, 2032.74,     kl: 12.03, 11.80,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1608, step:40225 (TRAIN, VALID): total: 2041.79, 2047.60      recon: 2027.25, 2033.27,     kl: 12.02, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1609, step:40250 (TRAIN, VALID): total: 2041.79, 2047.44      recon: 2027.23, 2033.12,     kl: 12.03, 11.80,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1610, step:40275 (TRAIN, VALID): total: 2041.78, 2047.23      recon: 2027.22, 2032.87,     kl: 12.03, 11.84,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1611, step:40300 (TRAIN, VALID): total: 2041.91, 2047.33      recon: 2027.37, 2033.00,     kl: 12.02, 11.81,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1612, step:40325 (TRAIN, VALID): total: 2042.06, 2047.03      recon: 2027.51, 2032.69,     kl: 12.03, 11.81,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000011.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1613, step:40350 (TRAIN, VALID): total: 2041.89, 2046.10      recon: 2027.34, 2031.78,     kl: 12.02, 11.80,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1614, step:40375 (TRAIN, VALID): total: 2041.90, 2046.73      recon: 2027.36, 2032.38,     kl: 12.02, 11.82,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1615, step:40400 (TRAIN, VALID): total: 2041.90, 2046.65      recon: 2027.35, 2032.32,     kl: 12.02, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1616, step:40425 (TRAIN, VALID): total: 2041.80, 2045.93      recon: 2027.26, 2031.62,     kl: 12.02, 11.79,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1617, step:40450 (TRAIN, VALID): total: 2041.74, 2047.72      recon: 2027.18, 2033.38,     kl: 12.04, 11.81,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1618, step:40475 (TRAIN, VALID): total: 2041.82, 2046.42      recon: 2027.27, 2032.09,     kl: 12.02, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1619, step:40500 (TRAIN, VALID): total: 2041.88, 2046.33      recon: 2027.32, 2032.06,     kl: 12.03, 11.75,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1620, step:40525 (TRAIN, VALID): total: 2041.84, 2045.79      recon: 2027.30, 2031.52,     kl: 12.01, 11.75,     l2: 2.52433,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1621, step:40550 (TRAIN, VALID): total: 2041.75, 2046.16      recon: 2027.20, 2031.86,     kl: 12.03, 11.78,     l2: 2.52432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1622, step:40575 (TRAIN, VALID): total: 2041.85, 2046.73      recon: 2027.31, 2032.40,     kl: 12.02, 11.81,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1623, step:40600 (TRAIN, VALID): total: 2041.71, 2045.93      recon: 2027.17, 2031.64,     kl: 12.02, 11.77,     l2: 2.52432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1624, step:40625 (TRAIN, VALID): total: 2041.92, 2046.28      recon: 2027.37, 2031.98,     kl: 12.03, 11.78,     l2: 2.52431,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000011.\n",
      "Epoch:1625, step:40650 (TRAIN, VALID): total: 2041.81, 2046.36      recon: 2027.29, 2032.04,     kl: 11.99, 11.80,     l2: 2.52429,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1626, step:40675 (TRAIN, VALID): total: 2041.75, 2046.50      recon: 2027.21, 2032.20,     kl: 12.01, 11.78,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1627, step:40700 (TRAIN, VALID): total: 2041.86, 2046.78      recon: 2027.32, 2032.47,     kl: 12.01, 11.78,     l2: 2.52434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1628, step:40725 (TRAIN, VALID): total: 2041.77, 2045.76      recon: 2027.23, 2031.45,     kl: 12.02, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1629, step:40750 (TRAIN, VALID): total: 2041.87, 2047.64      recon: 2027.32, 2033.33,     kl: 12.03, 11.78,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1630, step:40775 (TRAIN, VALID): total: 2041.79, 2046.35      recon: 2027.27, 2032.02,     kl: 11.99, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1631, step:40800 (TRAIN, VALID): total: 2041.88, 2046.20      recon: 2027.35, 2031.91,     kl: 12.00, 11.76,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000010.\n",
      "Epoch:1632, step:40825 (TRAIN, VALID): total: 2042.04, 2046.65      recon: 2027.49, 2032.32,     kl: 12.03, 11.81,     l2: 2.52440,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1633, step:40850 (TRAIN, VALID): total: 2042.04, 2046.22      recon: 2027.49, 2031.92,     kl: 12.03, 11.78,     l2: 2.52439,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1634, step:40875 (TRAIN, VALID): total: 2042.02, 2047.05      recon: 2027.46, 2032.74,     kl: 12.03, 11.79,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1635, step:40900 (TRAIN, VALID): total: 2041.79, 2047.49      recon: 2027.23, 2033.16,     kl: 12.04, 11.80,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1636, step:40925 (TRAIN, VALID): total: 2041.83, 2047.53      recon: 2027.25, 2033.20,     kl: 12.05, 11.81,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1637, step:40950 (TRAIN, VALID): total: 2041.86, 2047.12      recon: 2027.31, 2032.81,     kl: 12.03, 11.79,     l2: 2.52436,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1638, step:40975 (TRAIN, VALID): total: 2041.83, 2047.02      recon: 2027.28, 2032.73,     kl: 12.02, 11.77,     l2: 2.52437,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:1639, step:41000 (TRAIN, VALID): total: 2042.13, 2046.17      recon: 2027.59, 2031.86,     kl: 12.02, 11.78,     l2: 2.52435,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000010.\n",
      "Stopping optimization based on learning rate criteria.\n"
     ]
    }
   ],
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=chaotic_rnn_no_inputs \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_no_inputs \\\n",
    "--co_dim=0 \\\n",
    "--factors_dim=20 \\\n",
    "--ext_input_dim=0 \\\n",
    "--controller_input_lag=1 \\\n",
    "--output_dist=poisson \\\n",
    "--do_causal_controller=false \\\n",
    "--batch_size=128 \\\n",
    "--learning_rate_init=0.01 \\\n",
    "--learning_rate_stop=1e-05 \\\n",
    "--learning_rate_decay_factor=0.95 \\\n",
    "--learning_rate_n_to_compare=6 \\\n",
    "--do_reset_learning_rate=false \\\n",
    "--keep_prob=0.95 \\\n",
    "--con_dim=128 \\\n",
    "--gen_dim=200 \\\n",
    "--ci_enc_dim=128 \\\n",
    "--ic_dim=64 \\\n",
    "--ic_enc_dim=128 \\\n",
    "--ic_prior_var_min=0.1 \\\n",
    "--gen_cell_input_weight_scale=1.0 \\\n",
    "--cell_weight_scale=1.0 \\\n",
    "--do_feed_factors_to_controller=true \\\n",
    "--kl_start_step=0 \\\n",
    "--kl_increase_steps=2000 \\\n",
    "--kl_ic_weight=1.0 \\\n",
    "--l2_con_scale=0.0 \\\n",
    "--l2_gen_scale=2000.0 \\\n",
    "--l2_start_step=0 \\\n",
    "--l2_increase_steps=2000 \\\n",
    "--ic_prior_var_scale=0.1 \\\n",
    "--ic_post_var_min=0.0001 \\\n",
    "--kl_co_weight=1.0 \\\n",
    "--prior_ar_nvar=0.1 \\\n",
    "--cell_clip_value=5.0 \\\n",
    "--max_ckpt_to_keep_lve=5 \\\n",
    "--do_train_prior_ar_atau=true \\\n",
    "--co_prior_var_scale=0.1 \\\n",
    "--csv_log=fitlog \\\n",
    "--feedback_factors_or_rates=factors \\\n",
    "--do_train_prior_ar_nvar=true \\\n",
    "--max_grad_norm=200.0 \\\n",
    "--device=gpu:0 \\\n",
    "--num_steps_for_gen_ic=100000000 \\\n",
    "--ps_nexamples_to_process=100000000 \\\n",
    "--checkpoint_name=lfads_vae \\\n",
    "--temporal_spike_jitter_width=0 \\\n",
    "--checkpoint_pb_load_name=checkpoint \\\n",
    "--inject_ext_input_to_gen=false \\\n",
    "--co_mean_corr_scale=0.0 \\\n",
    "--gen_cell_rec_weight_scale=1.0 \\\n",
    "--max_ckpt_to_keep=5 \\\n",
    "--output_filename_stem=\"\" \\\n",
    "--ic_prior_var_max=0.1 \\\n",
    "--prior_ar_atau=10.0 \\\n",
    "--do_train_io_only=false \\\n",
    "--do_train_encoder_only=false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lucazurmuehle/anaconda3/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Reading data from  /tmp/rnn_synth_data_v1.0/\n",
      "loading data from /tmp/rnn_synth_data_v1.0/ with stem gaussian_chaotic_rnn_no_inputs\n",
      "1 datasets loaded\n",
      "Found training set with number examples:  3200\n",
      "Found validation set with number examples:  800\n",
      "2018-04-19 00:06:34.739837: I tensorflow/core/platform/cpu_feature_guard.cc:137] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.2 AVX AVX2 FMA\n",
      "Building graph...\n",
      "/Users/lucazurmuehle/Documents/GitHub/tensorflow/models/research/lfads/lfads.py:327: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  datasets[hps.dataset_names[0]]['train_data'].dtype, float), \\\n",
      "done.\n",
      "Model Variables (to be optimized): \n",
      "     0 LFADS/glm/fac_2_means_dataset_N50_S50/W:0 [20, 50]\n",
      "     1 LFADS/glm/fac_2_means_dataset_N50_S50/b:0 [1, 50]\n",
      "     2 LFADS/glm/fac_2_logvars_dataset_N50_S50/W:0 [20, 50]\n",
      "     3 LFADS/glm/fac_2_logvars_dataset_N50_S50/b:0 [1, 50]\n",
      "     4 LFADS/ic_enc_fwd/ic_enc_t0_fwd:0 [1, 128]\n",
      "     5 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     6 LFADS/ic_enc_fwd/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     7 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     8 LFADS/ic_enc_fwd/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     9 LFADS/ic_enc_rev/ic_enc_t0_rev:0 [1, 128]\n",
      "     10 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     11 LFADS/ic_enc_rev/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     12 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     13 LFADS/ic_enc_rev/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     14 LFADS/ci_enc_fwd/ci_enc_t0_fwd:0 [1, 128]\n",
      "     15 LFADS/ci_enc_fwd/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     16 LFADS/ci_enc_fwd/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     17 LFADS/ci_enc_fwd/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     18 LFADS/ci_enc_fwd/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     19 LFADS/ci_enc_rev/ci_enc_t0_rev:0 [1, 128]\n",
      "     20 LFADS/ci_enc_rev/GRU/Gates/xh_2_ru/W:0 [178, 256]\n",
      "     21 LFADS/ci_enc_rev/GRU/Gates/xh_2_ru/b:0 [1, 256]\n",
      "     22 LFADS/ci_enc_rev/GRU/Candidate/xrh_2_c/W:0 [178, 128]\n",
      "     23 LFADS/ci_enc_rev/GRU/Candidate/xrh_2_c/b:0 [1, 128]\n",
      "     24 LFADS/z/prior_g0/mean:0 [1, 64]\n",
      "     25 LFADS/z/ic_enc_2_post_g0/mean/W:0 [256, 64]\n",
      "     26 LFADS/z/ic_enc_2_post_g0/mean/b:0 [1, 64]\n",
      "     27 LFADS/z/ic_enc_2_post_g0/logvar/W:0 [256, 64]\n",
      "     28 LFADS/z/ic_enc_2_post_g0/logvar/b:0 [1, 64]\n",
      "     29 LFADS/z/u_prior_ar1/logevars:0 [1, 1]\n",
      "     30 LFADS/z/u_prior_ar1/logatau:0 [1, 1]\n",
      "     31 LFADS/con/c0:0 [1, 128]\n",
      "     32 LFADS/gen/g0_2_gen_ic/W:0 [64, 200]\n",
      "     33 LFADS/gen/g0_2_gen_ic/b:0 [1, 200]\n",
      "     34 LFADS/gen/gen_2_fac/W:0 [200, 20]\n",
      "     35 LFADS/con/GenGRU/Gates/x_2_ru/W:0 [276, 256]\n",
      "     36 LFADS/con/GenGRU/Gates/h_2_ru/W:0 [128, 256]\n",
      "     37 LFADS/con/GenGRU/Gates/h_2_ru/b:0 [1, 256]\n",
      "     38 LFADS/con/GenGRU/Candidate/x_2_c/W:0 [276, 128]\n",
      "     39 LFADS/con/GenGRU/Candidate/rh_2_c/W:0 [128, 128]\n",
      "     40 LFADS/con/GenGRU/Candidate/rh_2_c/b:0 [1, 128]\n",
      "     41 LFADS/con/con_to_post_co/mean/W:0 [128, 1]\n",
      "     42 LFADS/con/con_to_post_co/mean/b:0 [1, 1]\n",
      "     43 LFADS/con/con_to_post_co/logvar/W:0 [128, 1]\n",
      "     44 LFADS/con/con_to_post_co/logvar/b:0 [1, 1]\n",
      "     45 LFADS/gen/GenGRU/Gates/x_2_ru/W:0 [1, 400]\n",
      "     46 LFADS/gen/GenGRU/Gates/h_2_ru/W:0 [200, 400]\n",
      "     47 LFADS/gen/GenGRU/Gates/h_2_ru/b:0 [1, 400]\n",
      "     48 LFADS/gen/GenGRU/Candidate/x_2_c/W:0 [1, 200]\n",
      "     49 LFADS/gen/GenGRU/Candidate/rh_2_c/W:0 [200, 200]\n",
      "     50 LFADS/gen/GenGRU/Candidate/rh_2_c/b:0 [1, 200]\n",
      "Total model parameters:  604624\n",
      "Loading latest training checkpoint in:  /tmp/lfads_chaotic_rnn_inputs_g2p5\n",
      "ckpt:  model_checkpoint_path: \"/tmp/lfads_chaotic_rnn_inputs_g2p5/lfads_vae.ckpt-525\"\n",
      "all_model_checkpoint_paths: \"/tmp/lfads_chaotic_rnn_inputs_g2p5/lfads_vae.ckpt-25\"\n",
      "all_model_checkpoint_paths: \"/tmp/lfads_chaotic_rnn_inputs_g2p5/lfads_vae.ckpt-275\"\n",
      "all_model_checkpoint_paths: \"/tmp/lfads_chaotic_rnn_inputs_g2p5/lfads_vae.ckpt-525\"\n",
      "\n",
      "Reading model parameters from /tmp/lfads_chaotic_rnn_inputs_g2p5/lfads_vae.ckpt-525\n",
      "Epoch:0, step:550 (TRAIN, VALID): total: 20832.31, 20814.32      recon: 20804.12, 20788.69,     kl: 100.93, 89.06,     l2: 4.13642,      kl weight: 0.27, l2 weight: 0.27\n",
      "Epoch:1, step:575 (TRAIN, VALID): total: 20825.84, 20805.06      recon: 20799.77, 20780.76,     kl: 88.69, 80.38,     l2: 4.15283,      kl weight: 0.29, l2 weight: 0.29\n",
      "Epoch:2, step:600 (TRAIN, VALID): total: 20819.73, 20794.26      recon: 20794.06, 20770.99,     kl: 83.34, 73.41,     l2: 4.16405,      kl weight: 0.30, l2 weight: 0.30\n",
      "Epoch:3, step:625 (TRAIN, VALID): total: 20818.63, 20800.55      recon: 20792.76, 20777.05,     kl: 80.37, 71.01,     l2: 4.17548,      kl weight: 0.31, l2 weight: 0.31\n",
      "Epoch:4, step:650 (TRAIN, VALID): total: 20822.50, 20797.43      recon: 20794.76, 20772.83,     kl: 82.91, 71.48,     l2: 4.18666,      kl weight: 0.32, l2 weight: 0.32\n",
      "Epoch:5, step:675 (TRAIN, VALID): total: 20819.68, 20793.16      recon: 20792.81, 20769.30,     kl: 76.98, 66.49,     l2: 4.19909,      kl weight: 0.34, l2 weight: 0.34\n",
      "Epoch:6, step:700 (TRAIN, VALID): total: 20816.92, 20795.14      recon: 20790.36, 20769.35,     kl: 73.13, 69.48,     l2: 4.21009,      kl weight: 0.35, l2 weight: 0.35\n",
      "Epoch:7, step:725 (TRAIN, VALID): total: 20823.47, 20803.55      recon: 20793.84, 20774.16,     kl: 79.01, 76.84,     l2: 4.22074,      kl weight: 0.36, l2 weight: 0.36\n",
      "Epoch:8, step:750 (TRAIN, VALID): total: 20819.23, 20795.28      recon: 20790.36, 20766.74,     kl: 74.10, 71.87,     l2: 4.23306,      kl weight: 0.37, l2 weight: 0.37\n",
      "Epoch:9, step:775 (TRAIN, VALID): total: 20816.24, 20789.85      recon: 20787.92, 20763.97,     kl: 70.11, 62.54,     l2: 4.24156,      kl weight: 0.39, l2 weight: 0.39\n",
      "Epoch:10, step:800 (TRAIN, VALID): total: 20812.75, 20790.14      recon: 20785.52, 20763.04,     kl: 64.98, 63.50,     l2: 4.24430,      kl weight: 0.40, l2 weight: 0.40\n",
      "Epoch:11, step:825 (TRAIN, VALID): total: 20811.17, 20786.62      recon: 20783.40, 20760.09,     kl: 64.15, 60.07,     l2: 4.24807,      kl weight: 0.41, l2 weight: 0.41\n",
      "Epoch:12, step:850 (TRAIN, VALID): total: 20813.17, 20798.33      recon: 20784.98, 20769.69,     kl: 63.10, 63.14,     l2: 4.24959,      kl weight: 0.42, l2 weight: 0.42\n",
      "Epoch:13, step:875 (TRAIN, VALID): total: 20814.21, 20794.00      recon: 20785.70, 20765.76,     kl: 61.91, 60.30,     l2: 4.25625,      kl weight: 0.44, l2 weight: 0.44\n",
      "Epoch:14, step:900 (TRAIN, VALID): total: 20812.90, 20790.65      recon: 20783.39, 20762.61,     kl: 62.29, 58.05,     l2: 4.26394,      kl weight: 0.45, l2 weight: 0.45\n",
      "Epoch:15, step:925 (TRAIN, VALID): total: 20809.02, 20789.26      recon: 20781.09, 20761.36,     kl: 56.99, 56.04,     l2: 4.26569,      kl weight: 0.46, l2 weight: 0.46\n",
      "Epoch:16, step:950 (TRAIN, VALID): total: 20809.76, 20795.10      recon: 20781.82, 20766.58,     kl: 55.38, 55.77,     l2: 4.26263,      kl weight: 0.47, l2 weight: 0.47\n",
      "Epoch:17, step:975 (TRAIN, VALID): total: 20815.22, 20789.97      recon: 20783.65, 20761.16,     kl: 61.38, 54.83,     l2: 4.26588,      kl weight: 0.49, l2 weight: 0.49\n",
      "     Decreasing learning rate to 0.009500.\n",
      "Epoch:18, step:1000 (TRAIN, VALID): total: 20808.55, 20789.56      recon: 20779.55, 20764.55,     kl: 54.52, 45.77,     l2: 4.26466,      kl weight: 0.50, l2 weight: 0.50\n",
      "Epoch:19, step:1025 (TRAIN, VALID): total: 20811.55, 20803.58      recon: 20782.14, 20774.49,     kl: 53.84, 52.48,     l2: 4.26401,      kl weight: 0.51, l2 weight: 0.51\n",
      "Epoch:20, step:1050 (TRAIN, VALID): total: 20815.70, 20789.56      recon: 20785.70, 20762.37,     kl: 53.61, 47.51,     l2: 4.27509,      kl weight: 0.52, l2 weight: 0.52\n",
      "Epoch:21, step:1075 (TRAIN, VALID): total: 20808.76, 20788.77      recon: 20779.92, 20763.08,     kl: 50.04, 43.52,     l2: 4.27498,      kl weight: 0.54, l2 weight: 0.54\n",
      "Epoch:22, step:1100 (TRAIN, VALID): total: 20805.61, 20786.35      recon: 20777.70, 20762.24,     kl: 47.07, 39.56,     l2: 4.26862,      kl weight: 0.55, l2 weight: 0.55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:23, step:1125 (TRAIN, VALID): total: 20810.87, 20795.04      recon: 20782.02, 20758.40,     kl: 47.61, 60.88,     l2: 4.26193,      kl weight: 0.56, l2 weight: 0.56\n",
      "Epoch:24, step:1150 (TRAIN, VALID): total: 20807.76, 20787.25      recon: 20778.07, 20759.48,     kl: 47.99, 44.04,     l2: 4.25891,      kl weight: 0.57, l2 weight: 0.57\n",
      "Epoch:25, step:1175 (TRAIN, VALID): total: 20804.97, 20784.84      recon: 20776.99, 20757.81,     kl: 43.91, 41.77,     l2: 4.24909,      kl weight: 0.59, l2 weight: 0.59\n",
      "Epoch:26, step:1200 (TRAIN, VALID): total: 20811.46, 20789.21      recon: 20780.42, 20761.80,     kl: 48.04, 41.44,     l2: 4.24493,      kl weight: 0.60, l2 weight: 0.60\n",
      "Epoch:27, step:1225 (TRAIN, VALID): total: 20809.92, 20798.06      recon: 20779.39, 20766.97,     kl: 46.14, 46.53,     l2: 4.24549,      kl weight: 0.61, l2 weight: 0.61\n",
      "Epoch:28, step:1250 (TRAIN, VALID): total: 20809.78, 20792.35      recon: 20779.10, 20764.87,     kl: 45.35, 39.73,     l2: 4.24379,      kl weight: 0.62, l2 weight: 0.62\n",
      "Epoch:29, step:1275 (TRAIN, VALID): total: 20806.96, 20783.97      recon: 20776.49, 20757.57,     kl: 44.06, 37.17,     l2: 4.23935,      kl weight: 0.64, l2 weight: 0.64\n",
      "Epoch:30, step:1300 (TRAIN, VALID): total: 20804.00, 20791.84      recon: 20775.87, 20761.93,     kl: 39.47, 41.78,     l2: 4.22527,      kl weight: 0.65, l2 weight: 0.65\n",
      "Epoch:31, step:1325 (TRAIN, VALID): total: 20803.78, 20791.54      recon: 20775.48, 20765.74,     kl: 38.92, 34.74,     l2: 4.21764,      kl weight: 0.66, l2 weight: 0.66\n",
      "Epoch:32, step:1350 (TRAIN, VALID): total: 20807.23, 20797.81      recon: 20777.81, 20766.32,     kl: 39.81, 42.43,     l2: 4.21410,      kl weight: 0.67, l2 weight: 0.67\n",
      "Epoch:33, step:1375 (TRAIN, VALID): total: 20802.80, 20783.40      recon: 20774.88, 20756.49,     kl: 36.79, 34.95,     l2: 4.20745,      kl weight: 0.69, l2 weight: 0.69\n",
      "Epoch:34, step:1400 (TRAIN, VALID): total: 20805.96, 20786.20      recon: 20775.97, 20758.62,     kl: 39.04, 35.21,     l2: 4.19989,      kl weight: 0.70, l2 weight: 0.70\n",
      "Epoch:35, step:1425 (TRAIN, VALID): total: 20805.20, 20791.70      recon: 20775.61, 20763.03,     kl: 37.72, 36.04,     l2: 4.19699,      kl weight: 0.71, l2 weight: 0.71\n",
      "Epoch:36, step:1450 (TRAIN, VALID): total: 20803.30, 20784.01      recon: 20774.59, 20754.54,     kl: 35.78, 36.46,     l2: 4.19050,      kl weight: 0.72, l2 weight: 0.72\n",
      "Epoch:37, step:1475 (TRAIN, VALID): total: 20801.37, 20783.13      recon: 20771.69, 20757.19,     kl: 36.42, 30.99,     l2: 4.18239,      kl weight: 0.74, l2 weight: 0.74\n",
      "Epoch:38, step:1500 (TRAIN, VALID): total: 20804.01, 20791.08      recon: 20774.33, 20758.07,     kl: 35.72, 39.84,     l2: 4.17921,      kl weight: 0.75, l2 weight: 0.75\n",
      "Epoch:39, step:1525 (TRAIN, VALID): total: 20800.06, 20782.14      recon: 20770.00, 20754.01,     kl: 35.59, 32.72,     l2: 4.17510,      kl weight: 0.76, l2 weight: 0.76\n",
      "Epoch:40, step:1550 (TRAIN, VALID): total: 20799.02, 20779.07      recon: 20770.98, 20751.15,     kl: 32.32, 31.86,     l2: 4.16474,      kl weight: 0.77, l2 weight: 0.77\n",
      "Epoch:41, step:1575 (TRAIN, VALID): total: 20800.14, 20783.76      recon: 20770.99, 20756.15,     kl: 33.16, 30.91,     l2: 4.15526,      kl weight: 0.79, l2 weight: 0.79\n",
      "Epoch:42, step:1600 (TRAIN, VALID): total: 20801.58, 20784.44      recon: 20770.48, 20751.18,     kl: 35.03, 37.44,     l2: 4.14804,      kl weight: 0.80, l2 weight: 0.80\n",
      "Epoch:43, step:1625 (TRAIN, VALID): total: 20801.71, 20783.22      recon: 20770.82, 20752.47,     kl: 34.18, 33.71,     l2: 4.13831,      kl weight: 0.81, l2 weight: 0.81\n",
      "Epoch:44, step:1650 (TRAIN, VALID): total: 20801.81, 20782.50      recon: 20769.38, 20752.89,     kl: 35.50, 31.76,     l2: 4.13171,      kl weight: 0.82, l2 weight: 0.82\n",
      "Epoch:45, step:1675 (TRAIN, VALID): total: 20804.56, 20783.04      recon: 20771.79, 20752.09,     kl: 35.30, 32.83,     l2: 4.12030,      kl weight: 0.84, l2 weight: 0.84\n",
      "     Decreasing learning rate to 0.009025.\n",
      "Epoch:46, step:1700 (TRAIN, VALID): total: 20796.65, 20778.95      recon: 20767.17, 20750.93,     kl: 30.84, 28.85,     l2: 4.12115,      kl weight: 0.85, l2 weight: 0.85\n",
      "Epoch:47, step:1725 (TRAIN, VALID): total: 20795.02, 20775.67      recon: 20765.96, 20746.86,     kl: 29.83, 29.30,     l2: 4.10873,      kl weight: 0.86, l2 weight: 0.86\n",
      "Epoch:48, step:1750 (TRAIN, VALID): total: 20793.42, 20779.56      recon: 20764.24, 20751.21,     kl: 29.49, 28.31,     l2: 4.08782,      kl weight: 0.87, l2 weight: 0.87\n",
      "Epoch:49, step:1775 (TRAIN, VALID): total: 20794.88, 20785.80      recon: 20764.67, 20757.07,     kl: 30.21, 28.31,     l2: 4.06581,      kl weight: 0.89, l2 weight: 0.89\n",
      "Epoch:50, step:1800 (TRAIN, VALID): total: 20799.89, 20784.50      recon: 20768.73, 20751.60,     kl: 30.81, 32.51,     l2: 4.05130,      kl weight: 0.90, l2 weight: 0.90\n",
      "Epoch:51, step:1825 (TRAIN, VALID): total: 20797.65, 20776.91      recon: 20766.27, 20746.86,     kl: 30.60, 28.88,     l2: 4.04956,      kl weight: 0.91, l2 weight: 0.91\n",
      "Epoch:52, step:1850 (TRAIN, VALID): total: 20793.98, 20782.42      recon: 20763.13, 20751.81,     kl: 29.55, 29.05,     l2: 4.03789,      kl weight: 0.92, l2 weight: 0.92\n",
      "Epoch:53, step:1875 (TRAIN, VALID): total: 20796.19, 20779.77      recon: 20764.18, 20749.11,     kl: 30.35, 28.69,     l2: 4.01877,      kl weight: 0.94, l2 weight: 0.94\n",
      "Epoch:54, step:1900 (TRAIN, VALID): total: 20795.27, 20779.66      recon: 20763.80, 20748.78,     kl: 29.35, 28.50,     l2: 4.00598,      kl weight: 0.95, l2 weight: 0.95\n",
      "Epoch:55, step:1925 (TRAIN, VALID): total: 20796.53, 20779.40      recon: 20765.65, 20748.25,     kl: 28.29, 28.37,     l2: 3.99700,      kl weight: 0.96, l2 weight: 0.96\n",
      "Epoch:56, step:1950 (TRAIN, VALID): total: 20790.86, 20774.94      recon: 20760.98, 20746.68,     kl: 26.86, 25.01,     l2: 3.98243,      kl weight: 0.97, l2 weight: 0.97\n",
      "Epoch:57, step:1975 (TRAIN, VALID): total: 20792.04, 20777.32      recon: 20761.71, 20748.38,     kl: 26.96, 25.34,     l2: 3.96048,      kl weight: 0.99, l2 weight: 0.99\n",
      "Epoch:58, step:2000 (TRAIN, VALID): total: 20792.51, 20777.23      recon: 20761.22, 20746.35,     kl: 27.55, 26.95,     l2: 3.93189,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:59, step:2025 (TRAIN, VALID): total: 20792.88, 20778.59      recon: 20761.71, 20749.40,     kl: 27.25, 25.28,     l2: 3.91682,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:60, step:2050 (TRAIN, VALID): total: 20791.00, 20778.76      recon: 20760.89, 20747.66,     kl: 26.20, 27.20,     l2: 3.90359,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:61, step:2075 (TRAIN, VALID): total: 20790.25, 20771.46      recon: 20759.33, 20744.34,     kl: 27.02, 23.23,     l2: 3.88997,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:62, step:2100 (TRAIN, VALID): total: 20793.99, 20782.84      recon: 20762.72, 20753.17,     kl: 27.39, 25.80,     l2: 3.87217,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.008574.\n",
      "Epoch:63, step:2125 (TRAIN, VALID): total: 20790.13, 20775.57      recon: 20758.97, 20747.45,     kl: 27.30, 24.26,     l2: 3.86111,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:64, step:2150 (TRAIN, VALID): total: 20788.12, 20775.20      recon: 20758.07, 20745.15,     kl: 26.20, 26.21,     l2: 3.84457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:65, step:2175 (TRAIN, VALID): total: 20787.45, 20768.12      recon: 20757.06, 20741.58,     kl: 26.56, 22.71,     l2: 3.83071,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:66, step:2200 (TRAIN, VALID): total: 20786.98, 20782.02      recon: 20756.85, 20748.32,     kl: 26.31, 29.89,     l2: 3.81272,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:67, step:2225 (TRAIN, VALID): total: 20786.79, 20772.61      recon: 20756.71, 20743.29,     kl: 26.27, 25.52,     l2: 3.79758,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:68, step:2250 (TRAIN, VALID): total: 20787.44, 20766.45      recon: 20757.08, 20738.57,     kl: 26.56, 24.09,     l2: 3.79101,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:69, step:2275 (TRAIN, VALID): total: 20784.57, 20767.17      recon: 20754.74, 20738.67,     kl: 26.04, 24.72,     l2: 3.77636,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:70, step:2300 (TRAIN, VALID): total: 20785.99, 20771.02      recon: 20755.16, 20743.04,     kl: 27.06, 24.22,     l2: 3.75954,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:71, step:2325 (TRAIN, VALID): total: 20787.76, 20770.63      recon: 20756.60, 20742.38,     kl: 27.41, 24.50,     l2: 3.75099,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.008145.\n",
      "Epoch:72, step:2350 (TRAIN, VALID): total: 20784.95, 20772.62      recon: 20755.23, 20742.81,     kl: 25.98, 26.07,     l2: 3.74199,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:73, step:2375 (TRAIN, VALID): total: 20788.00, 20771.71      recon: 20757.17, 20743.41,     kl: 27.10, 24.56,     l2: 3.73762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:74, step:2400 (TRAIN, VALID): total: 20783.04, 20765.41      recon: 20753.42, 20737.36,     kl: 25.89, 24.31,     l2: 3.72808,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:75, step:2425 (TRAIN, VALID): total: 20783.51, 20766.67      recon: 20753.31, 20738.61,     kl: 26.48, 24.34,     l2: 3.72018,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:76, step:2450 (TRAIN, VALID): total: 20782.64, 20768.18      recon: 20752.78, 20738.97,     kl: 26.15, 25.51,     l2: 3.70641,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:77, step:2475 (TRAIN, VALID): total: 20780.29, 20764.36      recon: 20751.35, 20736.31,     kl: 25.25, 24.36,     l2: 3.68718,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:78, step:2500 (TRAIN, VALID): total: 20781.01, 20772.60      recon: 20751.71, 20741.68,     kl: 25.62, 27.26,     l2: 3.67129,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:79, step:2525 (TRAIN, VALID): total: 20782.01, 20773.48      recon: 20752.35, 20743.63,     kl: 26.00, 26.19,     l2: 3.66243,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:80, step:2550 (TRAIN, VALID): total: 20780.34, 20765.36      recon: 20751.47, 20737.43,     kl: 25.21, 24.28,     l2: 3.65264,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:81, step:2575 (TRAIN, VALID): total: 20781.46, 20765.59      recon: 20752.09, 20736.83,     kl: 25.72, 25.12,     l2: 3.64226,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:82, step:2600 (TRAIN, VALID): total: 20779.19, 20765.21      recon: 20750.50, 20738.63,     kl: 25.05, 22.96,     l2: 3.63146,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:83, step:2625 (TRAIN, VALID): total: 20778.33, 20762.88      recon: 20749.01, 20733.83,     kl: 25.69, 25.43,     l2: 3.62216,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:84, step:2650 (TRAIN, VALID): total: 20777.21, 20762.87      recon: 20748.51, 20734.40,     kl: 25.08, 24.86,     l2: 3.60918,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:85, step:2675 (TRAIN, VALID): total: 20783.48, 20763.01      recon: 20753.63, 20734.67,     kl: 26.25, 24.73,     l2: 3.60671,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007738.\n",
      "Epoch:86, step:2700 (TRAIN, VALID): total: 20778.70, 20764.89      recon: 20750.14, 20736.95,     kl: 24.96, 24.34,     l2: 3.60509,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:87, step:2725 (TRAIN, VALID): total: 20777.78, 20762.29      recon: 20749.06, 20734.89,     kl: 25.11, 23.80,     l2: 3.59682,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:88, step:2750 (TRAIN, VALID): total: 20776.55, 20766.00      recon: 20747.96, 20738.02,     kl: 24.99, 24.39,     l2: 3.58908,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:89, step:2775 (TRAIN, VALID): total: 20779.13, 20768.46      recon: 20749.50, 20740.98,     kl: 26.04, 23.90,     l2: 3.58227,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:90, step:2800 (TRAIN, VALID): total: 20777.66, 20761.65      recon: 20748.63, 20733.52,     kl: 25.45, 24.55,     l2: 3.58051,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:91, step:2825 (TRAIN, VALID): total: 20775.98, 20763.64      recon: 20747.21, 20735.74,     kl: 25.19, 24.32,     l2: 3.57525,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:92, step:2850 (TRAIN, VALID): total: 20775.53, 20762.10      recon: 20746.47, 20732.36,     kl: 25.50, 26.17,     l2: 3.56415,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:93, step:2875 (TRAIN, VALID): total: 20777.64, 20763.77      recon: 20748.17, 20735.97,     kl: 25.90, 24.24,     l2: 3.56068,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:94, step:2900 (TRAIN, VALID): total: 20775.00, 20766.05      recon: 20745.96, 20736.78,     kl: 25.48, 25.71,     l2: 3.55385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:95, step:2925 (TRAIN, VALID): total: 20775.44, 20762.81      recon: 20746.14, 20733.45,     kl: 25.75, 25.82,     l2: 3.54938,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:96, step:2950 (TRAIN, VALID): total: 20775.43, 20762.70      recon: 20746.56, 20733.55,     kl: 25.32, 25.61,     l2: 3.53770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:97, step:2975 (TRAIN, VALID): total: 20776.06, 20759.72      recon: 20747.42, 20732.77,     kl: 25.11, 23.41,     l2: 3.53899,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:98, step:3000 (TRAIN, VALID): total: 20772.69, 20763.56      recon: 20744.30, 20735.84,     kl: 24.86, 24.19,     l2: 3.53088,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:99, step:3025 (TRAIN, VALID): total: 20773.69, 20760.89      recon: 20744.94, 20732.75,     kl: 25.23, 24.62,     l2: 3.51472,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:100, step:3050 (TRAIN, VALID): total: 20774.79, 20759.63      recon: 20745.09, 20731.38,     kl: 26.19, 24.74,     l2: 3.51387,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:101, step:3075 (TRAIN, VALID): total: 20774.21, 20765.93      recon: 20744.50, 20735.91,     kl: 26.20, 26.51,     l2: 3.51244,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:102, step:3100 (TRAIN, VALID): total: 20773.97, 20758.67      recon: 20745.02, 20731.83,     kl: 25.43, 23.33,     l2: 3.50882,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:103, step:3125 (TRAIN, VALID): total: 20772.42, 20760.50      recon: 20744.09, 20733.89,     kl: 24.82, 23.10,     l2: 3.51443,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:104, step:3150 (TRAIN, VALID): total: 20771.67, 20756.40      recon: 20743.62, 20730.28,     kl: 24.53, 22.60,     l2: 3.50945,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:105, step:3175 (TRAIN, VALID): total: 20770.53, 20756.82      recon: 20742.37, 20729.39,     kl: 24.65, 23.93,     l2: 3.50362,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:106, step:3200 (TRAIN, VALID): total: 20770.61, 20760.08      recon: 20742.08, 20731.05,     kl: 25.03, 25.53,     l2: 3.49387,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:107, step:3225 (TRAIN, VALID): total: 20771.75, 20763.34      recon: 20743.02, 20735.11,     kl: 25.25, 24.74,     l2: 3.48725,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:108, step:3250 (TRAIN, VALID): total: 20770.88, 20760.63      recon: 20742.53, 20731.54,     kl: 24.86, 25.61,     l2: 3.48105,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:109, step:3275 (TRAIN, VALID): total: 20771.32, 20763.41      recon: 20742.62, 20733.31,     kl: 25.22, 26.62,     l2: 3.48104,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:110, step:3300 (TRAIN, VALID): total: 20771.43, 20760.50      recon: 20742.32, 20732.21,     kl: 25.63, 24.81,     l2: 3.47617,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:111, step:3325 (TRAIN, VALID): total: 20770.54, 20762.19      recon: 20741.68, 20735.25,     kl: 25.39, 23.46,     l2: 3.47580,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:112, step:3350 (TRAIN, VALID): total: 20769.81, 20757.65      recon: 20741.58, 20731.55,     kl: 24.75, 22.62,     l2: 3.47965,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:113, step:3375 (TRAIN, VALID): total: 20769.13, 20759.92      recon: 20741.15, 20732.53,     kl: 24.50, 23.90,     l2: 3.48911,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:114, step:3400 (TRAIN, VALID): total: 20769.68, 20760.47      recon: 20741.44, 20733.29,     kl: 24.75, 23.70,     l2: 3.48560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:115, step:3425 (TRAIN, VALID): total: 20768.12, 20758.40      recon: 20740.18, 20729.42,     kl: 24.45, 25.50,     l2: 3.48408,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:116, step:3450 (TRAIN, VALID): total: 20769.42, 20758.25      recon: 20740.34, 20730.11,     kl: 25.60, 24.66,     l2: 3.47624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:117, step:3475 (TRAIN, VALID): total: 20770.40, 20759.58      recon: 20741.34, 20730.27,     kl: 25.58, 25.83,     l2: 3.47810,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:118, step:3500 (TRAIN, VALID): total: 20768.91, 20758.50      recon: 20740.60, 20729.80,     kl: 24.83, 25.22,     l2: 3.47682,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:119, step:3525 (TRAIN, VALID): total: 20768.87, 20757.36      recon: 20740.29, 20730.96,     kl: 25.10, 22.92,     l2: 3.47967,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:120, step:3550 (TRAIN, VALID): total: 20766.99, 20761.94      recon: 20739.00, 20734.25,     kl: 24.51, 24.21,     l2: 3.47790,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:121, step:3575 (TRAIN, VALID): total: 20770.43, 20761.67      recon: 20741.95, 20733.78,     kl: 25.00, 24.41,     l2: 3.48410,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.007351.\n",
      "Epoch:122, step:3600 (TRAIN, VALID): total: 20768.23, 20757.80      recon: 20739.66, 20730.15,     kl: 25.08, 24.16,     l2: 3.48524,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:123, step:3625 (TRAIN, VALID): total: 20767.45, 20756.34      recon: 20739.00, 20728.92,     kl: 24.97, 23.93,     l2: 3.48915,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:124, step:3650 (TRAIN, VALID): total: 20768.40, 20757.70      recon: 20739.61, 20729.87,     kl: 25.30, 24.34,     l2: 3.48961,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:125, step:3675 (TRAIN, VALID): total: 20767.21, 20757.82      recon: 20738.93, 20728.16,     kl: 24.78, 26.18,     l2: 3.48844,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:126, step:3700 (TRAIN, VALID): total: 20767.53, 20754.34      recon: 20739.26, 20727.46,     kl: 24.78, 23.39,     l2: 3.48983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:127, step:3725 (TRAIN, VALID): total: 20766.71, 20756.87      recon: 20738.70, 20729.38,     kl: 24.52, 24.00,     l2: 3.49349,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:128, step:3750 (TRAIN, VALID): total: 20767.54, 20754.25      recon: 20739.13, 20726.37,     kl: 24.91, 24.38,     l2: 3.49983,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:129, step:3775 (TRAIN, VALID): total: 20765.83, 20757.65      recon: 20737.61, 20729.15,     kl: 24.72, 25.00,     l2: 3.50463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:130, step:3800 (TRAIN, VALID): total: 20764.48, 20756.44      recon: 20736.46, 20729.67,     kl: 24.52, 23.26,     l2: 3.50231,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:131, step:3825 (TRAIN, VALID): total: 20766.11, 20763.40      recon: 20737.90, 20734.10,     kl: 24.70, 25.79,     l2: 3.50275,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:132, step:3850 (TRAIN, VALID): total: 20766.09, 20757.18      recon: 20737.96, 20729.86,     kl: 24.63, 23.82,     l2: 3.50197,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:133, step:3875 (TRAIN, VALID): total: 20766.32, 20758.24      recon: 20737.56, 20730.83,     kl: 25.26, 23.90,     l2: 3.50859,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:134, step:3900 (TRAIN, VALID): total: 20766.53, 20760.78      recon: 20737.84, 20731.00,     kl: 25.18, 26.27,     l2: 3.50925,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:135, step:3925 (TRAIN, VALID): total: 20765.81, 20758.68      recon: 20737.33, 20730.35,     kl: 24.97, 24.81,     l2: 3.51265,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:136, step:3950 (TRAIN, VALID): total: 20766.09, 20754.98      recon: 20737.70, 20726.88,     kl: 24.87, 24.59,     l2: 3.51806,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:137, step:3975 (TRAIN, VALID): total: 20764.93, 20756.02      recon: 20736.51, 20728.18,     kl: 24.90, 24.32,     l2: 3.52098,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:138, step:4000 (TRAIN, VALID): total: 20765.03, 20756.97      recon: 20736.77, 20730.74,     kl: 24.74, 22.70,     l2: 3.52702,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:139, step:4025 (TRAIN, VALID): total: 20764.74, 20755.67      recon: 20736.25, 20728.92,     kl: 24.96, 23.22,     l2: 3.52748,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:140, step:4050 (TRAIN, VALID): total: 20763.99, 20755.42      recon: 20736.00, 20727.39,     kl: 24.46, 24.50,     l2: 3.52942,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:141, step:4075 (TRAIN, VALID): total: 20764.69, 20752.17      recon: 20736.12, 20724.20,     kl: 25.04, 24.44,     l2: 3.53153,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:142, step:4100 (TRAIN, VALID): total: 20764.51, 20755.17      recon: 20736.07, 20727.26,     kl: 24.91, 24.38,     l2: 3.53342,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:143, step:4125 (TRAIN, VALID): total: 20763.69, 20754.71      recon: 20735.16, 20726.67,     kl: 25.00, 24.51,     l2: 3.53592,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:144, step:4150 (TRAIN, VALID): total: 20763.22, 20755.06      recon: 20734.91, 20727.52,     kl: 24.77, 24.00,     l2: 3.54123,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:145, step:4175 (TRAIN, VALID): total: 20764.25, 20755.34      recon: 20735.80, 20727.75,     kl: 24.91, 24.06,     l2: 3.54349,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:146, step:4200 (TRAIN, VALID): total: 20764.08, 20755.06      recon: 20735.74, 20726.96,     kl: 24.80, 24.56,     l2: 3.54288,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:147, step:4225 (TRAIN, VALID): total: 20762.19, 20755.59      recon: 20733.83, 20726.77,     kl: 24.81, 25.27,     l2: 3.54773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:148, step:4250 (TRAIN, VALID): total: 20763.67, 20755.30      recon: 20735.01, 20727.76,     kl: 25.12, 23.99,     l2: 3.55031,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:149, step:4275 (TRAIN, VALID): total: 20763.41, 20755.32      recon: 20734.88, 20728.13,     kl: 24.98, 23.63,     l2: 3.55217,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:150, step:4300 (TRAIN, VALID): total: 20765.42, 20753.09      recon: 20736.85, 20725.00,     kl: 25.02, 24.53,     l2: 3.56351,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006983.\n",
      "Epoch:151, step:4325 (TRAIN, VALID): total: 20762.42, 20752.71      recon: 20734.10, 20723.93,     kl: 24.76, 25.21,     l2: 3.56617,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:152, step:4350 (TRAIN, VALID): total: 20762.71, 20750.67      recon: 20734.10, 20723.96,     kl: 25.05, 23.14,     l2: 3.56920,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:153, step:4375 (TRAIN, VALID): total: 20760.37, 20751.29      recon: 20732.48, 20724.66,     kl: 24.32, 23.06,     l2: 3.57155,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:154, step:4400 (TRAIN, VALID): total: 20760.14, 20751.87      recon: 20732.56, 20725.21,     kl: 24.00, 23.10,     l2: 3.56717,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:155, step:4425 (TRAIN, VALID): total: 20761.76, 20754.86      recon: 20734.01, 20726.85,     kl: 24.18, 24.45,     l2: 3.57226,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:156, step:4450 (TRAIN, VALID): total: 20761.30, 20753.86      recon: 20733.34, 20726.51,     kl: 24.39, 23.78,     l2: 3.57428,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:157, step:4475 (TRAIN, VALID): total: 20760.20, 20752.13      recon: 20732.43, 20724.01,     kl: 24.19, 24.53,     l2: 3.57984,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:158, step:4500 (TRAIN, VALID): total: 20760.26, 20754.65      recon: 20732.24, 20725.73,     kl: 24.44, 25.34,     l2: 3.57934,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:159, step:4525 (TRAIN, VALID): total: 20760.43, 20752.16      recon: 20732.24, 20725.37,     kl: 24.62, 23.21,     l2: 3.58328,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:160, step:4550 (TRAIN, VALID): total: 20760.77, 20754.16      recon: 20732.95, 20727.74,     kl: 24.24, 22.83,     l2: 3.58985,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:161, step:4575 (TRAIN, VALID): total: 20761.17, 20750.76      recon: 20732.77, 20723.62,     kl: 24.81, 23.55,     l2: 3.59309,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:162, step:4600 (TRAIN, VALID): total: 20758.67, 20749.29      recon: 20730.75, 20722.27,     kl: 24.32, 23.42,     l2: 3.60037,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:163, step:4625 (TRAIN, VALID): total: 20758.46, 20751.29      recon: 20730.97, 20724.00,     kl: 23.89, 23.70,     l2: 3.59858,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:164, step:4650 (TRAIN, VALID): total: 20760.12, 20754.21      recon: 20732.05, 20726.46,     kl: 24.47, 24.14,     l2: 3.60505,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:165, step:4675 (TRAIN, VALID): total: 20760.62, 20749.52      recon: 20732.37, 20721.72,     kl: 24.65, 24.17,     l2: 3.61568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:166, step:4700 (TRAIN, VALID): total: 20758.94, 20752.88      recon: 20731.12, 20726.28,     kl: 24.20, 22.99,     l2: 3.61655,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:167, step:4725 (TRAIN, VALID): total: 20760.61, 20753.00      recon: 20732.44, 20725.71,     kl: 24.55, 23.66,     l2: 3.62167,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:168, step:4750 (TRAIN, VALID): total: 20758.27, 20750.24      recon: 20730.12, 20722.76,     kl: 24.53, 23.86,     l2: 3.62467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:169, step:4775 (TRAIN, VALID): total: 20758.28, 20750.57      recon: 20730.42, 20724.43,     kl: 24.24, 22.52,     l2: 3.62424,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:170, step:4800 (TRAIN, VALID): total: 20759.86, 20750.92      recon: 20731.57, 20723.39,     kl: 24.66, 23.90,     l2: 3.62947,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:171, step:4825 (TRAIN, VALID): total: 20759.09, 20750.25      recon: 20730.65, 20722.28,     kl: 24.81, 24.34,     l2: 3.63050,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:172, step:4850 (TRAIN, VALID): total: 20758.37, 20747.40      recon: 20730.36, 20720.71,     kl: 24.37, 23.05,     l2: 3.64132,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:173, step:4875 (TRAIN, VALID): total: 20758.48, 20749.04      recon: 20730.43, 20722.68,     kl: 24.41, 22.72,     l2: 3.65080,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:174, step:4900 (TRAIN, VALID): total: 20758.59, 20753.34      recon: 20730.45, 20725.15,     kl: 24.49, 24.53,     l2: 3.65945,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:175, step:4925 (TRAIN, VALID): total: 20758.12, 20750.37      recon: 20729.96, 20723.14,     kl: 24.50, 23.57,     l2: 3.66745,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:176, step:4950 (TRAIN, VALID): total: 20757.95, 20748.68      recon: 20730.02, 20722.53,     kl: 24.26, 22.48,     l2: 3.67170,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:177, step:4975 (TRAIN, VALID): total: 20758.33, 20750.59      recon: 20730.29, 20723.55,     kl: 24.37, 23.36,     l2: 3.67907,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:178, step:5000 (TRAIN, VALID): total: 20757.59, 20749.50      recon: 20729.46, 20721.24,     kl: 24.45, 24.57,     l2: 3.68881,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:179, step:5025 (TRAIN, VALID): total: 20757.01, 20748.16      recon: 20728.95, 20721.14,     kl: 24.36, 23.33,     l2: 3.69149,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:180, step:5050 (TRAIN, VALID): total: 20756.14, 20749.58      recon: 20728.43, 20722.08,     kl: 24.01, 23.81,     l2: 3.69415,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:181, step:5075 (TRAIN, VALID): total: 20756.81, 20748.67      recon: 20729.20, 20721.06,     kl: 23.91, 23.91,     l2: 3.70159,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:182, step:5100 (TRAIN, VALID): total: 20756.13, 20750.51      recon: 20728.29, 20724.23,     kl: 24.14, 22.56,     l2: 3.70959,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:183, step:5125 (TRAIN, VALID): total: 20756.81, 20748.64      recon: 20729.44, 20721.82,     kl: 23.66, 23.10,     l2: 3.71864,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:184, step:5150 (TRAIN, VALID): total: 20757.90, 20747.92      recon: 20729.84, 20721.95,     kl: 24.34, 22.24,     l2: 3.72387,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006634.\n",
      "Epoch:185, step:5175 (TRAIN, VALID): total: 20755.58, 20747.04      recon: 20727.91, 20719.25,     kl: 23.95, 24.06,     l2: 3.72758,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:186, step:5200 (TRAIN, VALID): total: 20755.50, 20750.32      recon: 20727.83, 20722.64,     kl: 23.94, 23.95,     l2: 3.72806,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:187, step:5225 (TRAIN, VALID): total: 20756.93, 20748.65      recon: 20728.75, 20720.65,     kl: 24.45, 24.28,     l2: 3.72733,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:188, step:5250 (TRAIN, VALID): total: 20754.88, 20746.88      recon: 20727.36, 20719.49,     kl: 23.79, 23.65,     l2: 3.73138,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:189, step:5275 (TRAIN, VALID): total: 20755.11, 20751.46      recon: 20727.60, 20723.50,     kl: 23.78, 24.22,     l2: 3.73718,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:190, step:5300 (TRAIN, VALID): total: 20755.73, 20747.56      recon: 20728.13, 20720.16,     kl: 23.86, 23.65,     l2: 3.74750,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:191, step:5325 (TRAIN, VALID): total: 20755.37, 20751.61      recon: 20727.56, 20724.41,     kl: 24.06, 23.44,     l2: 3.75465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:192, step:5350 (TRAIN, VALID): total: 20758.31, 20748.88      recon: 20729.74, 20721.70,     kl: 24.82, 23.41,     l2: 3.76555,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.006302.\n",
      "Epoch:193, step:5375 (TRAIN, VALID): total: 20753.78, 20747.29      recon: 20726.60, 20721.37,     kl: 23.41, 22.15,     l2: 3.77234,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:194, step:5400 (TRAIN, VALID): total: 20754.37, 20746.72      recon: 20726.65, 20719.30,     kl: 23.95, 23.64,     l2: 3.77543,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:195, step:5425 (TRAIN, VALID): total: 20754.25, 20749.60      recon: 20726.62, 20722.95,     kl: 23.86, 22.87,     l2: 3.77458,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:196, step:5450 (TRAIN, VALID): total: 20753.94, 20747.38      recon: 20725.93, 20720.40,     kl: 24.23, 23.20,     l2: 3.78225,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:197, step:5475 (TRAIN, VALID): total: 20753.46, 20745.72      recon: 20725.65, 20717.91,     kl: 24.02, 24.03,     l2: 3.78418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:198, step:5500 (TRAIN, VALID): total: 20752.89, 20749.31      recon: 20725.75, 20722.40,     kl: 23.36, 23.12,     l2: 3.78927,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:199, step:5525 (TRAIN, VALID): total: 20753.39, 20747.78      recon: 20725.39, 20720.32,     kl: 24.21, 23.66,     l2: 3.79052,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:200, step:5550 (TRAIN, VALID): total: 20753.03, 20747.49      recon: 20725.54, 20720.39,     kl: 23.70, 23.30,     l2: 3.79651,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:201, step:5575 (TRAIN, VALID): total: 20753.88, 20747.91      recon: 20726.13, 20721.00,     kl: 23.95, 23.10,     l2: 3.80688,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:202, step:5600 (TRAIN, VALID): total: 20753.54, 20749.80      recon: 20725.94, 20722.30,     kl: 23.79, 23.69,     l2: 3.81546,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:203, step:5625 (TRAIN, VALID): total: 20754.15, 20747.66      recon: 20725.77, 20720.09,     kl: 24.56, 23.74,     l2: 3.82093,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005987.\n",
      "Epoch:204, step:5650 (TRAIN, VALID): total: 20751.46, 20746.33      recon: 20724.07, 20719.68,     kl: 23.56, 22.83,     l2: 3.82520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:205, step:5675 (TRAIN, VALID): total: 20751.81, 20745.92      recon: 20724.52, 20719.27,     kl: 23.46, 22.82,     l2: 3.83062,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:206, step:5700 (TRAIN, VALID): total: 20751.26, 20747.61      recon: 20724.19, 20720.47,     kl: 23.25, 23.31,     l2: 3.82805,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:207, step:5725 (TRAIN, VALID): total: 20752.15, 20747.33      recon: 20724.65, 20719.92,     kl: 23.67, 23.57,     l2: 3.83563,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:208, step:5750 (TRAIN, VALID): total: 20752.05, 20745.79      recon: 20724.56, 20717.68,     kl: 23.65, 24.27,     l2: 3.84363,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:209, step:5775 (TRAIN, VALID): total: 20753.01, 20747.69      recon: 20725.18, 20718.73,     kl: 23.99, 25.10,     l2: 3.85029,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:210, step:5800 (TRAIN, VALID): total: 20751.25, 20747.85      recon: 20723.57, 20720.24,     kl: 23.82, 23.75,     l2: 3.85741,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:211, step:5825 (TRAIN, VALID): total: 20750.55, 20748.51      recon: 20723.29, 20722.24,     kl: 23.40, 22.41,     l2: 3.86261,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:212, step:5850 (TRAIN, VALID): total: 20750.69, 20745.08      recon: 20723.65, 20718.25,     kl: 23.18, 22.96,     l2: 3.87138,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:213, step:5875 (TRAIN, VALID): total: 20750.72, 20745.62      recon: 20723.29, 20718.06,     kl: 23.56, 23.68,     l2: 3.87037,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:214, step:5900 (TRAIN, VALID): total: 20750.27, 20744.76      recon: 20723.03, 20718.55,     kl: 23.37, 22.34,     l2: 3.87584,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:215, step:5925 (TRAIN, VALID): total: 20751.06, 20745.12      recon: 20723.64, 20718.01,     kl: 23.54, 23.23,     l2: 3.88264,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:216, step:5950 (TRAIN, VALID): total: 20750.57, 20745.07      recon: 20723.43, 20719.01,     kl: 23.26, 22.17,     l2: 3.89010,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:217, step:5975 (TRAIN, VALID): total: 20752.07, 20746.77      recon: 20724.05, 20719.70,     kl: 24.12, 23.18,     l2: 3.89844,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005688.\n",
      "Epoch:218, step:6000 (TRAIN, VALID): total: 20750.27, 20744.22      recon: 20722.89, 20717.30,     kl: 23.48, 23.02,     l2: 3.90449,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:219, step:6025 (TRAIN, VALID): total: 20750.14, 20746.14      recon: 20722.93, 20719.07,     kl: 23.30, 23.16,     l2: 3.90974,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:220, step:6050 (TRAIN, VALID): total: 20750.32, 20746.33      recon: 20723.02, 20718.56,     kl: 23.38, 23.86,     l2: 3.91390,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:221, step:6075 (TRAIN, VALID): total: 20749.98, 20745.94      recon: 20722.49, 20718.78,     kl: 23.57, 23.24,     l2: 3.91814,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:222, step:6100 (TRAIN, VALID): total: 20749.73, 20743.80      recon: 20722.47, 20717.74,     kl: 23.34, 22.14,     l2: 3.92354,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:223, step:6125 (TRAIN, VALID): total: 20748.78, 20742.94      recon: 20721.93, 20716.28,     kl: 22.92, 22.73,     l2: 3.92762,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:224, step:6150 (TRAIN, VALID): total: 20748.55, 20744.83      recon: 20721.58, 20719.16,     kl: 23.03, 21.74,     l2: 3.93135,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:225, step:6175 (TRAIN, VALID): total: 20748.95, 20745.05      recon: 20721.79, 20717.51,     kl: 23.23, 23.61,     l2: 3.93589,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:226, step:6200 (TRAIN, VALID): total: 20749.30, 20746.24      recon: 20722.06, 20718.62,     kl: 23.30, 23.68,     l2: 3.93793,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:227, step:6225 (TRAIN, VALID): total: 20748.67, 20744.44      recon: 20721.59, 20717.92,     kl: 23.14, 22.57,     l2: 3.94466,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:228, step:6250 (TRAIN, VALID): total: 20749.12, 20744.97      recon: 20722.01, 20718.91,     kl: 23.17, 22.10,     l2: 3.94956,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:229, step:6275 (TRAIN, VALID): total: 20748.75, 20745.35      recon: 20721.81, 20718.39,     kl: 22.98, 23.00,     l2: 3.95699,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:230, step:6300 (TRAIN, VALID): total: 20749.69, 20744.25      recon: 20721.85, 20717.92,     kl: 23.88, 22.38,     l2: 3.95905,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005404.\n",
      "Epoch:231, step:6325 (TRAIN, VALID): total: 20748.29, 20743.95      recon: 20721.38, 20717.34,     kl: 22.95, 22.64,     l2: 3.96448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:232, step:6350 (TRAIN, VALID): total: 20747.55, 20744.62      recon: 20720.35, 20718.27,     kl: 23.23, 22.38,     l2: 3.97205,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:233, step:6375 (TRAIN, VALID): total: 20747.74, 20744.12      recon: 20720.70, 20716.99,     kl: 23.07, 23.15,     l2: 3.97561,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:234, step:6400 (TRAIN, VALID): total: 20748.24, 20743.07      recon: 20721.25, 20717.08,     kl: 23.01, 22.01,     l2: 3.98260,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:235, step:6425 (TRAIN, VALID): total: 20747.66, 20742.55      recon: 20720.54, 20715.64,     kl: 23.13, 22.92,     l2: 3.98972,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:236, step:6450 (TRAIN, VALID): total: 20747.32, 20744.01      recon: 20720.20, 20717.08,     kl: 23.13, 22.94,     l2: 3.99312,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:237, step:6475 (TRAIN, VALID): total: 20747.65, 20744.57      recon: 20720.71, 20717.94,     kl: 22.94, 22.63,     l2: 3.99737,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:238, step:6500 (TRAIN, VALID): total: 20746.12, 20741.19      recon: 20719.18, 20715.19,     kl: 22.94, 21.99,     l2: 4.00383,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:239, step:6525 (TRAIN, VALID): total: 20747.02, 20743.83      recon: 20719.98, 20718.09,     kl: 23.03, 21.74,     l2: 4.00558,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:240, step:6550 (TRAIN, VALID): total: 20748.61, 20743.47      recon: 20721.37, 20716.45,     kl: 23.23, 23.01,     l2: 4.01525,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.005133.\n",
      "Epoch:241, step:6575 (TRAIN, VALID): total: 20747.60, 20742.86      recon: 20720.40, 20715.83,     kl: 23.18, 23.01,     l2: 4.01826,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:242, step:6600 (TRAIN, VALID): total: 20746.76, 20744.27      recon: 20719.80, 20717.47,     kl: 22.94, 22.77,     l2: 4.02168,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:243, step:6625 (TRAIN, VALID): total: 20746.45, 20744.05      recon: 20719.59, 20716.84,     kl: 22.83, 23.19,     l2: 4.02418,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:244, step:6650 (TRAIN, VALID): total: 20745.93, 20743.38      recon: 20719.01, 20716.52,     kl: 22.89, 22.83,     l2: 4.03265,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:245, step:6675 (TRAIN, VALID): total: 20746.63, 20744.52      recon: 20719.25, 20717.90,     kl: 23.35, 22.58,     l2: 4.04048,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:246, step:6700 (TRAIN, VALID): total: 20745.76, 20743.19      recon: 20718.99, 20716.53,     kl: 22.73, 22.61,     l2: 4.04368,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:247, step:6725 (TRAIN, VALID): total: 20746.52, 20747.45      recon: 20719.64, 20720.14,     kl: 22.83, 23.26,     l2: 4.04982,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:248, step:6750 (TRAIN, VALID): total: 20746.19, 20743.29      recon: 20719.10, 20715.78,     kl: 23.03, 23.45,     l2: 4.05771,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:249, step:6775 (TRAIN, VALID): total: 20747.79, 20743.66      recon: 20720.32, 20717.52,     kl: 23.41, 22.08,     l2: 4.06194,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004877.\n",
      "Epoch:250, step:6800 (TRAIN, VALID): total: 20746.96, 20743.65      recon: 20719.59, 20716.99,     kl: 23.31, 22.59,     l2: 4.06687,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:251, step:6825 (TRAIN, VALID): total: 20746.51, 20741.42      recon: 20719.40, 20715.70,     kl: 23.05, 21.65,     l2: 4.07358,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:252, step:6850 (TRAIN, VALID): total: 20745.41, 20740.86      recon: 20718.30, 20714.26,     kl: 23.04, 22.52,     l2: 4.08189,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:253, step:6875 (TRAIN, VALID): total: 20744.94, 20742.47      recon: 20718.08, 20714.24,     kl: 22.77, 24.15,     l2: 4.08511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:254, step:6900 (TRAIN, VALID): total: 20745.39, 20742.13      recon: 20718.40, 20715.35,     kl: 22.90, 22.69,     l2: 4.09245,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:255, step:6925 (TRAIN, VALID): total: 20745.51, 20742.70      recon: 20718.28, 20716.49,     kl: 23.14, 22.11,     l2: 4.09865,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:256, step:6950 (TRAIN, VALID): total: 20744.72, 20742.22      recon: 20717.89, 20715.84,     kl: 22.72, 22.28,     l2: 4.10422,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:257, step:6975 (TRAIN, VALID): total: 20745.07, 20742.41      recon: 20718.09, 20716.40,     kl: 22.87, 21.90,     l2: 4.10957,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:258, step:7000 (TRAIN, VALID): total: 20744.04, 20741.51      recon: 20717.46, 20715.65,     kl: 22.47, 21.74,     l2: 4.11695,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:259, step:7025 (TRAIN, VALID): total: 20744.89, 20743.93      recon: 20717.76, 20716.33,     kl: 23.00, 23.47,     l2: 4.11915,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:260, step:7050 (TRAIN, VALID): total: 20745.47, 20740.52      recon: 20718.43, 20714.19,     kl: 22.93, 22.21,     l2: 4.12179,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:261, step:7075 (TRAIN, VALID): total: 20744.32, 20741.55      recon: 20717.16, 20714.21,     kl: 23.04, 23.20,     l2: 4.13243,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:262, step:7100 (TRAIN, VALID): total: 20744.61, 20741.91      recon: 20717.68, 20715.11,     kl: 22.80, 22.67,     l2: 4.13433,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:263, step:7125 (TRAIN, VALID): total: 20743.51, 20740.37      recon: 20716.47, 20714.19,     kl: 22.91, 22.04,     l2: 4.14062,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:264, step:7150 (TRAIN, VALID): total: 20743.59, 20743.35      recon: 20716.83, 20716.95,     kl: 22.61, 22.26,     l2: 4.14429,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:265, step:7175 (TRAIN, VALID): total: 20743.92, 20742.39      recon: 20717.20, 20716.63,     kl: 22.57, 21.60,     l2: 4.15122,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:266, step:7200 (TRAIN, VALID): total: 20744.19, 20744.58      recon: 20717.28, 20716.83,     kl: 22.77, 23.59,     l2: 4.15513,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:267, step:7225 (TRAIN, VALID): total: 20744.95, 20741.50      recon: 20717.47, 20714.62,     kl: 23.32, 22.71,     l2: 4.16484,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004633.\n",
      "Epoch:268, step:7250 (TRAIN, VALID): total: 20743.13, 20742.37      recon: 20716.46, 20715.34,     kl: 22.51, 22.86,     l2: 4.17144,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:269, step:7275 (TRAIN, VALID): total: 20743.61, 20741.21      recon: 20716.59, 20714.61,     kl: 22.85, 22.42,     l2: 4.17492,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:270, step:7300 (TRAIN, VALID): total: 20742.91, 20739.75      recon: 20716.09, 20713.44,     kl: 22.64, 22.13,     l2: 4.17982,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:271, step:7325 (TRAIN, VALID): total: 20742.26, 20738.60      recon: 20715.69, 20713.41,     kl: 22.39, 21.00,     l2: 4.18337,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:272, step:7350 (TRAIN, VALID): total: 20742.71, 20741.93      recon: 20716.17, 20716.24,     kl: 22.36, 21.50,     l2: 4.18919,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:273, step:7375 (TRAIN, VALID): total: 20743.34, 20741.27      recon: 20716.44, 20715.26,     kl: 22.71, 21.81,     l2: 4.19456,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:274, step:7400 (TRAIN, VALID): total: 20742.74, 20740.68      recon: 20715.87, 20714.38,     kl: 22.68, 22.10,     l2: 4.19889,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:275, step:7425 (TRAIN, VALID): total: 20742.57, 20743.96      recon: 20715.66, 20717.79,     kl: 22.71, 21.97,     l2: 4.20297,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:276, step:7450 (TRAIN, VALID): total: 20741.91, 20739.36      recon: 20715.28, 20713.99,     kl: 22.43, 21.16,     l2: 4.20990,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:277, step:7475 (TRAIN, VALID): total: 20742.52, 20741.27      recon: 20715.88, 20714.50,     kl: 22.43, 22.55,     l2: 4.21242,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:278, step:7500 (TRAIN, VALID): total: 20742.53, 20741.24      recon: 20715.76, 20715.00,     kl: 22.55, 22.02,     l2: 4.21813,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:279, step:7525 (TRAIN, VALID): total: 20741.66, 20741.00      recon: 20715.24, 20714.89,     kl: 22.19, 21.88,     l2: 4.22433,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:280, step:7550 (TRAIN, VALID): total: 20742.08, 20739.70      recon: 20715.70, 20712.86,     kl: 22.15, 22.61,     l2: 4.22864,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:281, step:7575 (TRAIN, VALID): total: 20742.10, 20740.86      recon: 20715.50, 20714.88,     kl: 22.37, 21.74,     l2: 4.23591,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:282, step:7600 (TRAIN, VALID): total: 20742.22, 20742.68      recon: 20715.54, 20715.99,     kl: 22.44, 22.45,     l2: 4.23918,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:283, step:7625 (TRAIN, VALID): total: 20742.19, 20740.92      recon: 20715.17, 20713.84,     kl: 22.78, 22.84,     l2: 4.24674,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:284, step:7650 (TRAIN, VALID): total: 20741.70, 20742.30      recon: 20715.08, 20716.32,     kl: 22.37, 21.73,     l2: 4.25619,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:285, step:7675 (TRAIN, VALID): total: 20742.17, 20740.72      recon: 20715.35, 20713.27,     kl: 22.56, 23.18,     l2: 4.26324,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:286, step:7700 (TRAIN, VALID): total: 20742.62, 20740.66      recon: 20715.50, 20713.60,     kl: 22.85, 22.79,     l2: 4.26907,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004401.\n",
      "Epoch:287, step:7725 (TRAIN, VALID): total: 20741.77, 20739.54      recon: 20714.89, 20713.32,     kl: 22.61, 21.94,     l2: 4.27557,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:288, step:7750 (TRAIN, VALID): total: 20741.43, 20740.19      recon: 20714.66, 20713.81,     kl: 22.49, 22.09,     l2: 4.28067,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:289, step:7775 (TRAIN, VALID): total: 20740.76, 20739.48      recon: 20714.17, 20713.81,     kl: 22.31, 21.39,     l2: 4.28690,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:290, step:7800 (TRAIN, VALID): total: 20741.13, 20741.44      recon: 20714.38, 20714.14,     kl: 22.46, 23.01,     l2: 4.29119,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:291, step:7825 (TRAIN, VALID): total: 20741.40, 20739.22      recon: 20714.56, 20712.40,     kl: 22.55, 22.53,     l2: 4.29779,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:292, step:7850 (TRAIN, VALID): total: 20740.10, 20740.81      recon: 20713.48, 20713.63,     kl: 22.31, 22.87,     l2: 4.30615,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:293, step:7875 (TRAIN, VALID): total: 20740.82, 20738.92      recon: 20714.05, 20713.59,     kl: 22.46, 21.02,     l2: 4.31271,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:294, step:7900 (TRAIN, VALID): total: 20740.96, 20741.34      recon: 20714.12, 20714.74,     kl: 22.52, 22.28,     l2: 4.31766,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:295, step:7925 (TRAIN, VALID): total: 20740.44, 20739.58      recon: 20714.03, 20712.71,     kl: 22.09, 22.54,     l2: 4.32564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:296, step:7950 (TRAIN, VALID): total: 20739.84, 20741.76      recon: 20713.38, 20715.39,     kl: 22.13, 22.04,     l2: 4.33280,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:297, step:7975 (TRAIN, VALID): total: 20740.33, 20738.14      recon: 20713.81, 20712.21,     kl: 22.19, 21.59,     l2: 4.33506,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:298, step:8000 (TRAIN, VALID): total: 20739.65, 20739.87      recon: 20713.23, 20713.85,     kl: 22.08, 21.68,     l2: 4.33850,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:299, step:8025 (TRAIN, VALID): total: 20741.04, 20739.94      recon: 20714.27, 20713.33,     kl: 22.43, 22.26,     l2: 4.34430,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.004181.\n",
      "Epoch:300, step:8050 (TRAIN, VALID): total: 20740.17, 20739.29      recon: 20713.48, 20712.75,     kl: 22.35, 22.20,     l2: 4.34903,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:301, step:8075 (TRAIN, VALID): total: 20740.60, 20739.72      recon: 20713.89, 20712.85,     kl: 22.35, 22.52,     l2: 4.35399,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:302, step:8100 (TRAIN, VALID): total: 20739.02, 20741.51      recon: 20712.48, 20715.00,     kl: 22.18, 22.15,     l2: 4.36093,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:303, step:8125 (TRAIN, VALID): total: 20739.47, 20738.15      recon: 20713.05, 20711.70,     kl: 22.06, 22.09,     l2: 4.36555,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:304, step:8150 (TRAIN, VALID): total: 20739.90, 20738.09      recon: 20713.02, 20712.21,     kl: 22.51, 21.51,     l2: 4.37096,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:305, step:8175 (TRAIN, VALID): total: 20739.32, 20738.94      recon: 20712.66, 20712.38,     kl: 22.28, 22.18,     l2: 4.37780,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:306, step:8200 (TRAIN, VALID): total: 20739.85, 20739.32      recon: 20713.34, 20713.31,     kl: 22.13, 21.62,     l2: 4.38539,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:307, step:8225 (TRAIN, VALID): total: 20739.83, 20739.85      recon: 20713.22, 20714.04,     kl: 22.22, 21.43,     l2: 4.39100,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:308, step:8250 (TRAIN, VALID): total: 20739.79, 20738.70      recon: 20713.31, 20712.12,     kl: 22.09, 22.19,     l2: 4.39508,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:309, step:8275 (TRAIN, VALID): total: 20739.52, 20740.64      recon: 20712.69, 20714.54,     kl: 22.43, 21.70,     l2: 4.39797,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:310, step:8300 (TRAIN, VALID): total: 20740.45, 20740.37      recon: 20713.31, 20712.27,     kl: 22.74, 23.69,     l2: 4.40444,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003972.\n",
      "Epoch:311, step:8325 (TRAIN, VALID): total: 20739.23, 20736.01      recon: 20712.29, 20709.80,     kl: 22.53, 21.79,     l2: 4.41074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:312, step:8350 (TRAIN, VALID): total: 20739.16, 20739.03      recon: 20712.37, 20713.30,     kl: 22.37, 21.31,     l2: 4.41564,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:313, step:8375 (TRAIN, VALID): total: 20739.02, 20738.49      recon: 20712.29, 20711.60,     kl: 22.31, 22.47,     l2: 4.42291,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:314, step:8400 (TRAIN, VALID): total: 20737.66, 20739.07      recon: 20711.25, 20712.13,     kl: 21.98, 22.50,     l2: 4.42676,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:315, step:8425 (TRAIN, VALID): total: 20737.99, 20739.72      recon: 20711.50, 20712.12,     kl: 22.05, 23.17,     l2: 4.43215,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:316, step:8450 (TRAIN, VALID): total: 20738.38, 20738.70      recon: 20711.76, 20712.67,     kl: 22.19, 21.59,     l2: 4.43588,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:317, step:8475 (TRAIN, VALID): total: 20738.17, 20738.92      recon: 20711.73, 20712.70,     kl: 22.00, 21.78,     l2: 4.44188,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:318, step:8500 (TRAIN, VALID): total: 20737.70, 20739.97      recon: 20711.27, 20713.49,     kl: 21.99, 22.03,     l2: 4.44611,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:319, step:8525 (TRAIN, VALID): total: 20738.16, 20739.16      recon: 20711.65, 20713.15,     kl: 22.06, 21.56,     l2: 4.45441,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:320, step:8550 (TRAIN, VALID): total: 20738.29, 20739.76      recon: 20712.03, 20713.28,     kl: 21.80, 22.02,     l2: 4.46281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:321, step:8575 (TRAIN, VALID): total: 20738.73, 20738.24      recon: 20712.15, 20712.30,     kl: 22.11, 21.47,     l2: 4.46784,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003774.\n",
      "Epoch:322, step:8600 (TRAIN, VALID): total: 20738.05, 20737.82      recon: 20711.35, 20711.91,     kl: 22.23, 21.43,     l2: 4.47191,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:323, step:8625 (TRAIN, VALID): total: 20736.85, 20737.33      recon: 20710.54, 20711.23,     kl: 21.83, 21.61,     l2: 4.47717,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:324, step:8650 (TRAIN, VALID): total: 20737.48, 20738.21      recon: 20710.81, 20711.84,     kl: 22.18, 21.89,     l2: 4.48156,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:325, step:8675 (TRAIN, VALID): total: 20737.15, 20739.42      recon: 20710.72, 20712.66,     kl: 21.95, 22.28,     l2: 4.48641,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:326, step:8700 (TRAIN, VALID): total: 20737.73, 20738.07      recon: 20711.26, 20711.50,     kl: 21.98, 22.07,     l2: 4.49245,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:327, step:8725 (TRAIN, VALID): total: 20737.61, 20738.55      recon: 20711.22, 20711.92,     kl: 21.89, 22.13,     l2: 4.49936,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:328, step:8750 (TRAIN, VALID): total: 20737.18, 20738.50      recon: 20710.86, 20712.51,     kl: 21.82, 21.49,     l2: 4.50520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:329, step:8775 (TRAIN, VALID): total: 20737.46, 20739.01      recon: 20710.89, 20712.29,     kl: 22.06, 22.20,     l2: 4.51202,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:330, step:8800 (TRAIN, VALID): total: 20737.14, 20737.35      recon: 20710.71, 20711.44,     kl: 21.92, 21.40,     l2: 4.51427,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:331, step:8825 (TRAIN, VALID): total: 20737.18, 20740.10      recon: 20710.52, 20714.05,     kl: 22.15, 21.53,     l2: 4.51892,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:332, step:8850 (TRAIN, VALID): total: 20736.70, 20738.65      recon: 20710.51, 20712.41,     kl: 21.66, 21.71,     l2: 4.52448,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:333, step:8875 (TRAIN, VALID): total: 20736.72, 20737.94      recon: 20710.21, 20711.51,     kl: 21.99, 21.90,     l2: 4.52818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:334, step:8900 (TRAIN, VALID): total: 20737.76, 20737.96      recon: 20710.87, 20710.78,     kl: 22.35, 22.65,     l2: 4.53233,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003585.\n",
      "Epoch:335, step:8925 (TRAIN, VALID): total: 20736.27, 20737.63      recon: 20709.83, 20711.43,     kl: 21.91, 21.66,     l2: 4.53813,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:336, step:8950 (TRAIN, VALID): total: 20736.56, 20738.33      recon: 20709.94, 20711.69,     kl: 22.08, 22.10,     l2: 4.54093,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:337, step:8975 (TRAIN, VALID): total: 20736.27, 20738.56      recon: 20710.00, 20712.62,     kl: 21.73, 21.39,     l2: 4.54424,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:338, step:9000 (TRAIN, VALID): total: 20737.07, 20739.58      recon: 20710.48, 20712.93,     kl: 22.04, 22.10,     l2: 4.54916,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:339, step:9025 (TRAIN, VALID): total: 20735.93, 20738.22      recon: 20709.60, 20711.71,     kl: 21.78, 21.95,     l2: 4.55552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:340, step:9050 (TRAIN, VALID): total: 20736.61, 20737.80      recon: 20710.00, 20710.87,     kl: 22.05, 22.36,     l2: 4.56216,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:341, step:9075 (TRAIN, VALID): total: 20735.44, 20736.62      recon: 20709.36, 20710.93,     kl: 21.51, 21.13,     l2: 4.56542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:342, step:9100 (TRAIN, VALID): total: 20736.54, 20736.97      recon: 20710.26, 20710.90,     kl: 21.71, 21.50,     l2: 4.57074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:343, step:9125 (TRAIN, VALID): total: 20736.30, 20738.72      recon: 20709.69, 20712.02,     kl: 22.04, 22.11,     l2: 4.58103,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:344, step:9150 (TRAIN, VALID): total: 20736.39, 20736.53      recon: 20709.83, 20710.35,     kl: 21.98, 21.60,     l2: 4.58615,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:345, step:9175 (TRAIN, VALID): total: 20736.22, 20738.52      recon: 20709.74, 20712.82,     kl: 21.89, 21.11,     l2: 4.59115,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:346, step:9200 (TRAIN, VALID): total: 20735.95, 20738.32      recon: 20709.62, 20712.49,     kl: 21.73, 21.23,     l2: 4.59694,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:347, step:9225 (TRAIN, VALID): total: 20735.81, 20740.24      recon: 20709.43, 20714.14,     kl: 21.78, 21.50,     l2: 4.60434,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:348, step:9250 (TRAIN, VALID): total: 20735.35, 20736.67      recon: 20709.34, 20710.09,     kl: 21.41, 21.97,     l2: 4.60781,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:349, step:9275 (TRAIN, VALID): total: 20735.36, 20737.21      recon: 20708.67, 20711.05,     kl: 22.07, 21.55,     l2: 4.61260,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:350, step:9300 (TRAIN, VALID): total: 20736.55, 20737.54      recon: 20709.98, 20711.49,     kl: 21.96, 21.44,     l2: 4.61626,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003406.\n",
      "Epoch:351, step:9325 (TRAIN, VALID): total: 20735.93, 20737.51      recon: 20709.33, 20711.08,     kl: 21.98, 21.80,     l2: 4.61930,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:352, step:9350 (TRAIN, VALID): total: 20735.16, 20739.80      recon: 20709.02, 20713.92,     kl: 21.51, 21.26,     l2: 4.62528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:353, step:9375 (TRAIN, VALID): total: 20736.30, 20738.25      recon: 20709.62, 20710.87,     kl: 22.05, 22.75,     l2: 4.63341,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:354, step:9400 (TRAIN, VALID): total: 20735.52, 20737.79      recon: 20709.04, 20711.11,     kl: 21.84, 22.04,     l2: 4.63932,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:355, step:9425 (TRAIN, VALID): total: 20735.77, 20738.12      recon: 20709.21, 20712.35,     kl: 21.91, 21.12,     l2: 4.64258,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:356, step:9450 (TRAIN, VALID): total: 20735.43, 20736.61      recon: 20708.98, 20710.41,     kl: 21.80, 21.55,     l2: 4.64834,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:357, step:9475 (TRAIN, VALID): total: 20735.04, 20736.06      recon: 20708.78, 20709.96,     kl: 21.62, 21.45,     l2: 4.65297,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:358, step:9500 (TRAIN, VALID): total: 20734.70, 20736.74      recon: 20708.41, 20710.14,     kl: 21.64, 21.94,     l2: 4.65685,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:359, step:9525 (TRAIN, VALID): total: 20735.40, 20738.46      recon: 20708.91, 20711.80,     kl: 21.83, 22.01,     l2: 4.65781,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:360, step:9550 (TRAIN, VALID): total: 20735.19, 20735.45      recon: 20708.79, 20709.44,     kl: 21.75, 21.34,     l2: 4.66256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:361, step:9575 (TRAIN, VALID): total: 20734.70, 20741.11      recon: 20708.54, 20714.03,     kl: 21.49, 22.41,     l2: 4.66759,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:362, step:9600 (TRAIN, VALID): total: 20735.74, 20735.76      recon: 20709.04, 20709.66,     kl: 22.03, 21.43,     l2: 4.67483,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003235.\n",
      "Epoch:363, step:9625 (TRAIN, VALID): total: 20733.97, 20735.98      recon: 20707.84, 20709.71,     kl: 21.45, 21.59,     l2: 4.67883,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:364, step:9650 (TRAIN, VALID): total: 20733.73, 20738.46      recon: 20707.57, 20711.46,     kl: 21.48, 22.32,     l2: 4.68301,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:365, step:9675 (TRAIN, VALID): total: 20733.69, 20736.25      recon: 20707.35, 20709.87,     kl: 21.65, 21.70,     l2: 4.68689,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:366, step:9700 (TRAIN, VALID): total: 20733.33, 20736.80      recon: 20707.22, 20710.64,     kl: 21.42, 21.47,     l2: 4.69233,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:367, step:9725 (TRAIN, VALID): total: 20734.24, 20737.83      recon: 20707.68, 20711.04,     kl: 21.87, 22.10,     l2: 4.69606,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:368, step:9750 (TRAIN, VALID): total: 20733.93, 20736.06      recon: 20707.39, 20710.12,     kl: 21.84, 21.24,     l2: 4.69868,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:369, step:9775 (TRAIN, VALID): total: 20733.31, 20736.80      recon: 20707.41, 20710.48,     kl: 21.20, 21.62,     l2: 4.70016,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:370, step:9800 (TRAIN, VALID): total: 20733.41, 20736.15      recon: 20707.26, 20709.60,     kl: 21.45, 21.85,     l2: 4.70394,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:371, step:9825 (TRAIN, VALID): total: 20733.91, 20736.42      recon: 20707.64, 20710.29,     kl: 21.57, 21.42,     l2: 4.70911,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:372, step:9850 (TRAIN, VALID): total: 20733.64, 20737.79      recon: 20707.45, 20711.47,     kl: 21.48, 21.61,     l2: 4.71385,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:373, step:9875 (TRAIN, VALID): total: 20734.35, 20738.67      recon: 20708.00, 20712.46,     kl: 21.64, 21.48,     l2: 4.72070,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.003074.\n",
      "Epoch:374, step:9900 (TRAIN, VALID): total: 20733.14, 20735.61      recon: 20706.97, 20709.30,     kl: 21.44, 21.59,     l2: 4.72499,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:375, step:9925 (TRAIN, VALID): total: 20733.22, 20735.08      recon: 20707.12, 20709.12,     kl: 21.38, 21.23,     l2: 4.72866,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:376, step:9950 (TRAIN, VALID): total: 20733.26, 20735.81      recon: 20707.05, 20710.29,     kl: 21.47, 20.78,     l2: 4.73157,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:377, step:9975 (TRAIN, VALID): total: 20733.01, 20737.89      recon: 20706.90, 20711.28,     kl: 21.38, 21.87,     l2: 4.73542,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:378, step:10000 (TRAIN, VALID): total: 20732.72, 20736.28      recon: 20706.62, 20709.28,     kl: 21.37, 22.26,     l2: 4.73867,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:379, step:10025 (TRAIN, VALID): total: 20733.05, 20736.07      recon: 20706.78, 20709.85,     kl: 21.53, 21.48,     l2: 4.74428,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:380, step:10050 (TRAIN, VALID): total: 20732.96, 20735.98      recon: 20706.80, 20710.01,     kl: 21.42, 21.23,     l2: 4.74488,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:381, step:10075 (TRAIN, VALID): total: 20733.14, 20737.14      recon: 20706.93, 20710.43,     kl: 21.46, 21.97,     l2: 4.74629,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:382, step:10100 (TRAIN, VALID): total: 20733.14, 20735.70      recon: 20706.92, 20709.43,     kl: 21.48, 21.52,     l2: 4.75186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:383, step:10125 (TRAIN, VALID): total: 20732.86, 20735.64      recon: 20706.77, 20709.62,     kl: 21.34, 21.26,     l2: 4.75556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:384, step:10150 (TRAIN, VALID): total: 20732.47, 20736.28      recon: 20706.28, 20710.83,     kl: 21.43, 20.69,     l2: 4.75905,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:385, step:10175 (TRAIN, VALID): total: 20732.19, 20736.94      recon: 20706.22, 20710.55,     kl: 21.21, 21.63,     l2: 4.76305,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:386, step:10200 (TRAIN, VALID): total: 20732.94, 20737.40      recon: 20706.73, 20710.38,     kl: 21.45, 22.25,     l2: 4.76847,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:387, step:10225 (TRAIN, VALID): total: 20732.59, 20736.50      recon: 20706.40, 20710.10,     kl: 21.42, 21.63,     l2: 4.77450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:388, step:10250 (TRAIN, VALID): total: 20733.18, 20737.88      recon: 20706.90, 20711.63,     kl: 21.51, 21.47,     l2: 4.77907,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002920.\n",
      "Epoch:389, step:10275 (TRAIN, VALID): total: 20732.14, 20736.89      recon: 20706.15, 20710.89,     kl: 21.21, 21.21,     l2: 4.78381,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:390, step:10300 (TRAIN, VALID): total: 20731.88, 20736.74      recon: 20705.79, 20711.50,     kl: 21.30, 20.45,     l2: 4.78734,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:391, step:10325 (TRAIN, VALID): total: 20731.36, 20735.45      recon: 20705.45, 20710.07,     kl: 21.12, 20.58,     l2: 4.79147,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:392, step:10350 (TRAIN, VALID): total: 20731.85, 20736.34      recon: 20706.02, 20709.89,     kl: 21.04, 21.66,     l2: 4.79384,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:393, step:10375 (TRAIN, VALID): total: 20732.09, 20737.94      recon: 20705.86, 20711.63,     kl: 21.44, 21.52,     l2: 4.79738,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:394, step:10400 (TRAIN, VALID): total: 20731.54, 20736.19      recon: 20705.37, 20710.52,     kl: 21.37, 20.88,     l2: 4.80009,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:395, step:10425 (TRAIN, VALID): total: 20731.63, 20737.92      recon: 20705.85, 20711.34,     kl: 20.98, 21.77,     l2: 4.80431,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:396, step:10450 (TRAIN, VALID): total: 20731.69, 20735.26      recon: 20705.73, 20709.53,     kl: 21.15, 20.92,     l2: 4.80937,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:397, step:10475 (TRAIN, VALID): total: 20731.71, 20734.85      recon: 20705.77, 20709.07,     kl: 21.13, 20.97,     l2: 4.81481,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:398, step:10500 (TRAIN, VALID): total: 20732.01, 20736.81      recon: 20705.73, 20710.29,     kl: 21.46, 21.70,     l2: 4.81454,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:399, step:10525 (TRAIN, VALID): total: 20732.50, 20739.01      recon: 20706.27, 20712.75,     kl: 21.41, 21.44,     l2: 4.82190,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002774.\n",
      "Epoch:400, step:10550 (TRAIN, VALID): total: 20732.30, 20735.92      recon: 20706.22, 20710.27,     kl: 21.26, 20.82,     l2: 4.82842,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:401, step:10575 (TRAIN, VALID): total: 20731.60, 20734.94      recon: 20705.32, 20709.04,     kl: 21.45, 21.06,     l2: 4.83246,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:402, step:10600 (TRAIN, VALID): total: 20731.99, 20735.42      recon: 20705.90, 20709.09,     kl: 21.26, 21.50,     l2: 4.83671,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:403, step:10625 (TRAIN, VALID): total: 20731.67, 20736.26      recon: 20705.55, 20709.87,     kl: 21.29, 21.55,     l2: 4.83949,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:404, step:10650 (TRAIN, VALID): total: 20731.37, 20736.85      recon: 20705.30, 20710.19,     kl: 21.23, 21.82,     l2: 4.84433,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:405, step:10675 (TRAIN, VALID): total: 20731.64, 20737.99      recon: 20705.13, 20711.35,     kl: 21.66, 21.79,     l2: 4.84736,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:406, step:10700 (TRAIN, VALID): total: 20730.90, 20734.15      recon: 20704.74, 20708.18,     kl: 21.31, 21.11,     l2: 4.85032,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:407, step:10725 (TRAIN, VALID): total: 20731.19, 20737.52      recon: 20705.01, 20711.67,     kl: 21.33, 20.99,     l2: 4.85627,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:408, step:10750 (TRAIN, VALID): total: 20731.69, 20734.94      recon: 20705.57, 20709.56,     kl: 21.27, 20.52,     l2: 4.86120,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:409, step:10775 (TRAIN, VALID): total: 20731.11, 20735.42      recon: 20705.34, 20709.37,     kl: 20.91, 21.18,     l2: 4.86444,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:410, step:10800 (TRAIN, VALID): total: 20730.54, 20733.48      recon: 20704.70, 20707.86,     kl: 20.98, 20.75,     l2: 4.86783,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:411, step:10825 (TRAIN, VALID): total: 20731.07, 20735.55      recon: 20705.00, 20709.53,     kl: 21.19, 21.15,     l2: 4.87175,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:412, step:10850 (TRAIN, VALID): total: 20730.88, 20735.55      recon: 20704.86, 20708.74,     kl: 21.15, 21.94,     l2: 4.87702,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:413, step:10875 (TRAIN, VALID): total: 20730.27, 20735.37      recon: 20704.38, 20708.99,     kl: 21.01, 21.50,     l2: 4.87885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:414, step:10900 (TRAIN, VALID): total: 20731.06, 20734.46      recon: 20704.74, 20708.04,     kl: 21.45, 21.53,     l2: 4.88467,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:415, step:10925 (TRAIN, VALID): total: 20730.38, 20736.34      recon: 20704.45, 20710.58,     kl: 21.05, 20.88,     l2: 4.88916,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:416, step:10950 (TRAIN, VALID): total: 20730.66, 20737.35      recon: 20704.50, 20711.65,     kl: 21.27, 20.81,     l2: 4.89389,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:417, step:10975 (TRAIN, VALID): total: 20730.42, 20736.17      recon: 20704.41, 20710.60,     kl: 21.12, 20.67,     l2: 4.89763,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:418, step:11000 (TRAIN, VALID): total: 20730.55, 20736.69      recon: 20704.66, 20710.61,     kl: 20.99, 21.18,     l2: 4.90074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:419, step:11025 (TRAIN, VALID): total: 20731.25, 20736.12      recon: 20704.87, 20709.35,     kl: 21.48, 21.86,     l2: 4.90439,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002635.\n",
      "Epoch:420, step:11050 (TRAIN, VALID): total: 20731.00, 20736.39      recon: 20704.64, 20709.76,     kl: 21.46, 21.71,     l2: 4.90989,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:421, step:11075 (TRAIN, VALID): total: 20729.96, 20735.80      recon: 20703.89, 20710.09,     kl: 21.16, 20.81,     l2: 4.91074,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:422, step:11100 (TRAIN, VALID): total: 20730.29, 20735.22      recon: 20703.98, 20709.10,     kl: 21.39, 21.20,     l2: 4.91657,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:423, step:11125 (TRAIN, VALID): total: 20730.19, 20733.82      recon: 20704.51, 20707.66,     kl: 20.77, 21.24,     l2: 4.91785,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:424, step:11150 (TRAIN, VALID): total: 20730.17, 20733.17      recon: 20704.32, 20707.22,     kl: 20.94, 21.03,     l2: 4.92088,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:425, step:11175 (TRAIN, VALID): total: 20729.14, 20734.16      recon: 20703.30, 20708.56,     kl: 20.92, 20.68,     l2: 4.92429,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:426, step:11200 (TRAIN, VALID): total: 20730.08, 20737.51      recon: 20704.15, 20711.09,     kl: 21.01, 21.49,     l2: 4.92802,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:427, step:11225 (TRAIN, VALID): total: 20729.42, 20734.11      recon: 20703.73, 20707.93,     kl: 20.76, 21.25,     l2: 4.93230,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:428, step:11250 (TRAIN, VALID): total: 20728.95, 20734.26      recon: 20703.31, 20708.72,     kl: 20.70, 20.61,     l2: 4.93650,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:429, step:11275 (TRAIN, VALID): total: 20729.77, 20737.74      recon: 20703.83, 20711.10,     kl: 21.00, 21.70,     l2: 4.94060,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:430, step:11300 (TRAIN, VALID): total: 20730.16, 20735.19      recon: 20703.97, 20708.46,     kl: 21.24, 21.79,     l2: 4.94568,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:431, step:11325 (TRAIN, VALID): total: 20730.08, 20735.41      recon: 20703.96, 20709.71,     kl: 21.17, 20.75,     l2: 4.94942,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:432, step:11350 (TRAIN, VALID): total: 20730.36, 20735.29      recon: 20704.22, 20709.34,     kl: 21.18, 20.99,     l2: 4.95534,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002503.\n",
      "Epoch:433, step:11375 (TRAIN, VALID): total: 20729.43, 20735.79      recon: 20703.49, 20709.69,     kl: 20.98, 21.14,     l2: 4.95997,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:434, step:11400 (TRAIN, VALID): total: 20729.31, 20734.47      recon: 20703.57, 20707.88,     kl: 20.77, 21.63,     l2: 4.96395,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:435, step:11425 (TRAIN, VALID): total: 20729.47, 20735.15      recon: 20703.51, 20709.14,     kl: 20.99, 21.04,     l2: 4.96769,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:436, step:11450 (TRAIN, VALID): total: 20729.07, 20734.96      recon: 20703.14, 20708.83,     kl: 20.97, 21.16,     l2: 4.97014,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:437, step:11475 (TRAIN, VALID): total: 20729.15, 20735.45      recon: 20703.27, 20709.37,     kl: 20.91, 21.11,     l2: 4.97237,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:438, step:11500 (TRAIN, VALID): total: 20729.31, 20735.84      recon: 20703.39, 20709.77,     kl: 20.94, 21.10,     l2: 4.97809,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:439, step:11525 (TRAIN, VALID): total: 20730.01, 20738.07      recon: 20703.77, 20711.99,     kl: 21.27, 21.10,     l2: 4.98129,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002378.\n",
      "Epoch:440, step:11550 (TRAIN, VALID): total: 20728.69, 20734.33      recon: 20702.76, 20708.77,     kl: 20.94, 20.58,     l2: 4.98334,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:441, step:11575 (TRAIN, VALID): total: 20729.00, 20736.22      recon: 20703.18, 20710.30,     kl: 20.83, 20.93,     l2: 4.98709,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:442, step:11600 (TRAIN, VALID): total: 20728.14, 20733.21      recon: 20702.51, 20707.49,     kl: 20.64, 20.73,     l2: 4.98963,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:443, step:11625 (TRAIN, VALID): total: 20727.99, 20735.34      recon: 20702.31, 20709.39,     kl: 20.69, 20.96,     l2: 4.99104,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:444, step:11650 (TRAIN, VALID): total: 20728.84, 20734.60      recon: 20702.80, 20709.10,     kl: 21.05, 20.51,     l2: 4.99304,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:445, step:11675 (TRAIN, VALID): total: 20729.05, 20733.66      recon: 20703.10, 20707.39,     kl: 20.95, 21.28,     l2: 4.99652,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:446, step:11700 (TRAIN, VALID): total: 20728.43, 20732.87      recon: 20702.66, 20706.81,     kl: 20.76, 21.06,     l2: 4.99956,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:447, step:11725 (TRAIN, VALID): total: 20728.08, 20734.23      recon: 20702.34, 20708.57,     kl: 20.74, 20.65,     l2: 5.00475,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:448, step:11750 (TRAIN, VALID): total: 20728.10, 20735.04      recon: 20702.42, 20709.05,     kl: 20.68, 20.99,     l2: 5.00569,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:449, step:11775 (TRAIN, VALID): total: 20728.47, 20736.43      recon: 20702.56, 20709.77,     kl: 20.90, 21.66,     l2: 5.01050,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:450, step:11800 (TRAIN, VALID): total: 20728.82, 20735.21      recon: 20702.93, 20708.11,     kl: 20.88, 22.08,     l2: 5.01337,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:451, step:11825 (TRAIN, VALID): total: 20728.22, 20734.36      recon: 20702.55, 20708.15,     kl: 20.65, 21.19,     l2: 5.01776,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:452, step:11850 (TRAIN, VALID): total: 20728.16, 20733.10      recon: 20702.29, 20707.11,     kl: 20.85, 20.96,     l2: 5.02027,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:453, step:11875 (TRAIN, VALID): total: 20728.34, 20735.73      recon: 20702.60, 20708.91,     kl: 20.71, 21.80,     l2: 5.02320,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:454, step:11900 (TRAIN, VALID): total: 20727.98, 20734.79      recon: 20702.03, 20708.47,     kl: 20.92, 21.29,     l2: 5.02773,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:455, step:11925 (TRAIN, VALID): total: 20728.21, 20734.30      recon: 20702.37, 20708.34,     kl: 20.81, 20.93,     l2: 5.03107,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:456, step:11950 (TRAIN, VALID): total: 20727.65, 20735.00      recon: 20701.97, 20708.80,     kl: 20.65, 21.17,     l2: 5.03386,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:457, step:11975 (TRAIN, VALID): total: 20728.18, 20733.52      recon: 20702.34, 20707.32,     kl: 20.80, 21.17,     l2: 5.03601,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:458, step:12000 (TRAIN, VALID): total: 20727.75, 20735.60      recon: 20701.91, 20709.73,     kl: 20.80, 20.83,     l2: 5.04029,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:459, step:12025 (TRAIN, VALID): total: 20727.45, 20735.93      recon: 20701.77, 20709.67,     kl: 20.63, 21.21,     l2: 5.04357,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:460, step:12050 (TRAIN, VALID): total: 20727.20, 20734.51      recon: 20701.51, 20708.92,     kl: 20.65, 20.54,     l2: 5.04548,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:461, step:12075 (TRAIN, VALID): total: 20727.03, 20732.54      recon: 20701.50, 20706.25,     kl: 20.48, 21.24,     l2: 5.04892,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:462, step:12100 (TRAIN, VALID): total: 20727.42, 20734.60      recon: 20701.76, 20709.35,     kl: 20.61, 20.19,     l2: 5.05035,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:463, step:12125 (TRAIN, VALID): total: 20727.66, 20736.41      recon: 20701.99, 20709.88,     kl: 20.62, 21.47,     l2: 5.05514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:464, step:12150 (TRAIN, VALID): total: 20728.50, 20735.11      recon: 20702.58, 20708.64,     kl: 20.87, 21.41,     l2: 5.05808,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002259.\n",
      "Epoch:465, step:12175 (TRAIN, VALID): total: 20728.39, 20735.22      recon: 20702.19, 20708.76,     kl: 21.14, 21.40,     l2: 5.06200,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:466, step:12200 (TRAIN, VALID): total: 20727.77, 20733.97      recon: 20701.96, 20708.55,     kl: 20.75, 20.36,     l2: 5.06463,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:467, step:12225 (TRAIN, VALID): total: 20727.10, 20733.18      recon: 20701.52, 20707.24,     kl: 20.51, 20.87,     l2: 5.06877,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:468, step:12250 (TRAIN, VALID): total: 20728.07, 20734.84      recon: 20702.09, 20709.13,     kl: 20.91, 20.64,     l2: 5.07204,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:469, step:12275 (TRAIN, VALID): total: 20727.57, 20734.69      recon: 20701.62, 20708.92,     kl: 20.87, 20.69,     l2: 5.07567,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:470, step:12300 (TRAIN, VALID): total: 20728.24, 20734.91      recon: 20702.17, 20708.98,     kl: 20.99, 20.85,     l2: 5.07861,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:471, step:12325 (TRAIN, VALID): total: 20727.69, 20735.82      recon: 20701.84, 20709.60,     kl: 20.77, 21.13,     l2: 5.08416,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:472, step:12350 (TRAIN, VALID): total: 20727.22, 20734.33      recon: 20701.43, 20708.47,     kl: 20.70, 20.78,     l2: 5.08593,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:473, step:12375 (TRAIN, VALID): total: 20727.45, 20735.96      recon: 20701.68, 20709.75,     kl: 20.68, 21.13,     l2: 5.08882,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:474, step:12400 (TRAIN, VALID): total: 20727.99, 20733.38      recon: 20701.87, 20707.41,     kl: 21.03, 20.88,     l2: 5.09450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:475, step:12425 (TRAIN, VALID): total: 20727.13, 20734.83      recon: 20701.46, 20709.27,     kl: 20.57, 20.46,     l2: 5.10311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:476, step:12450 (TRAIN, VALID): total: 20727.24, 20733.84      recon: 20701.64, 20707.72,     kl: 20.50, 21.02,     l2: 5.10520,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:477, step:12475 (TRAIN, VALID): total: 20727.87, 20733.36      recon: 20701.75, 20707.51,     kl: 21.02, 20.74,     l2: 5.10760,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:478, step:12500 (TRAIN, VALID): total: 20726.89, 20733.96      recon: 20701.18, 20708.10,     kl: 20.60, 20.74,     l2: 5.11268,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:479, step:12525 (TRAIN, VALID): total: 20727.35, 20734.10      recon: 20701.38, 20707.67,     kl: 20.86, 21.31,     l2: 5.11624,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:480, step:12550 (TRAIN, VALID): total: 20727.02, 20733.80      recon: 20701.20, 20707.30,     kl: 20.70, 21.38,     l2: 5.11828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:481, step:12575 (TRAIN, VALID): total: 20727.28, 20733.79      recon: 20701.28, 20708.05,     kl: 20.87, 20.61,     l2: 5.12091,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:482, step:12600 (TRAIN, VALID): total: 20726.73, 20732.86      recon: 20701.07, 20706.84,     kl: 20.54, 20.89,     l2: 5.12432,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:483, step:12625 (TRAIN, VALID): total: 20726.63, 20735.03      recon: 20700.93, 20708.80,     kl: 20.57, 21.11,     l2: 5.12681,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:484, step:12650 (TRAIN, VALID): total: 20726.62, 20735.39      recon: 20700.79, 20709.30,     kl: 20.70, 20.95,     l2: 5.12944,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:485, step:12675 (TRAIN, VALID): total: 20727.21, 20734.21      recon: 20701.20, 20707.85,     kl: 20.88, 21.23,     l2: 5.13353,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:486, step:12700 (TRAIN, VALID): total: 20726.71, 20735.40      recon: 20701.09, 20708.95,     kl: 20.48, 21.32,     l2: 5.13854,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:487, step:12725 (TRAIN, VALID): total: 20726.76, 20734.03      recon: 20701.03, 20707.93,     kl: 20.59, 20.96,     l2: 5.14281,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:488, step:12750 (TRAIN, VALID): total: 20726.94, 20734.64      recon: 20701.09, 20708.09,     kl: 20.70, 21.40,     l2: 5.14730,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:489, step:12775 (TRAIN, VALID): total: 20726.40, 20734.27      recon: 20700.73, 20707.75,     kl: 20.52, 21.37,     l2: 5.15125,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:490, step:12800 (TRAIN, VALID): total: 20726.97, 20733.52      recon: 20700.95, 20707.43,     kl: 20.87, 20.94,     l2: 5.15498,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:491, step:12825 (TRAIN, VALID): total: 20726.35, 20733.62      recon: 20700.97, 20707.58,     kl: 20.22, 20.88,     l2: 5.15849,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:492, step:12850 (TRAIN, VALID): total: 20726.44, 20733.08      recon: 20700.65, 20706.49,     kl: 20.63, 21.43,     l2: 5.16009,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:493, step:12875 (TRAIN, VALID): total: 20727.07, 20736.61      recon: 20701.07, 20709.86,     kl: 20.84, 21.58,     l2: 5.16369,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002146.\n",
      "Epoch:494, step:12900 (TRAIN, VALID): total: 20726.81, 20734.58      recon: 20701.12, 20708.90,     kl: 20.52, 20.52,     l2: 5.16626,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:495, step:12925 (TRAIN, VALID): total: 20726.14, 20734.24      recon: 20700.68, 20708.29,     kl: 20.29, 20.78,     l2: 5.16831,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:496, step:12950 (TRAIN, VALID): total: 20726.75, 20733.40      recon: 20700.90, 20707.42,     kl: 20.68, 20.80,     l2: 5.17202,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:497, step:12975 (TRAIN, VALID): total: 20726.18, 20735.30      recon: 20700.30, 20708.61,     kl: 20.71, 21.51,     l2: 5.17510,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:498, step:13000 (TRAIN, VALID): total: 20726.12, 20732.45      recon: 20700.60, 20706.67,     kl: 20.34, 20.61,     l2: 5.17741,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:499, step:13025 (TRAIN, VALID): total: 20725.97, 20733.17      recon: 20700.36, 20707.06,     kl: 20.42, 20.93,     l2: 5.18081,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:500, step:13050 (TRAIN, VALID): total: 20726.45, 20734.31      recon: 20700.49, 20708.06,     kl: 20.78, 21.06,     l2: 5.18477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:501, step:13075 (TRAIN, VALID): total: 20726.35, 20733.81      recon: 20700.50, 20707.57,     kl: 20.66, 21.05,     l2: 5.18702,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:502, step:13100 (TRAIN, VALID): total: 20726.11, 20733.82      recon: 20700.38, 20708.06,     kl: 20.54, 20.57,     l2: 5.19020,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:503, step:13125 (TRAIN, VALID): total: 20726.26, 20735.77      recon: 20700.35, 20709.69,     kl: 20.72, 20.89,     l2: 5.19298,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:504, step:13150 (TRAIN, VALID): total: 20726.28, 20734.70      recon: 20700.73, 20708.22,     kl: 20.36, 21.28,     l2: 5.19602,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:505, step:13175 (TRAIN, VALID): total: 20726.75, 20734.22      recon: 20700.74, 20708.36,     kl: 20.81, 20.67,     l2: 5.20031,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.002039.\n",
      "Epoch:506, step:13200 (TRAIN, VALID): total: 20726.33, 20732.92      recon: 20700.52, 20706.54,     kl: 20.61, 21.18,     l2: 5.20382,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:507, step:13225 (TRAIN, VALID): total: 20725.72, 20732.80      recon: 20700.04, 20706.80,     kl: 20.47, 20.79,     l2: 5.20748,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:508, step:13250 (TRAIN, VALID): total: 20725.40, 20733.40      recon: 20699.78, 20707.34,     kl: 20.41, 20.85,     l2: 5.20954,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:509, step:13275 (TRAIN, VALID): total: 20726.11, 20735.31      recon: 20700.08, 20709.32,     kl: 20.82, 20.78,     l2: 5.21205,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:510, step:13300 (TRAIN, VALID): total: 20725.85, 20734.78      recon: 20699.93, 20709.04,     kl: 20.71, 20.52,     l2: 5.21537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:511, step:13325 (TRAIN, VALID): total: 20725.81, 20733.30      recon: 20700.05, 20707.38,     kl: 20.54, 20.70,     l2: 5.22009,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:512, step:13350 (TRAIN, VALID): total: 20725.51, 20735.54      recon: 20699.61, 20709.67,     kl: 20.68, 20.65,     l2: 5.22316,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:513, step:13375 (TRAIN, VALID): total: 20725.56, 20731.96      recon: 20699.86, 20705.67,     kl: 20.47, 21.06,     l2: 5.22394,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:514, step:13400 (TRAIN, VALID): total: 20725.11, 20732.09      recon: 20699.62, 20706.03,     kl: 20.26, 20.84,     l2: 5.22889,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:515, step:13425 (TRAIN, VALID): total: 20725.91, 20735.00      recon: 20699.95, 20708.55,     kl: 20.73, 21.22,     l2: 5.23148,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:516, step:13450 (TRAIN, VALID): total: 20725.58, 20733.93      recon: 20699.82, 20707.65,     kl: 20.52, 21.05,     l2: 5.23407,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:517, step:13475 (TRAIN, VALID): total: 20725.34, 20732.70      recon: 20699.74, 20706.29,     kl: 20.36, 21.17,     l2: 5.23815,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:518, step:13500 (TRAIN, VALID): total: 20725.18, 20733.26      recon: 20699.41, 20707.05,     kl: 20.53, 20.97,     l2: 5.24012,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:519, step:13525 (TRAIN, VALID): total: 20724.80, 20733.55      recon: 20699.28, 20707.40,     kl: 20.29, 20.91,     l2: 5.24302,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:520, step:13550 (TRAIN, VALID): total: 20725.04, 20734.62      recon: 20699.33, 20708.40,     kl: 20.46, 20.98,     l2: 5.24450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:521, step:13575 (TRAIN, VALID): total: 20724.79, 20731.98      recon: 20699.34, 20705.96,     kl: 20.21, 20.77,     l2: 5.24697,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:522, step:13600 (TRAIN, VALID): total: 20725.38, 20733.07      recon: 20699.54, 20707.42,     kl: 20.59, 20.41,     l2: 5.24868,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:523, step:13625 (TRAIN, VALID): total: 20724.75, 20734.31      recon: 20699.23, 20708.22,     kl: 20.26, 20.84,     l2: 5.25245,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:524, step:13650 (TRAIN, VALID): total: 20725.52, 20735.11      recon: 20699.51, 20708.93,     kl: 20.76, 20.92,     l2: 5.25569,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001937.\n",
      "Epoch:525, step:13675 (TRAIN, VALID): total: 20725.03, 20733.57      recon: 20699.37, 20707.56,     kl: 20.41, 20.75,     l2: 5.26010,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:526, step:13700 (TRAIN, VALID): total: 20725.21, 20734.68      recon: 20699.42, 20708.42,     kl: 20.53, 21.00,     l2: 5.26122,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:527, step:13725 (TRAIN, VALID): total: 20725.13, 20734.11      recon: 20699.58, 20708.07,     kl: 20.28, 20.78,     l2: 5.26401,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:528, step:13750 (TRAIN, VALID): total: 20725.66, 20733.37      recon: 20699.90, 20707.59,     kl: 20.49, 20.51,     l2: 5.26634,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:529, step:13775 (TRAIN, VALID): total: 20725.28, 20732.89      recon: 20699.61, 20706.73,     kl: 20.40, 20.88,     l2: 5.27011,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:530, step:13800 (TRAIN, VALID): total: 20724.70, 20732.89      recon: 20699.23, 20706.70,     kl: 20.19, 20.92,     l2: 5.27490,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:531, step:13825 (TRAIN, VALID): total: 20725.34, 20734.21      recon: 20699.54, 20707.55,     kl: 20.52, 21.38,     l2: 5.27707,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:532, step:13850 (TRAIN, VALID): total: 20724.51, 20732.54      recon: 20698.83, 20706.19,     kl: 20.39, 21.07,     l2: 5.27993,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:533, step:13875 (TRAIN, VALID): total: 20724.03, 20732.96      recon: 20698.48, 20706.41,     kl: 20.27, 21.26,     l2: 5.28259,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:534, step:13900 (TRAIN, VALID): total: 20724.58, 20733.89      recon: 20698.93, 20708.00,     kl: 20.36, 20.60,     l2: 5.28511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:535, step:13925 (TRAIN, VALID): total: 20724.50, 20734.57      recon: 20699.01, 20708.49,     kl: 20.20, 20.79,     l2: 5.28623,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:536, step:13950 (TRAIN, VALID): total: 20724.32, 20735.05      recon: 20698.73, 20709.12,     kl: 20.31, 20.64,     l2: 5.28977,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:537, step:13975 (TRAIN, VALID): total: 20724.01, 20734.67      recon: 20698.55, 20708.27,     kl: 20.17, 21.10,     l2: 5.29280,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:538, step:14000 (TRAIN, VALID): total: 20724.41, 20732.20      recon: 20698.80, 20706.30,     kl: 20.31, 20.61,     l2: 5.29699,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:539, step:14025 (TRAIN, VALID): total: 20724.67, 20732.11      recon: 20698.78, 20706.00,     kl: 20.60, 20.81,     l2: 5.30120,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001840.\n",
      "Epoch:540, step:14050 (TRAIN, VALID): total: 20723.83, 20732.57      recon: 20698.23, 20706.37,     kl: 20.29, 20.89,     l2: 5.30413,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:541, step:14075 (TRAIN, VALID): total: 20724.23, 20733.16      recon: 20698.75, 20706.97,     kl: 20.17, 20.89,     l2: 5.30531,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:542, step:14100 (TRAIN, VALID): total: 20724.15, 20734.21      recon: 20698.49, 20708.04,     kl: 20.35, 20.86,     l2: 5.30737,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:543, step:14125 (TRAIN, VALID): total: 20723.91, 20732.08      recon: 20698.33, 20706.19,     kl: 20.28, 20.59,     l2: 5.30991,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:544, step:14150 (TRAIN, VALID): total: 20724.23, 20734.82      recon: 20698.65, 20708.50,     kl: 20.27, 21.01,     l2: 5.31256,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:545, step:14175 (TRAIN, VALID): total: 20724.31, 20733.42      recon: 20698.58, 20707.43,     kl: 20.42, 20.68,     l2: 5.31528,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:546, step:14200 (TRAIN, VALID): total: 20724.15, 20733.65      recon: 20698.58, 20707.25,     kl: 20.25, 21.08,     l2: 5.31900,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:547, step:14225 (TRAIN, VALID): total: 20724.26, 20734.01      recon: 20698.62, 20707.46,     kl: 20.32, 21.23,     l2: 5.32026,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:548, step:14250 (TRAIN, VALID): total: 20724.15, 20731.58      recon: 20698.52, 20704.96,     kl: 20.31, 21.30,     l2: 5.32347,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:549, step:14275 (TRAIN, VALID): total: 20723.96, 20733.78      recon: 20698.20, 20707.59,     kl: 20.44, 20.87,     l2: 5.32480,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:550, step:14300 (TRAIN, VALID): total: 20723.77, 20732.95      recon: 20698.26, 20706.73,     kl: 20.18, 20.89,     l2: 5.32795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:551, step:14325 (TRAIN, VALID): total: 20724.06, 20733.80      recon: 20698.39, 20707.67,     kl: 20.35, 20.81,     l2: 5.32977,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:552, step:14350 (TRAIN, VALID): total: 20724.18, 20731.76      recon: 20698.55, 20705.46,     kl: 20.30, 20.97,     l2: 5.33210,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:553, step:14375 (TRAIN, VALID): total: 20724.07, 20735.12      recon: 20698.63, 20708.62,     kl: 20.11, 21.17,     l2: 5.33675,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:554, step:14400 (TRAIN, VALID): total: 20724.07, 20733.70      recon: 20698.31, 20708.37,     kl: 20.42, 19.99,     l2: 5.33899,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:555, step:14425 (TRAIN, VALID): total: 20723.51, 20731.90      recon: 20697.99, 20706.00,     kl: 20.18, 20.56,     l2: 5.34108,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:556, step:14450 (TRAIN, VALID): total: 20724.58, 20732.33      recon: 20698.74, 20705.43,     kl: 20.50, 21.56,     l2: 5.34218,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001748.\n",
      "Epoch:557, step:14475 (TRAIN, VALID): total: 20724.19, 20733.55      recon: 20698.44, 20707.24,     kl: 20.40, 20.96,     l2: 5.34514,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:558, step:14500 (TRAIN, VALID): total: 20723.42, 20731.40      recon: 20698.00, 20705.49,     kl: 20.08, 20.57,     l2: 5.34693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:559, step:14525 (TRAIN, VALID): total: 20723.33, 20731.74      recon: 20697.62, 20706.11,     kl: 20.35, 20.28,     l2: 5.34994,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:560, step:14550 (TRAIN, VALID): total: 20723.21, 20734.96      recon: 20697.83, 20708.38,     kl: 20.03, 21.23,     l2: 5.35287,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:561, step:14575 (TRAIN, VALID): total: 20724.60, 20734.81      recon: 20698.72, 20708.73,     kl: 20.53, 20.73,     l2: 5.35552,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:562, step:14600 (TRAIN, VALID): total: 20723.50, 20732.91      recon: 20697.89, 20706.76,     kl: 20.26, 20.79,     l2: 5.35875,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:563, step:14625 (TRAIN, VALID): total: 20723.39, 20732.27      recon: 20697.70, 20706.78,     kl: 20.32, 20.13,     l2: 5.36284,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:564, step:14650 (TRAIN, VALID): total: 20723.03, 20733.75      recon: 20697.81, 20708.16,     kl: 19.86, 20.22,     l2: 5.36530,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:565, step:14675 (TRAIN, VALID): total: 20722.90, 20733.69      recon: 20697.37, 20707.75,     kl: 20.16, 20.57,     l2: 5.36627,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:566, step:14700 (TRAIN, VALID): total: 20723.29, 20732.98      recon: 20697.80, 20706.97,     kl: 20.12, 20.64,     l2: 5.36679,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:567, step:14725 (TRAIN, VALID): total: 20723.05, 20734.07      recon: 20697.69, 20707.81,     kl: 19.99, 20.89,     l2: 5.36887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:568, step:14750 (TRAIN, VALID): total: 20723.39, 20733.71      recon: 20697.95, 20707.22,     kl: 20.07, 21.12,     l2: 5.37065,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:569, step:14775 (TRAIN, VALID): total: 20722.68, 20733.86      recon: 20697.35, 20707.23,     kl: 19.95, 21.26,     l2: 5.37406,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:570, step:14800 (TRAIN, VALID): total: 20722.68, 20732.73      recon: 20697.37, 20707.09,     kl: 19.93, 20.26,     l2: 5.37618,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:571, step:14825 (TRAIN, VALID): total: 20722.99, 20733.10      recon: 20697.47, 20706.75,     kl: 20.14, 20.98,     l2: 5.37764,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:572, step:14850 (TRAIN, VALID): total: 20723.47, 20733.49      recon: 20697.51, 20707.38,     kl: 20.58, 20.72,     l2: 5.38214,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001661.\n",
      "Epoch:573, step:14875 (TRAIN, VALID): total: 20722.56, 20733.24      recon: 20697.16, 20707.28,     kl: 20.02, 20.58,     l2: 5.38549,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:574, step:14900 (TRAIN, VALID): total: 20722.49, 20733.83      recon: 20697.00, 20707.84,     kl: 20.10, 20.60,     l2: 5.38733,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:575, step:14925 (TRAIN, VALID): total: 20723.20, 20732.89      recon: 20697.74, 20706.95,     kl: 20.08, 20.55,     l2: 5.38844,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:576, step:14950 (TRAIN, VALID): total: 20723.12, 20732.95      recon: 20697.53, 20706.33,     kl: 20.20, 21.24,     l2: 5.39005,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:577, step:14975 (TRAIN, VALID): total: 20722.80, 20733.99      recon: 20697.11, 20707.93,     kl: 20.30, 20.67,     l2: 5.39280,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:578, step:15000 (TRAIN, VALID): total: 20723.04, 20733.54      recon: 20697.62, 20707.34,     kl: 20.03, 20.81,     l2: 5.39495,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:579, step:15025 (TRAIN, VALID): total: 20723.51, 20732.36      recon: 20697.77, 20706.20,     kl: 20.34, 20.76,     l2: 5.39648,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001578.\n",
      "Epoch:580, step:15050 (TRAIN, VALID): total: 20722.67, 20733.10      recon: 20697.16, 20706.36,     kl: 20.10, 21.35,     l2: 5.40026,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:581, step:15075 (TRAIN, VALID): total: 20722.47, 20733.65      recon: 20697.04, 20707.57,     kl: 20.03, 20.68,     l2: 5.40395,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:582, step:15100 (TRAIN, VALID): total: 20722.00, 20732.98      recon: 20696.77, 20706.62,     kl: 19.82, 20.95,     l2: 5.40597,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:583, step:15125 (TRAIN, VALID): total: 20722.15, 20734.75      recon: 20696.90, 20707.90,     kl: 19.85, 21.44,     l2: 5.40725,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:584, step:15150 (TRAIN, VALID): total: 20722.44, 20733.37      recon: 20696.84, 20707.16,     kl: 20.18, 20.80,     l2: 5.40807,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:585, step:15175 (TRAIN, VALID): total: 20722.28, 20732.34      recon: 20696.90, 20706.22,     kl: 19.97, 20.71,     l2: 5.40925,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:586, step:15200 (TRAIN, VALID): total: 20722.30, 20733.03      recon: 20696.81, 20707.05,     kl: 20.09, 20.57,     l2: 5.41131,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:587, step:15225 (TRAIN, VALID): total: 20722.75, 20734.38      recon: 20697.26, 20707.58,     kl: 20.08, 21.38,     l2: 5.41193,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001499.\n",
      "Epoch:588, step:15250 (TRAIN, VALID): total: 20722.25, 20734.20      recon: 20696.84, 20708.15,     kl: 20.00, 20.63,     l2: 5.41403,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:589, step:15275 (TRAIN, VALID): total: 20722.05, 20731.95      recon: 20696.87, 20706.11,     kl: 19.77, 20.43,     l2: 5.41641,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:590, step:15300 (TRAIN, VALID): total: 20722.20, 20731.39      recon: 20696.76, 20705.18,     kl: 20.02, 20.79,     l2: 5.41953,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:591, step:15325 (TRAIN, VALID): total: 20722.06, 20732.86      recon: 20696.76, 20706.70,     kl: 19.88, 20.75,     l2: 5.41941,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:592, step:15350 (TRAIN, VALID): total: 20722.29, 20732.55      recon: 20696.89, 20706.73,     kl: 19.97, 20.40,     l2: 5.42064,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:593, step:15375 (TRAIN, VALID): total: 20722.25, 20730.77      recon: 20696.83, 20705.05,     kl: 20.00, 20.29,     l2: 5.42393,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:594, step:15400 (TRAIN, VALID): total: 20721.73, 20733.02      recon: 20696.40, 20706.94,     kl: 19.91, 20.66,     l2: 5.42457,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:595, step:15425 (TRAIN, VALID): total: 20721.94, 20731.32      recon: 20696.55, 20705.93,     kl: 19.96, 19.96,     l2: 5.42675,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:596, step:15450 (TRAIN, VALID): total: 20721.95, 20731.26      recon: 20696.89, 20705.43,     kl: 19.64, 20.40,     l2: 5.42789,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:597, step:15475 (TRAIN, VALID): total: 20721.65, 20733.09      recon: 20696.35, 20707.12,     kl: 19.87, 20.54,     l2: 5.43103,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:598, step:15500 (TRAIN, VALID): total: 20722.28, 20731.85      recon: 20696.62, 20706.02,     kl: 20.23, 20.40,     l2: 5.43296,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:599, step:15525 (TRAIN, VALID): total: 20721.98, 20731.35      recon: 20696.59, 20705.02,     kl: 19.95, 20.89,     l2: 5.43465,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:600, step:15550 (TRAIN, VALID): total: 20721.93, 20731.84      recon: 20696.46, 20705.51,     kl: 20.04, 20.89,     l2: 5.43600,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:601, step:15575 (TRAIN, VALID): total: 20722.15, 20731.63      recon: 20696.63, 20705.51,     kl: 20.09, 20.68,     l2: 5.43828,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:602, step:15600 (TRAIN, VALID): total: 20721.44, 20731.46      recon: 20696.33, 20705.78,     kl: 19.67, 20.24,     l2: 5.44104,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:603, step:15625 (TRAIN, VALID): total: 20721.98, 20731.64      recon: 20696.68, 20705.41,     kl: 19.86, 20.79,     l2: 5.44237,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:604, step:15650 (TRAIN, VALID): total: 20722.23, 20732.85      recon: 20696.60, 20706.22,     kl: 20.19, 21.18,     l2: 5.44450,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:605, step:15675 (TRAIN, VALID): total: 20721.58, 20730.74      recon: 20696.46, 20705.38,     kl: 19.68, 19.92,     l2: 5.44565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:606, step:15700 (TRAIN, VALID): total: 20721.74, 20732.30      recon: 20696.38, 20706.37,     kl: 19.92, 20.48,     l2: 5.44818,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:607, step:15725 (TRAIN, VALID): total: 20721.26, 20732.58      recon: 20696.12, 20706.99,     kl: 19.69, 20.14,     l2: 5.44990,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:608, step:15750 (TRAIN, VALID): total: 20721.17, 20731.59      recon: 20695.95, 20705.60,     kl: 19.77, 20.54,     l2: 5.45122,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:609, step:15775 (TRAIN, VALID): total: 20721.00, 20733.03      recon: 20695.81, 20706.81,     kl: 19.74, 20.77,     l2: 5.45451,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:610, step:15800 (TRAIN, VALID): total: 20722.12, 20731.58      recon: 20696.54, 20705.98,     kl: 20.13, 20.15,     l2: 5.45634,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:611, step:15825 (TRAIN, VALID): total: 20722.36, 20733.39      recon: 20696.86, 20707.05,     kl: 20.05, 20.88,     l2: 5.45935,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001424.\n",
      "Epoch:612, step:15850 (TRAIN, VALID): total: 20721.19, 20731.82      recon: 20695.91, 20705.68,     kl: 19.83, 20.67,     l2: 5.46145,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:613, step:15875 (TRAIN, VALID): total: 20721.08, 20733.92      recon: 20696.06, 20707.40,     kl: 19.56, 21.06,     l2: 5.46309,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:614, step:15900 (TRAIN, VALID): total: 20720.97, 20731.21      recon: 20695.73, 20705.53,     kl: 19.78, 20.21,     l2: 5.46588,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:615, step:15925 (TRAIN, VALID): total: 20721.50, 20732.21      recon: 20696.34, 20705.81,     kl: 19.69, 20.94,     l2: 5.46799,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:616, step:15950 (TRAIN, VALID): total: 20721.12, 20732.71      recon: 20695.85, 20706.86,     kl: 19.80, 20.38,     l2: 5.46785,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:617, step:15975 (TRAIN, VALID): total: 20721.78, 20734.60      recon: 20696.32, 20708.02,     kl: 20.00, 21.11,     l2: 5.46878,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:618, step:16000 (TRAIN, VALID): total: 20721.10, 20734.14      recon: 20695.86, 20708.60,     kl: 19.77, 20.07,     l2: 5.47073,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:619, step:16025 (TRAIN, VALID): total: 20721.33, 20731.60      recon: 20696.04, 20705.30,     kl: 19.82, 20.82,     l2: 5.47231,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:620, step:16050 (TRAIN, VALID): total: 20721.68, 20733.60      recon: 20696.25, 20706.87,     kl: 19.96, 21.26,     l2: 5.47556,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:621, step:16075 (TRAIN, VALID): total: 20721.72, 20731.63      recon: 20696.09, 20705.81,     kl: 20.16, 20.35,     l2: 5.47812,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:622, step:16100 (TRAIN, VALID): total: 20721.00, 20732.69      recon: 20695.89, 20706.60,     kl: 19.63, 20.61,     l2: 5.48017,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:623, step:16125 (TRAIN, VALID): total: 20720.76, 20733.60      recon: 20695.54, 20707.66,     kl: 19.74, 20.46,     l2: 5.48234,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:624, step:16150 (TRAIN, VALID): total: 20720.80, 20731.60      recon: 20695.61, 20705.94,     kl: 19.71, 20.18,     l2: 5.48380,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:625, step:16175 (TRAIN, VALID): total: 20721.15, 20730.71      recon: 20695.91, 20705.14,     kl: 19.75, 20.09,     l2: 5.48493,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:626, step:16200 (TRAIN, VALID): total: 20720.71, 20733.18      recon: 20695.52, 20707.22,     kl: 19.71, 20.48,     l2: 5.48573,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:627, step:16225 (TRAIN, VALID): total: 20720.59, 20732.07      recon: 20695.38, 20706.40,     kl: 19.73, 20.18,     l2: 5.48957,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:628, step:16250 (TRAIN, VALID): total: 20720.60, 20731.83      recon: 20695.31, 20705.77,     kl: 19.80, 20.56,     l2: 5.49025,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:629, step:16275 (TRAIN, VALID): total: 20720.57, 20731.82      recon: 20695.55, 20705.83,     kl: 19.53, 20.50,     l2: 5.49192,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:630, step:16300 (TRAIN, VALID): total: 20720.94, 20729.98      recon: 20695.67, 20704.34,     kl: 19.78, 20.14,     l2: 5.49321,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:631, step:16325 (TRAIN, VALID): total: 20721.46, 20730.40      recon: 20696.11, 20704.09,     kl: 19.85, 20.82,     l2: 5.49547,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001353.\n",
      "Epoch:632, step:16350 (TRAIN, VALID): total: 20720.54, 20732.21      recon: 20695.45, 20706.26,     kl: 19.60, 20.45,     l2: 5.49658,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:633, step:16375 (TRAIN, VALID): total: 20720.40, 20731.56      recon: 20695.09, 20705.63,     kl: 19.81, 20.44,     l2: 5.49815,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:634, step:16400 (TRAIN, VALID): total: 20720.67, 20730.56      recon: 20695.55, 20704.47,     kl: 19.62, 20.58,     l2: 5.49978,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:635, step:16425 (TRAIN, VALID): total: 20720.34, 20733.32      recon: 20695.21, 20707.19,     kl: 19.63, 20.63,     l2: 5.50140,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:636, step:16450 (TRAIN, VALID): total: 20721.27, 20732.09      recon: 20695.52, 20705.61,     kl: 20.24, 20.97,     l2: 5.50320,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:637, step:16475 (TRAIN, VALID): total: 20720.98, 20731.32      recon: 20695.57, 20705.32,     kl: 19.90, 20.50,     l2: 5.50473,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:638, step:16500 (TRAIN, VALID): total: 20720.21, 20732.02      recon: 20695.11, 20706.02,     kl: 19.59, 20.49,     l2: 5.50681,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:639, step:16525 (TRAIN, VALID): total: 20720.37, 20730.36      recon: 20695.23, 20704.97,     kl: 19.63, 19.89,     l2: 5.50739,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:640, step:16550 (TRAIN, VALID): total: 20720.47, 20730.83      recon: 20695.36, 20705.19,     kl: 19.61, 20.12,     l2: 5.50930,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:641, step:16575 (TRAIN, VALID): total: 20720.71, 20732.04      recon: 20695.45, 20706.04,     kl: 19.75, 20.49,     l2: 5.50998,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:642, step:16600 (TRAIN, VALID): total: 20720.42, 20731.05      recon: 20695.24, 20704.45,     kl: 19.67, 21.10,     l2: 5.51063,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:643, step:16625 (TRAIN, VALID): total: 20719.95, 20733.42      recon: 20694.80, 20707.46,     kl: 19.64, 20.44,     l2: 5.51260,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:644, step:16650 (TRAIN, VALID): total: 20720.08, 20731.99      recon: 20695.04, 20705.88,     kl: 19.52, 20.60,     l2: 5.51462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:645, step:16675 (TRAIN, VALID): total: 20720.39, 20733.29      recon: 20695.13, 20707.27,     kl: 19.75, 20.51,     l2: 5.51685,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:646, step:16700 (TRAIN, VALID): total: 20721.00, 20731.05      recon: 20695.78, 20705.11,     kl: 19.70, 20.42,     l2: 5.51945,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001285.\n",
      "Epoch:647, step:16725 (TRAIN, VALID): total: 20720.39, 20729.96      recon: 20695.09, 20704.54,     kl: 19.78, 19.91,     l2: 5.52081,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:648, step:16750 (TRAIN, VALID): total: 20720.04, 20730.72      recon: 20694.94, 20704.68,     kl: 19.58, 20.51,     l2: 5.52160,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:649, step:16775 (TRAIN, VALID): total: 20719.86, 20732.16      recon: 20694.77, 20705.65,     kl: 19.57, 20.98,     l2: 5.52317,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:650, step:16800 (TRAIN, VALID): total: 20721.08, 20731.19      recon: 20695.63, 20705.19,     kl: 19.93, 20.47,     l2: 5.52369,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:651, step:16825 (TRAIN, VALID): total: 20720.10, 20731.22      recon: 20694.99, 20705.67,     kl: 19.59, 20.01,     l2: 5.52512,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:652, step:16850 (TRAIN, VALID): total: 20719.96, 20732.95      recon: 20694.92, 20706.81,     kl: 19.51, 20.61,     l2: 5.52812,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:653, step:16875 (TRAIN, VALID): total: 20720.08, 20733.83      recon: 20694.88, 20707.94,     kl: 19.67, 20.35,     l2: 5.52964,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:654, step:16900 (TRAIN, VALID): total: 20719.88, 20730.40      recon: 20694.77, 20704.54,     kl: 19.58, 20.33,     l2: 5.53139,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:655, step:16925 (TRAIN, VALID): total: 20720.14, 20731.62      recon: 20694.83, 20706.30,     kl: 19.78, 19.78,     l2: 5.53288,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:656, step:16950 (TRAIN, VALID): total: 20720.44, 20731.09      recon: 20695.09, 20704.58,     kl: 19.82, 20.97,     l2: 5.53429,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:657, step:16975 (TRAIN, VALID): total: 20719.98, 20730.25      recon: 20694.82, 20704.57,     kl: 19.63, 20.15,     l2: 5.53560,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:658, step:17000 (TRAIN, VALID): total: 20719.75, 20731.76      recon: 20694.71, 20705.99,     kl: 19.50, 20.23,     l2: 5.53770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:659, step:17025 (TRAIN, VALID): total: 20719.42, 20732.06      recon: 20694.37, 20705.97,     kl: 19.51, 20.55,     l2: 5.53918,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:660, step:17050 (TRAIN, VALID): total: 20719.88, 20732.23      recon: 20694.89, 20706.60,     kl: 19.45, 20.10,     l2: 5.53993,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:661, step:17075 (TRAIN, VALID): total: 20719.96, 20732.49      recon: 20694.73, 20706.21,     kl: 19.68, 20.74,     l2: 5.54106,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:662, step:17100 (TRAIN, VALID): total: 20719.29, 20730.89      recon: 20694.40, 20704.91,     kl: 19.35, 20.44,     l2: 5.54374,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:663, step:17125 (TRAIN, VALID): total: 20719.85, 20734.04      recon: 20694.60, 20707.85,     kl: 19.71, 20.64,     l2: 5.54462,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:664, step:17150 (TRAIN, VALID): total: 20719.84, 20733.81      recon: 20694.66, 20707.78,     kl: 19.64, 20.49,     l2: 5.54677,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:665, step:17175 (TRAIN, VALID): total: 20719.97, 20731.96      recon: 20694.59, 20706.03,     kl: 19.84, 20.38,     l2: 5.54822,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001221.\n",
      "Epoch:666, step:17200 (TRAIN, VALID): total: 20719.56, 20731.82      recon: 20694.47, 20705.92,     kl: 19.54, 20.35,     l2: 5.55001,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:667, step:17225 (TRAIN, VALID): total: 20719.63, 20732.08      recon: 20694.71, 20706.18,     kl: 19.37, 20.34,     l2: 5.55223,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:668, step:17250 (TRAIN, VALID): total: 20719.67, 20732.22      recon: 20694.50, 20706.07,     kl: 19.62, 20.60,     l2: 5.55335,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:669, step:17275 (TRAIN, VALID): total: 20719.49, 20732.05      recon: 20694.47, 20705.88,     kl: 19.47, 20.62,     l2: 5.55537,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:670, step:17300 (TRAIN, VALID): total: 20719.73, 20733.90      recon: 20694.35, 20707.73,     kl: 19.83, 20.61,     l2: 5.55761,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:671, step:17325 (TRAIN, VALID): total: 20719.65, 20731.48      recon: 20694.47, 20705.66,     kl: 19.62, 20.26,     l2: 5.55840,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:672, step:17350 (TRAIN, VALID): total: 20719.27, 20731.82      recon: 20694.36, 20705.74,     kl: 19.35, 20.52,     l2: 5.55970,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:673, step:17375 (TRAIN, VALID): total: 20719.08, 20731.16      recon: 20694.13, 20705.47,     kl: 19.39, 20.14,     l2: 5.56119,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:674, step:17400 (TRAIN, VALID): total: 20718.81, 20733.19      recon: 20693.99, 20707.21,     kl: 19.26, 20.42,     l2: 5.56279,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:675, step:17425 (TRAIN, VALID): total: 20719.53, 20730.71      recon: 20694.30, 20705.10,     kl: 19.66, 20.05,     l2: 5.56414,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:676, step:17450 (TRAIN, VALID): total: 20719.42, 20733.21      recon: 20694.55, 20707.28,     kl: 19.31, 20.37,     l2: 5.56594,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:677, step:17475 (TRAIN, VALID): total: 20719.62, 20731.45      recon: 20694.36, 20705.22,     kl: 19.69, 20.66,     l2: 5.56775,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:678, step:17500 (TRAIN, VALID): total: 20720.22, 20731.99      recon: 20694.67, 20705.69,     kl: 19.98, 20.73,     l2: 5.56885,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001160.\n",
      "Epoch:679, step:17525 (TRAIN, VALID): total: 20719.05, 20732.56      recon: 20693.94, 20706.78,     kl: 19.54, 20.20,     l2: 5.57255,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:680, step:17550 (TRAIN, VALID): total: 20718.92, 20730.93      recon: 20693.97, 20704.86,     kl: 19.38, 20.50,     l2: 5.57544,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:681, step:17575 (TRAIN, VALID): total: 20719.35, 20731.32      recon: 20694.29, 20705.71,     kl: 19.48, 20.03,     l2: 5.57693,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:682, step:17600 (TRAIN, VALID): total: 20719.14, 20732.63      recon: 20694.10, 20706.15,     kl: 19.46, 20.90,     l2: 5.57792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:683, step:17625 (TRAIN, VALID): total: 20719.75, 20733.09      recon: 20694.47, 20706.75,     kl: 19.70, 20.76,     l2: 5.57957,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:684, step:17650 (TRAIN, VALID): total: 20718.97, 20731.80      recon: 20693.91, 20705.66,     kl: 19.48, 20.56,     l2: 5.58120,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:685, step:17675 (TRAIN, VALID): total: 20719.55, 20733.29      recon: 20694.23, 20707.15,     kl: 19.74, 20.56,     l2: 5.58202,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:686, step:17700 (TRAIN, VALID): total: 20719.31, 20732.02      recon: 20694.34, 20706.36,     kl: 19.39, 20.08,     l2: 5.58300,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:687, step:17725 (TRAIN, VALID): total: 20719.15, 20732.46      recon: 20693.92, 20706.28,     kl: 19.64, 20.60,     l2: 5.58374,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:688, step:17750 (TRAIN, VALID): total: 20719.31, 20731.21      recon: 20694.13, 20705.04,     kl: 19.60, 20.59,     l2: 5.58669,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:689, step:17775 (TRAIN, VALID): total: 20719.00, 20731.15      recon: 20693.95, 20704.96,     kl: 19.46, 20.60,     l2: 5.58803,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:690, step:17800 (TRAIN, VALID): total: 20719.55, 20731.56      recon: 20694.27, 20705.66,     kl: 19.70, 20.31,     l2: 5.58879,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:691, step:17825 (TRAIN, VALID): total: 20718.98, 20732.72      recon: 20694.02, 20707.02,     kl: 19.37, 20.11,     l2: 5.58993,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:692, step:17850 (TRAIN, VALID): total: 20719.23, 20730.23      recon: 20694.19, 20704.21,     kl: 19.45, 20.43,     l2: 5.59093,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:693, step:17875 (TRAIN, VALID): total: 20719.18, 20730.59      recon: 20693.91, 20704.38,     kl: 19.68, 20.62,     l2: 5.59235,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:694, step:17900 (TRAIN, VALID): total: 20719.00, 20731.43      recon: 20694.17, 20705.96,     kl: 19.23, 19.88,     l2: 5.59396,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:695, step:17925 (TRAIN, VALID): total: 20719.09, 20732.13      recon: 20693.91, 20706.31,     kl: 19.58, 20.23,     l2: 5.59639,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:696, step:17950 (TRAIN, VALID): total: 20719.01, 20731.67      recon: 20694.05, 20705.55,     kl: 19.36, 20.52,     l2: 5.59753,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:697, step:17975 (TRAIN, VALID): total: 20718.89, 20730.24      recon: 20693.86, 20704.39,     kl: 19.43, 20.25,     l2: 5.59885,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:698, step:18000 (TRAIN, VALID): total: 20718.58, 20732.86      recon: 20693.63, 20706.64,     kl: 19.34, 20.62,     l2: 5.60027,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:699, step:18025 (TRAIN, VALID): total: 20718.71, 20730.12      recon: 20693.61, 20704.16,     kl: 19.49, 20.36,     l2: 5.60139,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:700, step:18050 (TRAIN, VALID): total: 20718.81, 20730.80      recon: 20693.68, 20704.86,     kl: 19.53, 20.34,     l2: 5.60311,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:701, step:18075 (TRAIN, VALID): total: 20719.14, 20733.41      recon: 20693.96, 20706.90,     kl: 19.58, 20.90,     l2: 5.60490,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001102.\n",
      "Epoch:702, step:18100 (TRAIN, VALID): total: 20719.28, 20731.00      recon: 20694.01, 20704.82,     kl: 19.66, 20.57,     l2: 5.60681,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:703, step:18125 (TRAIN, VALID): total: 20719.54, 20733.22      recon: 20694.27, 20706.95,     kl: 19.67, 20.66,     l2: 5.60788,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:704, step:18150 (TRAIN, VALID): total: 20718.48, 20731.00      recon: 20693.53, 20705.25,     kl: 19.35, 20.13,     l2: 5.60877,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:705, step:18175 (TRAIN, VALID): total: 20718.87, 20731.04      recon: 20693.83, 20705.29,     kl: 19.43, 20.14,     l2: 5.60884,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:706, step:18200 (TRAIN, VALID): total: 20718.55, 20731.75      recon: 20693.57, 20705.65,     kl: 19.38, 20.49,     l2: 5.61054,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:707, step:18225 (TRAIN, VALID): total: 20718.83, 20732.18      recon: 20693.84, 20706.17,     kl: 19.38, 20.39,     l2: 5.61186,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:708, step:18250 (TRAIN, VALID): total: 20718.88, 20729.72      recon: 20693.72, 20703.87,     kl: 19.54, 20.23,     l2: 5.61375,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:709, step:18275 (TRAIN, VALID): total: 20718.47, 20731.81      recon: 20693.43, 20705.33,     kl: 19.43, 20.86,     l2: 5.61362,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:710, step:18300 (TRAIN, VALID): total: 20718.55, 20731.15      recon: 20693.46, 20705.06,     kl: 19.47, 20.47,     l2: 5.61629,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:711, step:18325 (TRAIN, VALID): total: 20718.62, 20729.04      recon: 20693.57, 20703.20,     kl: 19.43, 20.22,     l2: 5.61771,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:712, step:18350 (TRAIN, VALID): total: 20718.45, 20732.51      recon: 20693.49, 20706.48,     kl: 19.34, 20.41,     l2: 5.61795,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:713, step:18375 (TRAIN, VALID): total: 20718.19, 20731.97      recon: 20693.19, 20706.02,     kl: 19.38, 20.33,     l2: 5.61936,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:714, step:18400 (TRAIN, VALID): total: 20718.67, 20730.54      recon: 20693.59, 20704.28,     kl: 19.46, 20.64,     l2: 5.62070,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:715, step:18425 (TRAIN, VALID): total: 20718.88, 20730.94      recon: 20693.76, 20704.72,     kl: 19.50, 20.60,     l2: 5.62038,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.001047.\n",
      "Epoch:716, step:18450 (TRAIN, VALID): total: 20718.43, 20731.44      recon: 20693.30, 20705.46,     kl: 19.51, 20.35,     l2: 5.62171,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:717, step:18475 (TRAIN, VALID): total: 20718.26, 20731.33      recon: 20693.23, 20705.50,     kl: 19.41, 20.21,     l2: 5.62343,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:718, step:18500 (TRAIN, VALID): total: 20718.19, 20731.66      recon: 20693.27, 20705.68,     kl: 19.30, 20.36,     l2: 5.62396,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:719, step:18525 (TRAIN, VALID): total: 20717.80, 20731.93      recon: 20693.01, 20705.53,     kl: 19.16, 20.77,     l2: 5.62518,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:720, step:18550 (TRAIN, VALID): total: 20718.22, 20732.05      recon: 20693.35, 20706.19,     kl: 19.24, 20.23,     l2: 5.62585,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:721, step:18575 (TRAIN, VALID): total: 20718.22, 20731.58      recon: 20693.16, 20705.63,     kl: 19.43, 20.33,     l2: 5.62718,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:722, step:18600 (TRAIN, VALID): total: 20717.77, 20731.74      recon: 20692.90, 20705.63,     kl: 19.25, 20.48,     l2: 5.62792,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:723, step:18625 (TRAIN, VALID): total: 20718.22, 20732.01      recon: 20693.36, 20706.02,     kl: 19.23, 20.35,     l2: 5.62875,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:724, step:18650 (TRAIN, VALID): total: 20718.22, 20732.96      recon: 20693.21, 20706.91,     kl: 19.39, 20.42,     l2: 5.63056,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000994.\n",
      "Epoch:725, step:18675 (TRAIN, VALID): total: 20718.56, 20731.44      recon: 20693.52, 20705.39,     kl: 19.40, 20.42,     l2: 5.63241,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:726, step:18700 (TRAIN, VALID): total: 20718.01, 20732.09      recon: 20693.20, 20706.11,     kl: 19.18, 20.34,     l2: 5.63325,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:727, step:18725 (TRAIN, VALID): total: 20718.11, 20732.05      recon: 20693.22, 20706.19,     kl: 19.26, 20.22,     l2: 5.63372,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:728, step:18750 (TRAIN, VALID): total: 20718.11, 20732.77      recon: 20692.99, 20706.88,     kl: 19.49, 20.26,     l2: 5.63477,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:729, step:18775 (TRAIN, VALID): total: 20717.96, 20729.94      recon: 20692.99, 20704.28,     kl: 19.34, 20.02,     l2: 5.63607,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:730, step:18800 (TRAIN, VALID): total: 20717.78, 20730.77      recon: 20693.08, 20704.68,     kl: 19.06, 20.45,     l2: 5.63767,      kl weight: 1.00, l2 weight: 1.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:731, step:18825 (TRAIN, VALID): total: 20718.41, 20731.89      recon: 20693.38, 20705.56,     kl: 19.39, 20.69,     l2: 5.63887,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:732, step:18850 (TRAIN, VALID): total: 20717.72, 20732.58      recon: 20692.77, 20706.51,     kl: 19.31, 20.44,     l2: 5.64014,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:733, step:18875 (TRAIN, VALID): total: 20717.55, 20732.12      recon: 20692.73, 20705.79,     kl: 19.18, 20.70,     l2: 5.64131,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:734, step:18900 (TRAIN, VALID): total: 20718.10, 20732.39      recon: 20692.96, 20706.99,     kl: 19.50, 19.75,     l2: 5.64232,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:735, step:18925 (TRAIN, VALID): total: 20718.26, 20729.80      recon: 20693.31, 20703.93,     kl: 19.31, 20.22,     l2: 5.64232,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:736, step:18950 (TRAIN, VALID): total: 20718.13, 20732.68      recon: 20692.95, 20706.45,     kl: 19.54, 20.58,     l2: 5.64369,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:737, step:18975 (TRAIN, VALID): total: 20717.79, 20732.22      recon: 20693.02, 20706.21,     kl: 19.12, 20.36,     l2: 5.64511,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:738, step:19000 (TRAIN, VALID): total: 20717.78, 20732.60      recon: 20693.01, 20706.47,     kl: 19.13, 20.48,     l2: 5.64522,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:739, step:19025 (TRAIN, VALID): total: 20717.59, 20732.41      recon: 20692.69, 20706.16,     kl: 19.26, 20.60,     l2: 5.64565,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:740, step:19050 (TRAIN, VALID): total: 20717.61, 20729.98      recon: 20692.80, 20704.03,     kl: 19.16, 20.31,     l2: 5.64740,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:741, step:19075 (TRAIN, VALID): total: 20717.26, 20731.75      recon: 20692.64, 20705.89,     kl: 18.97, 20.21,     l2: 5.64770,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:742, step:19100 (TRAIN, VALID): total: 20717.76, 20731.87      recon: 20692.84, 20705.54,     kl: 19.27, 20.69,     l2: 5.64886,      kl weight: 1.00, l2 weight: 1.00\n",
      "Epoch:743, step:19125 (TRAIN, VALID): total: 20717.93, 20729.81      recon: 20692.92, 20704.02,     kl: 19.35, 20.13,     l2: 5.65024,      kl weight: 1.00, l2 weight: 1.00\n",
      "     Decreasing learning rate to 0.000945.\n"
     ]
    }
   ],
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=gaussian_chaotic_rnn_no_inputs \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_inputs_g2p5 \\\n",
    "--co_dim=1 \\\n",
    "--factors_dim=20 \\\n",
    "--output_dist=gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "! python run_lfads.py --kind=train \\\n",
    "--data_dir=/tmp/rnn_synth_data_v1.0/ \\\n",
    "--data_filename_stem=chaotic_rnn_inputs_g2p5 \\\n",
    "--lfads_save_dir=/tmp/lfads_chaotic_rnn_inputs_g2p5 \\\n",
    "--co_dim=1 \\\n",
    "--factors_dim=20 \\\n",
    "--output_dist=poisson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
